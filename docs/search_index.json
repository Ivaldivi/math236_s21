[["index.html", "MATH 236: Linear Algebra Preface", " MATH 236: Linear Algebra Preface This is the class handbook for Math 236 Linear Algebra at Macalester College. The content here was made by Andrew Beveridge and draws upon material prepared by Tom Halverson and other faculty in the Department of Mathematics, Statistics and Computer Science at Macalester College. This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["problem-set-1.html", "Vector 1 Problem Set 1 1.1 Characterize the Solution Set 1.2 Find the Parametric Solution 1.3 Elementary row operations are reversible 1.4 Traffic Flow 1.5 Parabolas Through Two Points", " Vector 1 Problem Set 1 Due: Tuesday November 3 by 11:55pm CST. Upload your solutions to Moodle in a PDF. Please feel free to use RStudio for all row reductions. You can download the Rmd source file for this problem set. 1.1 Characterize the Solution Set The following augmented matrices are in row echelon form. Decide whether the set of solutions is a point, line, plane, or the empty set in 3-space. Briefly justify your answer. \\(\\left[ \\begin{array}{ccc|c} 1 &amp; 3 &amp; -1 &amp; 4 \\\\ 0 &amp; 1 &amp; 4 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 2 \\\\ \\end{array} \\right]\\) \\(\\left[ \\begin{array}{ccc|c} 1 &amp; 3 &amp; -1 &amp; 5 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\end{array} \\right]\\) \\(\\left[ \\begin{array}{ccc|c} 1 &amp; -1 &amp; 0 &amp; -2 \\\\ 0 &amp; 0 &amp; 1 &amp; 7\\\\ 0 &amp; 0 &amp; 0 &amp; 1\\\\ \\end{array} \\right]\\) \\(\\left[ \\begin{array}{ccc|c} 0 &amp; 1 &amp; 0 &amp; 6 \\\\ 0 &amp; 0 &amp; 1 &amp; -2 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\end{array} \\right]\\) 1.2 Find the Parametric Solution Each of the following matrices is the reduced row echelon form of the augmented matrix of a system of linear equations. Give the general solution to each system. \\(\\left[ \\begin{array}{cccc|c} 1 &amp; 3 &amp; 0 &amp; -2 &amp; 5\\\\ 0 &amp; 0 &amp; 1 &amp; 4 &amp; -2 \\\\ \\end{array} \\right]\\) \\(\\left[ \\begin{array}{ccccc|c} 1 &amp; 0 &amp; 4 &amp; 0 &amp; 3 &amp; 6\\\\ 0 &amp; 1 &amp; 1 &amp; 0 &amp; -2&amp; -8 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -1 &amp; 3 \\\\ \\end{array} \\right]\\) \\(\\left[ \\begin{array}{cccc|c} 1 &amp; 4 &amp; 0 &amp; 0 &amp; -2 \\\\ 0 &amp; 0 &amp; 1 &amp; 7 &amp; 6\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\end{array} \\right]\\) 1.3 Elementary row operations are reversible In each case below, an elementary row operation turns the matrix \\(A\\) into the matrix \\(B\\). For each of them, Describe the row operation that turns \\(A\\) into \\(B\\), and Describe the row operation that turns \\(B\\) into \\(A\\). Give your answers in the form: “scale \\(R_2\\) by 3” or “swap \\(R_1\\) and \\(R_4\\)” or “replace \\(R_3\\) with \\(R_3 + \\frac{1}{5} R_1\\).” \\[A=\\left[ \\begin{array}{cccc} 1 &amp; 1 &amp; 1 &amp; 3 \\\\ 1 &amp; -2 &amp; 2 &amp; 1 \\\\ 2 &amp; 8 &amp; 2 &amp; -4 \\\\ 3 &amp; 1 &amp; 6 &amp; -1 \\\\ \\end{array} \\right]\\longrightarrow B=\\left[ \\begin{array}{cccc} 1 &amp; 1 &amp; 1 &amp; 3 \\\\ 1 &amp; -2 &amp; 2 &amp; 1 \\\\ 2 &amp; 8 &amp; 2 &amp; -4 \\\\ 0 &amp; 7 &amp; 0 &amp; -4 \\\\ \\end{array} \\right]\\] \\[A=\\left[ \\begin{array}{cccc} 1 &amp; 1 &amp; 1 &amp; 3 \\\\ 1 &amp; -2 &amp; 2 &amp; 1 \\\\ 2 &amp; 8 &amp; 2 &amp; -4 \\\\ 3 &amp; 1 &amp; 6 &amp; -1 \\\\ \\end{array} \\right]\\longrightarrow B=\\left[ \\begin{array}{cccc} 1 &amp; -2 &amp; 2 &amp; 1 \\\\ 1 &amp; 1 &amp; 1 &amp; 3 \\\\ 2 &amp; 8 &amp; 2 &amp; -4 \\\\ 3 &amp; 1 &amp; 6 &amp; -1 \\\\ \\end{array} \\right]\\] \\[A=\\left[ \\begin{array}{cccc} 1 &amp; 1 &amp; 1 &amp; 3 \\\\ 1 &amp; -2 &amp; 2 &amp; 1 \\\\ 2 &amp; 8 &amp; 2 &amp; -4 \\\\ 3 &amp; 1 &amp; 6 &amp; -1 \\\\ \\end{array} \\right]\\longrightarrow B=\\left[ \\begin{array}{cccc} 1 &amp; 1 &amp; 1 &amp; 3 \\\\ 1 &amp; -2 &amp; 2 &amp; 1 \\\\ 1 &amp; 4 &amp; 1 &amp; -2 \\\\ 3 &amp; 1 &amp; 6 &amp; -1 \\\\ \\end{array} \\right]\\] 1.4 Traffic Flow Below you find a section of one-way streets in downtown St Paul, where the arrows indicate traffic direction. The traffic control center has installed electronic sensors that count the numbers of vehicles passing through the 6 streets that lead into and out of this area. Assume that the total flow that enters each intersection equals the the total flow that leaves each intersection (we will ignore parking and staying). Create a system of linear equations to find the possible flow values for the inner streets \\(x_1, x_2, x_3, x_4\\). Use RStudio to find the solution set. Write your answer in parametric form. Your answer to part 2 finds an infinite solution set. In terms of traffic flow, explain why there can be more than one solution. Thinking about cars traveling along streets, why is there some flexibility in the overall flow of cars? Now critique the model as presented. What solutions to the linear system are problematic for our original traffic flow problem? What additional conditions should we require for a valid solution? 1.5 Parabolas Through Two Points You will find the family of all possible parabolas \\[ f(x) = a x^2 + b x + c \\] through two given points. Note that there will be an infinite number of such polynomials: there are three unknowns, but only two constraints. So there will be at least one free variable. Here are the plots of the two different families of parabolas that you will consider. For each pair of points, (a) create linear system that represents the problem (b) use RStudio to find the RREF of the augmented matrix for the system and (c) write down the general formula for the family of parabolas \\(f(x)\\) that contain the points. \\(p_1 = (1,0)\\) and \\(p_2 = (5,0)\\) \\(q_1= (1,-3)\\) and \\(q_2 = (5,10)\\) Part 1.1 characterizes the family of parabolas that contain the points \\(p_1\\) and \\(p_2\\). Let’s refer to this family of parabolas as our “\\(p_1,p_2\\) family.” Pick any two functions \\(g_1(x)\\) and \\(g_2(x)\\) from this \\(p_1,p_2\\) family of parabolas. Now consider the parabola \\[ g(x) = g_1(x) - g_2(x). \\] Show that \\(g(1)=0\\) and \\(g(5)=0\\). This means that \\(g(x)\\) is also in our \\(p_1,p_2\\) family! (That’s really cool!) Part 1.2 characterizes the family of parabolas that contain the points \\(q_1\\) and \\(q_2\\). Let’s refer to this family of parabolas as our “\\(q_1,q_2\\) family.” Pick any two functions \\(h_1(x)\\) and \\(h_2(x)\\) in this \\(q_1,q_2\\) family. Now consider the parabola \\[ h(x) = h_1(x) - h_2(x). \\] Show that \\(h(1) \\neq -3\\) and \\(h(5) \\neq 10\\). This means that \\(h(x)\\) is NOT in our \\(q_1,q_2\\) family. (So this family is not as nice as the previous one.) Now explain why the parabola \\(h(x)\\) from part 3 is actually a member of the \\(p_1, p_2\\) family. (So maybe this family is nicer than we thought!) Remark: This problem is about families of parabolas. But at its core, this is actually a problem about linear algebra. Obviously, we used linear algebra to solve part 1, but there is linear algebra in the other parts as well! We define \\(g(x) = g_1(x) - g_2(x)\\) by taking a linear combination of two functions. (Just like we take linear combinations of vectors.) What leads to the “nice” behavior of the \\(p_1, p_2\\) family in part 2? It’s because the \\(y\\)-values of the constraining points are both 0. We will soon learn about homogeneous linear systems whose right hand sides are all zero. These homogeneous systems have some very special properties. The \\(q_1, q_2\\) family is “not nice” because it a nonhomogenous system. Just as there is a connection betwen the \\(p_1,p_2\\) family and the \\(q_1, q_2\\) family, we will soon learn that there is a connection between homogeneous systems and nonhomogeneous systems. "],["problem-set-2.html", "Vector 2 Problem Set 2 2.1 Parametric Vector Form 2.2 RREF for a linear system 2.3 RREF for a set of vectors 2.4 Removing free variable columns from a matrix 2.5 A square matrix 2.6 Combining solutions to \\(A \\mathsf{x} = \\mathsf{b}\\)", " Vector 2 Problem Set 2 Due: Friday November 6 by 5:00pm CST. Upload your solutions to Moodle in a PDF. Please feel free to use RStudio for all row reductions. You can download the Rmd source file for this problem set. The Problem Set covers sections 1.3, 1.4, 1.5. 2.1 Parametric Vector Form Here is the augmented matrix for a system of linear equations \\(\\mathsf{A} \\mathsf{x} = \\mathsf{b}\\), and its RREF. Give the complete solution to this system in parametric vector form. \\[\\left[ \\begin{array}{ccccc|c} 1 &amp; 1 &amp; -1 &amp; -1 &amp; 2 &amp; 1 \\\\ 1 &amp; 0 &amp; -2 &amp; 1 &amp; 1 &amp; 3 \\\\ -2 &amp; 1 &amp; 5 &amp; 1 &amp; -6 &amp; 2 \\\\ -3 &amp; 0 &amp; 6 &amp; 2 &amp; -8 &amp; 1 \\\\ 0 &amp; 1 &amp; 1 &amp; 2 &amp; -3 &amp; 6 \\\\ 1 &amp; 0 &amp; -2 &amp; -1 &amp; 3 &amp; -1 \\\\ \\end{array} \\right] \\longrightarrow \\left[ \\begin{array}{ccccc|c} 1 &amp; 0 &amp; -2 &amp; 0 &amp; 2 &amp; 1 \\\\ 0 &amp; 1 &amp; 1 &amp; 0 &amp; -1 &amp; 2 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -1 &amp; 2 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\end{array} \\right] \\] 2.2 RREF for a linear system Here is the reduced row echelon form of a matrix \\(\\mathsf{A}\\) (you are not given the matrix \\(\\mathsf{A}\\)). \\[ \\mathsf{A} \\longrightarrow \\left[ \\begin{array}{cccc} 1 &amp; -2 &amp; 0 &amp; 4 \\\\ 0 &amp; 0 &amp; 1 &amp; -5 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\end{array} \\right] \\] Give the parametric equations of the general solution to the homogenous equation \\(\\mathsf{A} \\mathsf{x} = {\\bf 0}\\). Describe the geometric form of your answer to part (a). For example, you answer should be something like: “it is a plane in \\(\\mathbb{R}^3\\)” or “it is a line in \\(\\mathbb{R}^7\\)” or “it is a point in \\(\\mathbb{R}^4\\).” Suppose that we also know that \\(\\mathsf{A}\\begin{bmatrix} 4 \\\\ 1 \\\\ -3 \\\\ 2 \\\\ \\end{bmatrix} = \\begin{bmatrix} 22 \\\\ -13 \\\\ 7 \\\\ \\end{bmatrix}\\). Then give the general solution to \\(\\mathsf{A} \\mathsf{x}= \\begin{bmatrix} 22 \\\\ -13\\\\ 7 \\\\ \\end{bmatrix}\\) in parametric form. 2.3 RREF for a set of vectors Suppose that we have five vectors \\(\\mathsf{v}_1, \\mathsf{v}_2,\\mathsf{v}_3,\\mathsf{v}_4,\\mathsf{v}_5\\) in \\(\\mathbb{R}^4\\) and that the matrix \\[ A = \\left[ \\begin{array}{ccc} \\mid &amp; \\mid &amp; \\mid &amp; \\mid &amp; \\mid \\\\ \\mathsf{v}_1 &amp; \\mathsf{v}_2 &amp; \\mathsf{v}_3 &amp;\\mathsf{v}_4 &amp;\\mathsf{v}_5 \\\\ \\mid &amp; \\mid &amp; \\mid &amp; \\mid &amp; \\mid \\end{array} \\right] \\] has reduced row echelon form \\[ \\begin{bmatrix} 1 &amp; 0 &amp; -3 &amp; 0 &amp; 2 \\\\ 0 &amp; 1 &amp; 4 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix}. \\] Do the vectors \\(\\mathsf{v}_1, \\mathsf{v}_2, \\mathsf{v}_3, \\mathsf{v}_4, \\mathsf{v}_5\\) span \\(\\mathbb{R}^4\\)? Justify your answer. Is the vector \\(\\mathsf{v}_3\\) in \\(\\mathrm{span}(\\mathsf{v}_1,\\mathsf{v}_2)\\)? Justify your answer. Pick any \\(\\mathsf{b}\\) in \\(\\mathrm{span}(\\mathsf{v}_1, \\mathsf{v}_2, \\mathsf{v}_3, \\mathsf{v}_4, \\mathsf{v}_5)\\). Is there always a unqiue way to write \\(\\mathsf{b}\\) as a linear combination of \\(\\mathsf{v}_1, \\mathsf{v}_2, \\mathsf{v}_3, \\mathsf{v}_4, \\mathsf{v}_5\\)? Justify your answer. 2.4 Removing free variable columns from a matrix Consider the matrix \\[ A =\\left[ \\begin{array}{cccccc} 6 &amp; 5 &amp; -3 &amp; 4 &amp; 2 &amp; -9 \\\\ -7 &amp; -6 &amp; 4 &amp; -5 &amp; -7 &amp; 16 \\\\ -4 &amp; -3 &amp; -1 &amp; 0 &amp; -8 &amp; 9 \\\\ 8 &amp; 7 &amp; -5 &amp; 6 &amp; 1 &amp; -12 \\end{array} \\right]. \\] Use RStudio to show that the columns of \\(\\mathsf{A}\\) span \\(\\mathbb{R}^4\\). Write down matrix \\(\\mathsf{A}&#39;\\) that you get by removing the free variable columns from \\(\\mathsf{A}\\). Without using additional calculations on RStudio, explain why the new system \\(\\mathsf{A}&#39; \\mathsf{x} = \\mathsf{b}\\) is consistent and has a unique solution for every choice of \\(\\mathsf{b} \\in \\mathbb{R}^4\\). 2.5 A square matrix Suppose that \\(A\\) is a \\(5\\times 5\\) matrix and \\(\\mathsf{b}\\) is a vector in \\(\\mathbb{R}^5\\) with the property that \\(A\\mathsf{x}=\\mathsf{b}\\) has a unique solution. Explain why the columns of \\(A\\) must span \\(\\mathbb{R}^5\\). Use the reduced row echelon form of \\(A\\) in your explanation. 2.6 Combining solutions to \\(A \\mathsf{x} = \\mathsf{b}\\) Suppose that \\(\\mathsf{x}_1\\) and \\(\\mathsf{x}_2\\) are solutions to \\(\\mathsf{A} \\mathsf{x} = \\mathsf{b}\\) (where \\(\\mathsf{b} \\not= \\mathsf{0}\\)). Decide if any of the following are also solutions to \\(\\mathsf{A} \\mathsf{x} = \\mathsf{b}\\). \\(\\mathsf{x}_1+ \\mathsf{x}_2\\) \\(\\mathsf{x}_1 - \\mathsf{x}_2\\) \\(\\frac{1}{2} ( \\mathsf{x}_1 + \\mathsf{x}_2)\\) \\(\\frac{5}{2} \\mathsf{x}_1 - \\frac{3}{2} \\mathsf{x}_2\\). Under what conditions on \\(c\\) and \\(d\\) is \\(\\mathsf{x} = c \\mathsf{x}_1 + d \\mathsf{x}_2\\) a solution to \\(\\mathsf{A} \\mathsf{x} = \\mathsf{b}\\)? Justify your answer. Let \\(\\mathsf{u}\\) be the vector that points to \\(1/3\\) of the way from the tip of \\(\\mathsf{v}\\) to the tip of \\(\\mathsf{w}\\) as depicted below. Write \\(\\mathsf{u}\\) as a linear combination of \\(\\mathsf{v}\\) and \\(\\mathsf{w}\\) (hint: think about \\(\\mathsf{w} - \\mathsf{v}\\)) If \\(\\mathsf{v}\\) and \\(\\mathsf{w}\\) are solutions to \\(A x = \\mathsf{b}\\) then show that \\(\\mathsf{u}\\) is also a solution to \\(A \\mathsf{x} = \\mathsf{b}\\). "],["problem-set-3.html", "Vector 3 Problem Set 3 3.1 Three vectors in \\(\\mathbb{R}^4\\) 3.2 A Balanced Diet 3.3 A Problem about Span and Linear Dependence 3.4 Properties of Linear Transformations 3.5 Partial Information about a Linear Transformation 3.6 House Renovations", " Vector 3 Problem Set 3 Due: Tuesday November 10 by 11:55pm CST. Upload your solutions to Moodle in a PDF. Please feel free to use RStudio for all row reductions. You can download the Rmd source file for this problem set. The Problem Set covers sections 1.7, 1.8, 1.9. 3.1 Three vectors in \\(\\mathbb{R}^4\\) Consider the vectors \\(\\mathbf{u}\\), \\(\\mathbf{v}\\), and \\(\\mathbf{w}\\) given by \\[ \\qquad \\mathbf{u} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\\\ -1 \\end{bmatrix}, \\qquad \\mathbf{v} = \\begin{bmatrix} 2 \\\\ -1 \\\\ 3 \\\\ 1 \\end{bmatrix}, \\qquad \\mathbf{w} = \\begin{bmatrix} 1 \\\\ -2 \\\\ 2 \\\\ 1 \\end{bmatrix}. \\] Use RStudio to answer the following questions. Are \\(\\mathbf{u}\\), \\(\\mathbf{v}\\), and \\(\\mathbf{w}\\) linearly independent? Is the vector \\(\\mathbf{b} = \\begin{bmatrix} 4 \\\\ 4 \\\\ 2 \\\\ 4 \\end{bmatrix}\\) in the span of vectors \\(\\mathbf{u}\\), \\(\\mathbf{v}\\), and \\(\\mathbf{w}\\)? Is the vector \\(\\mathbf{b} = \\begin{bmatrix} 2 \\\\ 1 \\\\ 3 \\\\ 1 \\end{bmatrix}\\) in the span of vectors \\(\\mathbf{u}\\), \\(\\mathbf{v}\\), and \\(\\mathbf{w}\\)? 3.2 A Balanced Diet An athlete wants to consume a daily diet of 200 grams of carbohydrates, 60 grams of fats and 160 grams of proteins. Here are some of their favorite foods. Table 3.1: Food Carb/Fat/Protein (grams) food carbs fats proteins almonds 3 8 5 avocado 15 31 4 beans 20 1 8 bread 12 1 2 cheese 1 5 3 chicken 0 13 50 egg 1 5 6 milk 12 8 8 zucchini 6 0 2 Answer the following questions, using RStudio for your calculations. Each response must use two or more of the following terms: linear combination, span, linearly dependent, linearly independent. Explain why they cannot achieve their daily goal by eating only almonds, milk and zucchini. Explain why they cannot achieve their daily goal by eating only almonds, beans and cheese. Find a valid one-day diet consisting of almonds, chicken, and zucchini. 3.3 A Problem about Span and Linear Dependence Let \\(\\mathsf{v}_1, \\mathsf{v}_2, \\mathsf{v}_3\\) and \\(\\mathsf{w}_1, \\mathsf{w}_2, \\mathsf{w}_3, \\mathsf{w}_4\\) all be vectors in \\(\\mathbb{R}^4\\). Suppose that \\(\\{ \\mathsf{v}_1, \\mathsf{v}_2, \\mathsf{v}_3 \\}\\) is a linearly independent set, and that \\[ \\mathrm{span}(\\mathsf{v}_1, \\mathsf{v}_2, \\mathsf{v}_3) = \\mathrm{span}(\\mathsf{w}_1, \\mathsf{w}_2, \\mathsf{w}_3, \\mathsf{w}_4). \\] Prove that \\(\\mathsf{w}_1, \\mathsf{w}_2, \\mathsf{w}_3, \\mathsf{w}_4\\) must be linearly dependent. You can do this by either: Explaning why there must be a nontrivial linear combination \\(c_1 \\mathsf{w}_1 + c_2 \\mathsf{w}_2 + c \\mathsf{w}_3 + c \\mathsf{w}_4 = \\mathbf{0}\\), or Showing that the \\(4 \\times 4\\) matrix \\(\\begin{bmatrix} \\mathsf{w}_1 &amp; \\mathsf{w}_2 &amp; \\mathsf{w}_3 &amp; \\mathsf{w}_4 \\end{bmatrix}\\) does not have a pivot in every column. 3.4 Properties of Linear Transformations Here are the row reductions to reduced row echelon form of 4 matrices. \\[ \\begin{array}{ll} A \\longrightarrow \\begin{bmatrix} 1 &amp; 0 &amp; 5 &amp; -3 &amp; 0\\\\ 0 &amp; 1 &amp; -2 &amp; 8 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix} \\qquad &amp; B \\longrightarrow \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix} \\\\ \\\\ C \\longrightarrow \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} &amp; D \\longrightarrow \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 1 \\end{bmatrix} \\end{array} \\] In each case, if \\(T\\) is the linear transformation given by the matrix product \\(T(x) = M x\\), where \\(M\\) is an \\(m \\times n\\) matrix (\\(m\\) rows and \\(n\\) columns) then \\(T: \\mathbb{R}^n \\to \\mathbb{R}^m\\) is a transformation from domain \\(\\mathbb{R}^n\\) to codomain (aka target) \\(\\mathbb{R}^m\\). Determine the appropriate values for \\(n\\) and \\(m\\), and decide whether \\(T\\) is one-to-one and/or onto. Submit your answers in table form, as shown below. \\[ \\begin{array} {|c|c|c|c|c|} \\hline \\text{matrix } M &amp; n &amp; m &amp; \\text{one-to-one?} &amp; \\text{onto?} \\\\ \\hline A &amp;\\phantom{\\Big\\vert XX}&amp;\\phantom{\\Big\\vert XX}&amp;&amp; \\\\ \\hline B &amp;\\phantom{\\Big\\vert XX}&amp;&amp;&amp; \\\\ \\hline C &amp;\\phantom{\\Big\\vert XX}&amp;&amp;&amp; \\\\ \\hline D &amp;\\phantom{\\Big\\vert XX}&amp;&amp;&amp; \\\\ \\hline \\end{array} \\hskip5in \\] 3.5 Partial Information about a Linear Transformation \\(T: \\mathbb{R}^4 \\rightarrow \\mathbb{R}^3\\) is a linear transformation such that: \\[ T\\left(\\begin{bmatrix} 1 \\\\ 2 \\\\ 2 \\\\ 0 \\end{bmatrix} \\right) = \\begin{bmatrix} ~4~ \\\\ -1~ \\\\ 2 \\end{bmatrix} \\quad \\mbox{and} \\quad T\\left(\\begin{bmatrix} 2 \\\\ -1~ \\\\ 1 \\\\ 3 \\end{bmatrix} \\right) = \\begin{bmatrix} ~2~ \\\\ 6 \\\\ -1~ \\end{bmatrix} \\quad \\mbox{and} \\quad T\\left(\\begin{bmatrix} 3 \\\\ 0 \\\\ 2 \\\\ 2 \\end{bmatrix} \\right) = \\begin{bmatrix} 6 \\\\ 5 \\\\ 1 \\end{bmatrix} \\] Do we have enough information to determine whether \\(T\\) is one-to-one? If no, then explain why not. If yes, then do so, along with a justification. Do we have enough information to determine whether \\(T\\) is onto? If no, then explain why not. If yes, then do so, along with a justification. 3.6 House Renovations Find the matrix of a linear transformation \\(T: \\mathbb{R}^2 \\to \\mathbb{R}^2\\) that performs the given transformation of my house. (Hint: use the base, the doorway and the peak of the roof as a guide.) Transformation #1 \\(\\qquad \\qquad\\) Transformation #2 \\(\\qquad \\qquad\\) For your convenience, here is the code to make the original plot of the house. par(pty=&quot;s&quot;) house = cbind(c(0,0), c(0,3/4), c(1/2,3/4), c(1/2,0), c(1,0), c(1,1), c(5/4,1), c(0,2), c(-5/4,1), c(-1,1), c(-1,0), c(0,0)); plot(house[1,],house[2,],type=&quot;n&quot;,xlim=c(-6,6),ylim=c(-6,6),xlab=&quot;x&quot;,ylab=&quot;y&quot;, asp=1) abline(h=-6:6, v=-6:6, col=&quot;gray&quot;, lty=&quot;dotted&quot;) polygon(house[1,], house[2,], col = &quot;gray&quot;, border = &quot;blue&quot;) "],["problem-set-4.html", "Vector 4 Problem Set 4 4.1 An Invertible Product of Rectangular Matrices 4.2 Guessing the Inverse Matrix from a Pattern 4.3 LU Decomposition of an Invertible Matrix 4.4 Homogeneous Coordinates", " Vector 4 Problem Set 4 Due: Tuesday November 17 by 11:55pm CST. Upload your solutions to Moodle in a PDF. Please feel free to use RStudio for all row reductions. You can download the Rmd source file for this problem set. Would you like use RMarkdown to type up some or all of your solution? Here is an Rmd template file to get you started. You can “knit to PDF” when you are done. Here are some helpful resources: RMarkdown Basics Math Typsetting using LaTeX syntax The Rmd source for the problem set which has examples of using \\begin{bmatrix} ... \\end{bmatrix} to format matrices. The Problem Set covers sections 2.1, 2.2 and 2.3, and homogeneous coordinates. 4.1 An Invertible Product of Rectangular Matrices Suppose that \\(m \\neq n\\) and that \\(B\\) is a \\(m \\times n\\) matrix and that \\(C\\) is an \\(n \\times m\\) matrix where \\(A =BC\\) is an invertible matrix. Is \\(m &gt; n\\) or is \\(m &lt; n\\)? Explain. Since \\(A\\) is invertible, the Invertible Matrix Theorem tells us the following facts: \\(A\\) has a pivot in every row \\(A\\) has a pivot in every column \\(T(\\mathsf{x}) = A\\mathsf{x}\\) is one-to-one \\(T(\\mathsf{x}) = A\\mathsf{x}\\) is onto The columns of \\(A\\) span \\(\\mathbb{R}^m\\) The columns of \\(A\\) are linearly independent \\(A \\mathsf{x} =\\mathsf{b}\\) has at least one solution for all \\(\\mathsf{b}\\) \\(A \\mathsf{x} =\\mathbf{0}\\) only has the trivial solution What do these conditions guarantee about the \\(m \\times n\\) matrix \\(B\\) and the \\(n \\times m\\) matrix \\(C\\)? Make the appropriate list for each of \\(B\\) and \\(C\\). 4.2 Guessing the Inverse Matrix from a Pattern Use RStudio to find the inverse matrix for each of the following matrices. \\[ \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 \\end{bmatrix} \\qquad \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 &amp; 1 \\\\ \\end{bmatrix} \\qquad \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0\\\\ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 0\\\\ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1\\\\ \\end{bmatrix}. \\] by creating a matrix of the form \\([ \\, A \\, | \\, I \\, ]\\) and putting it into RREF to obtain \\([ \\, I \\, | \\, A^{-1} \\, ]\\). Use the previous part to guess the inverse matrix \\(A^{-1}\\) of the \\(n \\times n\\) matrix \\[ A = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp;0&amp;0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 &amp; \\cdots &amp;0 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 \\\\ \\vdots &amp; &amp; &amp; \\ddots &amp; &amp; \\vdots \\\\ 1 &amp; 1 &amp; 1 &amp; 1 &amp; \\cdots &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 &amp; 1 &amp; \\cdots &amp; 1 &amp; 1 \\end{bmatrix}. \\] Use this same method to guess the inverse matrix \\(B^{-1}\\) for the \\(n \\times n\\) matrix \\[ B = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 \\\\ 2 &amp; 2 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 \\\\ 3 &amp; 3 &amp; 3 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 \\\\ \\vdots &amp; &amp; &amp; \\ddots &amp; &amp; \\vdots \\\\ n-1 &amp; n-1 &amp; n-1 &amp; n-1 &amp; \\cdots &amp; n-1 &amp; 0 \\\\ n &amp; n &amp; n &amp; n &amp; \\cdots &amp; n &amp; n \\end{bmatrix}. \\] Pro Tip: when R displays a number with a large negative exponent like 3.700743e-17 then this number is \\(3.700743 \\times 10^{-17}\\) which is numerically equivalent to 0. 4.3 LU Decomposition of an Invertible Matrix Let \\(A\\) be a \\(4 \\times 4\\) invertible matrix. Recall that if we run Gaussian Elimination on \\([ \\, A \\, | \\, I \\, ]\\) until the first part is the RREF of matrix \\(A\\), then we get the matrix \\([ \\, I \\, | \\, A^{-1} ]\\). In other words, this procedue is how we calculate \\(A^{-1}\\). But what if we stop this process at the REF of matrix \\(A\\)? Let’s call this resulting matrix \\([ \\, B \\, | \\, C \\, ]\\) where \\(B\\) is the RREF of \\(A\\) where all the pivots are 1, so \\(B\\) looks like \\[ B = \\begin{bmatrix} 1 &amp; b_{12} &amp; b_{13}&amp; b_{14} \\\\ 0 &amp; 1 &amp; b_{23} &amp; b_{24} \\\\ 0 &amp; 0 &amp; 1 &amp; b_{34} \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ \\end{bmatrix} \\] Remark: B is an example of an invertible upper triangular matrix: all the entries below the diagonal are zero. Assume that \\(A\\) is a \\(4 \\times 4\\) matrix such that Gaussian Elimination to REF only uses two types of Elementary Row Operations: (E1) Add a multiple of one row to another (E3) Multiply a row by a nonzero constant. Explain why \\(C\\) has the the form \\[ C = \\begin{bmatrix} c_{11} &amp; 0 &amp; 0 &amp; 0 \\\\ c_{21} &amp; c_{22} &amp; 0 &amp; 0 \\\\ c_{31} &amp; c_{32} &amp; c_{33} &amp; 0 \\\\ c_{41} &amp; c_{42} &amp; c_{43} &amp; c_{44} \\\\ \\end{bmatrix} \\] where the diagonal elements \\(c_{11}, c_{22}, c_{33}, c_{44}\\) are nonzero. Remark: C is an example of an invertible lower triangular matrix: all the entries above the diagonal are zero. Explain why \\(CA=B\\). Next, you will show that the inverse matrix \\(C^{-1}\\) is also lower triangluar. Start with the matrix \\([ \\, C \\, | \\, I \\, ]\\) and perform Gaussian Elimination to put \\(C\\) into RREF to get the matrix \\([ \\, I \\, | \\, C^{-1} ]\\). Considering the lower triangular structure of \\(C\\), explain why putting \\(C\\) into \\(REF\\) actually results in the identity matrix \\(I\\). Use the previous three parts to show that we can factor \\(A=LU\\) where \\(L\\) is an invertible lower triangular matrix and \\(U\\) is an upper triangular matrix. Remark 1: You proved this for a \\(4 \\times 4\\) matrix, but your argument also works for an \\(n \\times n\\) matrix. Remark 2: If Gaussian Elimination of \\(A\\) requires row operation (E2) “exchange two rows” then we can choose to do those row swaps first. This corresponds to multiplying \\(A\\) by an invertible permutation matrix \\(P\\). We then perform Gaussian Elimination on \\(PA\\): we can factor \\(PA=LU\\) where \\(L\\) is lower triangular and \\(U\\) is upper triangular. This is called the \\(LU\\)-decomposition of \\(A\\). Remark 3: It turns out that explicitly calculating \\(A^{-1}\\) can lead to some very problematic rounding errors. So most solvers use the \\(LU\\)-decomposition to solve \\(A \\mathsf{x} = \\mathsf{b}\\) instead of calculating \\(\\mathsf{x} = A^{-1}\\mathsf{b}\\). More specifically, we replace \\(A \\mathsf{x} = \\mathsf{b}\\) with \\(LU \\mathsf{x} = P^{-1} \\mathsf{b}\\) and then solve this in two steps. First, we solve \\(L \\mathsf{y} = P^{-1}\\mathsf{b}\\). Because \\(L\\) is lower triangular, this runs exactly like ``back substitution.’’ Next, we solve \\(U \\mathsf{x} = \\mathsf{y}\\). Because \\(L\\) is upper triangular, this also runs like ``back substitution.’’ Remark 4: So what can go wrong when computing \\(A^{-1}\\)? Sometimes an invertible matrix is ill-conditioned which means that the rounding errors get in the way of the numerical calculation of the inverse. (Basically: you end up dividing by a number really close to 0.) The \\(LU\\) methodology avoids this problem. You can learn more about this in MATH 365 Computational Linear Algebra. 4.4 Homogeneous Coordinates I made the following nature scene with a bird and a palm tree. bird = rbind(c(20, 21.3, 23.3, 21.6, 20.7, 21.7, 20.9, 20.3, 18.9, 18.1, 18.3, 19.6, 19.2, 19.1, 19.2, 19.4, 20), c(20, 21.7, 20.9, 21.1, 19.3, 18.7, 18, 18.9, 18, 15.4, 18.6, 19.6, 20, 20.2, 20.3, 20.3, 20), c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)) fronds = rbind(c(10, 8, 6, 4, 2, 2.5, 4, 6, 9, 10, 10, 9, 7, 5, 2.5, 4, 6, 8, 9, 10, 10, 11, 11, 10.5, 12, 12.5, 12.5, 10, 10, 13, 15, 15.5, 15.5, 14, 12, 10, 10, 12, 14, 14, 13.5, 13, 12, 10), c(16, 16, 16, 15, 11, 15, 17, 17.5, 17, 16, 16, 17.5, 19, 19.5, 18.5, 20, 20.5, 20, 19, 16, 16, 18, 20, 20.5, 20, 19, 18, 16, 16, 17, 16, 15, 13.5, 15, 16, 16, 16, 15, 13, 11, 9, 11, 13, 16), c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)) trunk = rbind(c(10, 9, 8, 7.5, 7.5, 8, 10, 8, 6.5, 6, 5, 5, 6, 7, 10), c(16, 14, 12, 10, 8, 5, 2.5, 2, 2, 3, 6, 9, 12, 14, 16), c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)) # intialize the plot plot(bird[1,],bird[2,],type=&quot;n&quot;,xlim=c(0,25),ylim=c(0,25),xlab=&quot;x&quot;,ylab=&quot;y&quot;) abline(h=0:25, v=0:25, col=&quot;gray&quot;, lty=&quot;dotted&quot;) # plot the bird, trunk and fronds polygon(bird[1,], bird[2,], col = &quot;gray&quot;, border = &quot;blue&quot;) polygon(fronds[1,], fronds[2,], col = &quot;orange&quot;, border = &quot;black&quot;) polygon(trunk[1,], trunk[2,], col = &quot;brown&quot;, border = &quot;black&quot;) However, I’ve decided that I want to make some changes. I want to rotate the bird by \\(-\\pi/2\\) around the point \\((20,20)\\) where its head meets its wing. I want to enlarge the fronds (leaves) of the plam tree to be bigger by \\(25\\%\\). I like the trunk just as it is (no changes!), so the fronds should still meet at the point \\((10,16)\\). I want to change the colors to make it happier. For example, here is what I want it to look like (though maybe there is a better color choice). However, I’m not sure how to do this because: I only know how to rotate vectors around the point \\((0,0)\\). So how can I rotate around the point \\((20,20)\\)? Likewise, I only know how to expand vectros from the point \\((0,0)\\). So how can I expand outward from the point \\((10,16)\\)? I heard someone say that translations via homogeneous coordinates will help to solve my problem. But I’m not sure what to do. Help! Please submit: The numerical \\(3 \\times 3\\) matrix birdmap that you used for the bird, and an explanation of how you made it. The numerical \\(3 \\times 3\\) matrix leafmap that you used for the leaves, and an explanation of how you made it. Your resulting plot where you use happier colors of your choice that are unique to you and express your personal style. (An artist statement is optional.) For your convenience, here is some template code for you. Once you fill in the proper transformation, this code will make the final picture. Currently, it updates the colors, but doesn’t change the bird or the fronds (because it is using the identity transformation). ##################### ######## update this code with the appropriate linear transformations birdmap = cbind(c(1,0,0),c(0,1,0),c(0,0,1)) leafmap = cbind(c(1,0,0),c(0,1,0),c(0,0,1)) ##################### ######## you do not need to change this the code below this line newbird = birdmap %*% bird newfronds = leafmap %*% fronds # initialize the plot plot(newbird[1,],newbird[2,],type=&quot;n&quot;,xlim=c(0,25),ylim=c(0,25),xlab=&quot;x&quot;,ylab=&quot;y&quot;) abline(h=0:25, v=0:25, col=&quot;gray&quot;, lty=&quot;dotted&quot;) polygon(newbird[1,], newbird[2,], col = &quot;cyan&quot;, border = &quot;blue&quot;) polygon(newfronds[1,], newfronds[2,], col = &quot;green&quot;, border = &quot;black&quot;) polygon(trunk[1,], trunk[2,], col = &quot;brown&quot;, border = &quot;black&quot;) Finally, here is some R code that might be helpful. It overlays the original and the new version, so that you can directly compare them. Here is what the final comparison should look like: # initialize the plot plot(newbird[1,],newbird[2,],type=&quot;n&quot;,xlim=c(0,25),ylim=c(0,25),xlab=&quot;x&quot;,ylab=&quot;y&quot;) abline(h=0:25, v=0:25, col=&quot;gray&quot;, lty=&quot;dotted&quot;) # plot the new bird and new fronds polygon(newbird[1,], newbird[2,], col = &quot;gray&quot;, border = &quot;blue&quot;) polygon(newfronds[1,], newfronds[2,], col = &quot;orange&quot;, border = &quot;black&quot;) # plot the original bird, fronds and trunk polygon(bird[1,], bird[2,], col = &quot;cyan&quot;, border = &quot;blue&quot;) polygon(fronds[1,], fronds[2,], col = &quot;green&quot;, border = &quot;black&quot;) polygon(trunk[1,], trunk[2,], col = &quot;brown&quot;, border = &quot;black&quot;) Remark: This truly is how computer animation works! We use different effects for each object, and need to use homogeneous coordinates to get our desired results. "],["problem-set-5.html", "Vector 5 Problem Set 5 5.1 A Subspace from Two Linear Transformations 5.2 Getting Into a Subspace 5.3 Creating a Basis from Another Basis. 5.4 A Vector that is in Both Col(A) and Nul}(A) 5.5 Changing Coordinate Systems", " Vector 5 Problem Set 5 Due: Friday November 20 by 11:55pm CST. Upload your solutions to Moodle in a PDF. Please feel free to use RStudio for all row reductions. You can download the Rmd source file for this problem set. The Problem Set covers sections 4.1, 4.2, 4.3 and 4.4. 5.1 A Subspace from Two Linear Transformations Suppose that \\(T: \\mathbb{R}^n \\to \\mathbb{R}^m\\) and \\(S: \\mathbb{R}^n \\to \\mathbb{R}^m\\) are linear transformations. Let \\(V \\subset \\mathbb{R}^n\\) be the set \\[ V = \\{ \\mathsf{v} \\in \\mathbb{R}^n\\mid T(\\mathsf{v}) = S(\\mathsf{v}) \\}. \\] Prove that the set \\(V\\) is a subspace by showing that: If \\(\\mathsf{v} \\in V\\) and \\(\\mathsf{w} \\in V\\) then \\(\\mathsf{v}+\\mathsf{w} \\in V\\) If \\(\\mathsf{v} \\in V\\) and \\(c \\in \\mathbb{R}\\) then \\(c \\mathsf{v} \\in V\\) 5.2 Getting Into a Subspace Let \\(S \\subset \\mathbb{R}^n\\) be a subspace and let \\(\\mathsf{v}, \\mathsf{w} \\in \\mathbb{R}^n\\). For each of the following statements, either give a specific example or explain why it cannot happen. If \\(\\mathsf{v}\\) is in \\(S\\) but \\(\\mathsf{w}\\) is not in \\(S\\), can \\(\\mathsf{v} + \\mathsf{w}\\) be in \\(S\\)? If \\(\\mathsf{v}\\) is not in \\(S\\) and \\(\\mathsf{w}\\) is not in \\(S\\), can \\(\\mathsf{v} + \\mathsf{w}\\) be in \\(S\\)? If \\(\\mathsf{v}\\) is not in \\(S\\) and \\(c\\) is a nonzero constant, can \\(c\\mathsf{v}\\) be in \\(S\\)? 5.3 Creating a Basis from Another Basis. Suppose that \\(\\mathsf{v}_1, \\mathsf{v}_2, \\mathsf{v}_3\\) is a basis of \\(\\mathbb{R}^3\\). Let \\[ \\mathsf{w}_1 = \\mathsf{v}_1, \\quad \\mathsf{w}_2 = \\mathsf{v}_1 + \\mathsf{v}_2, \\quad \\mathsf{w}_3= \\mathsf{v}_1 + \\mathsf{v}_2 + \\mathsf{v}_3. \\] Prove that \\(\\mathsf{w}_1, \\mathsf{w}_2, \\mathsf{w}_3\\) is also a basis for \\(\\mathbb{R}^3\\) as follows: Show that \\(\\mathsf{w}_1, \\mathsf{w}_2, \\mathsf{w}_3\\) are linearly independent as follows: We know that whenever \\(a_1 \\mathsf{v}_1 + a_2 \\mathsf{v}_2 + a_3 \\mathsf{v}_3 = \\mathbf{0}\\), this means that \\(a_1 = a_2 = a_3 = 0\\). Now consider a linear combination \\(b_1 \\mathsf{w}_1 + b_2 \\mathsf{w}_2 + b_3 \\mathsf{w}_3 = \\mathbf{0}\\). Use the previous fact to show that \\(b_1 = b_2 = b_3 = 0\\). Show that \\(\\mathsf{w}_1, \\mathsf{w}_2, \\mathsf{w}_3\\) span \\(\\mathbb{R}^3\\) as follows: We know that for any \\(\\mathsf{b} \\in \\mathbb{R}^3\\), there exist \\(a_1, a_2, a_3 \\in \\mathbb{R}\\) such that \\(\\mathsf{b} = a_1 \\mathsf{v}_1 + a_2 \\mathsf{v}_2 + a_3 \\mathsf{v}_3\\). Use the previous fact to show that there also exist \\(c_1, c_2, c_3 \\in \\mathbb{R}\\) such that \\(\\mathsf{c} = b_1 \\mathsf{w}_1 + b_2 \\mathsf{w}_2 + b_3 \\mathsf{w}_3\\). 5.4 A Vector that is in Both Col(A) and Nul}(A) Give a \\(3 \\times 3\\) matrix \\(A\\) for which the vector \\(\\mathsf{v} = \\begin{bmatrix}3 \\\\ -2 \\\\ 5 \\end{bmatrix}\\) is in both \\(\\mathrm{Col}(A)\\) and \\(\\mathrm{Nul}(A)\\). Be sure to demonstrate that \\(\\mathsf{v} \\in \\mathrm{Col}(A)\\) and \\(\\mathsf{v} \\in \\mathrm{Nul}(A)\\). 5.5 Changing Coordinate Systems Here are three bases for \\(\\mathbb{R}^4\\): \\[\\begin{align} {\\cal S} &amp;= \\left\\{ \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\quad \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\quad \\begin{bmatrix} 0 \\\\0 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\quad \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix} \\right\\}, \\\\ \\\\ {\\cal B} &amp;= \\left\\{ \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}, \\quad \\begin{bmatrix} 1 \\\\ 1 \\\\ -1~ \\\\ -1~ \\end{bmatrix}, \\quad \\begin{bmatrix} 1 \\\\ -1~ \\\\ 0 \\\\ 0 \\end{bmatrix}, \\quad \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\ -1~ \\end{bmatrix} \\right\\}, \\\\ \\\\ {\\cal C} &amp;= \\left\\{ \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\quad \\begin{bmatrix} 1 \\\\ 1 \\\\ -1~ \\\\ 0 \\end{bmatrix}, \\quad \\begin{bmatrix} 1 \\\\ -1~ \\\\ 0 \\\\ 1 \\end{bmatrix}, \\quad \\begin{bmatrix} 1 \\\\ -1~ \\\\ 0 \\\\ -1~ \\end{bmatrix} \\right\\}. \\end{align}\\] Let \\(P_{\\cal B}\\) be the change-of-coordinates matrix from basis \\({\\cal B}\\) to the standard basis \\({\\cal S}\\), and let \\(P_{\\cal C}\\) be the change-of-coordinates matrix from basis \\({\\cal C}\\) to the standard basis \\({\\cal S}\\). Find \\(P_{\\cal B}^{-1}\\), which is the change-of-coordinates matrix from the standard basis \\({\\cal S}\\) to basis \\({\\cal B}\\). Find \\(P_{\\cal C}^{-1}\\), which is the change-of-coordinates matrix from the standard basis \\({\\cal S}\\) to basis \\({\\cal C}\\). Find the change-of-coordinates matrix from basis \\({\\cal B}\\) to basis \\({\\cal C}\\). Find the change-of-coordinates matrix from basis \\({\\cal C}\\) to basis \\({\\cal B}\\). Consider the vector \\(\\mathsf{v}\\) where \\[ [\\mathsf{v}]_{\\cal B} = \\begin{bmatrix} ~3.5 \\\\ -1.0 \\\\ -0.5 \\\\ ~1.5 \\end{bmatrix}_{\\cal B}.\\] Find \\([ \\mathsf{v} ]_{\\cal C}.\\) Then calculate both \\(P_{\\cal B} [\\mathsf{v}]_{\\cal B}\\) and \\(P_{\\cal C} [\\mathsf{v}]_{\\cal C}\\) to confirm that they both produce the same vector \\(\\mathsf{v} =[\\mathsf{v}]_{\\cal S}\\). Remark: Both \\(\\cal{B}\\) and \\(\\cal{C}\\) are examples of wavelet bases. Wavelets and similar bases are useful for image processing and image compression. "],["problem-set-6.html", "Vector 6 Problem Set 6 6.1 The Square Root of a Matrix? 6.2 A Matrix Mystery 6.3 Upper Triangular Matrix with a Constant Diagonal 6.4 Block Diagonalization of a \\(4 \\times 4\\) Matrix 6.5 Network Analysis of Risk Territories", " Vector 6 Problem Set 6 Due: Friday December 04 by 11:55pm CST. Upload your solutions to Moodle in a PDF. Please feel free to use RStudio for all calculations, including row reduction, matrix multiplication, eigenvector calculation and inverse matrices. You can download the Rmd source file for this problem set. The Problem Set covers sections 5.1, 5.2, 5.3, 5.5 and Network Analysis. 6.1 The Square Root of a Matrix? The matrix \\(A =\\begin{bmatrix} 7 &amp; 2 \\\\ -4 &amp; 1 \\end{bmatrix}\\) has characteristic polynomial \\(\\lambda^2 - 8 \\lambda + 15 = (\\lambda -3)(\\lambda - 5).\\) Describe the eigenspaces of \\(A\\). Diagonalize \\(A\\). Find a matrix that makes sense to call \\(\\sqrt{A}\\). Then show that when you square this matrix, you really do get matrix \\(A\\). 6.2 A Matrix Mystery An unknown \\(3 \\times 3\\) matrix \\(M\\) has eigenvectors and corresponding eigenvalues: \\[ \\mathsf{v}_1 = \\begin{bmatrix} 1 \\\\ 2 \\\\ 1 \\end{bmatrix}, \\ \\lambda_1 = 1; \\qquad \\mathsf{v}_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ 1 \\end{bmatrix},\\ \\lambda_2 = \\frac{9}{10}; \\qquad \\mathsf{v}_3 = \\begin{bmatrix} -1 \\\\ 1 \\\\ 0 \\end{bmatrix},\\ \\lambda_3 = 0. \\] Find (exactly, if possible, or approximately otherwise) the vector \\(M^{10} \\mathsf{v}\\) where \\(\\mathsf{v} = \\begin{bmatrix}7\\\\3\\\\4\\end{bmatrix}\\). Describe all vectors \\(\\mathsf{v}\\), if there are any, such that \\(M^{n} \\mathsf{v} \\to {\\bf 0}\\) as \\(n \\to \\infty\\). Is it possible to reconstruct \\(M\\) from the evidence given? If so, then do it! If not, explain what further information is needed. 6.3 Upper Triangular Matrix with a Constant Diagonal Let \\(A\\) be a \\(3 \\times 3\\) upper triangular matrix of the form \\[ A = \\begin{bmatrix} d &amp; a &amp; b \\\\ 0 &amp; d &amp; c \\\\ 0 &amp; 0 &amp; d \\end{bmatrix} \\] where \\(d \\neq 0\\) and at least one of \\(a,b,c\\) is nonzero. Explain why \\(A\\) is not diagonalizable. 6.4 Block Diagonalization of a \\(4 \\times 4\\) Matrix The \\(4 \\times 4\\) matrix \\[ A = \\begin{bmatrix} 2 &amp; -1 &amp; 1 &amp; -1 \\\\ 1 &amp; -3 &amp; 3 &amp; 2 \\\\ 2 &amp; -9 &amp; 7 &amp; 0 \\\\ 2 &amp; -4 &amp; 2 &amp; 0 \\end{bmatrix} \\] has complex eigenvalues \\(a \\pm bi\\) and \\(c \\pm di\\). Use RStudio to find the eigenvalues \\(a \\pm bi\\) and \\(c \\pm di\\), as well as “human friendly” eigenvectors \\(\\mathsf{v} = \\mathsf{v}_1 + i \\mathsf{v}_2\\) for eigenvalue \\(a + bi\\), and \\(\\mathsf{w} = \\mathsf{w}_1 + i \\mathsf{w}_2\\) for eigenvalue \\(c + di\\). Hint: the command zapsmall() might be helpful. This matrix A can be factored as \\(A = P B P^{-1}\\) where \\(B\\) is a “block diagonal” matrix of the form \\[ B = \\begin{bmatrix} a &amp; -b &amp; 0 &amp; 0 \\\\ b &amp; a &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; c &amp; -d \\\\ 0 &amp; 0 &amp; d &amp; c \\end{bmatrix} \\] and \\[ P = \\begin{bmatrix} \\mathrm{Im} (\\mathsf{v}) &amp; \\mathrm{Re} (\\mathsf{v}) &amp; \\mathrm{Im} (\\mathsf{w}) &amp; \\mathrm{Re}( \\mathsf{w}) \\end{bmatrix} =\\begin{bmatrix} \\mathsf{v}_2 &amp; \\mathsf{v}_1 &amp; \\mathsf{w}_2 &amp; \\mathsf{w}_1 \\end{bmatrix} \\] where the constants \\(a,b,c,d\\) and the vectors \\(\\mathsf{v}, \\mathsf{w}\\) are as described in part (a). Use RStudio to find the \\(4 \\times 4\\) matrices \\(B\\), \\(P\\) and its inverse \\(P^{-1}\\). Hints: You can use the command solve(M) to find the inverse of matrix \\(M\\). You can confirm that your answer is correct by computing \\(P B P^{-1}\\) and checking that this equals the original matrix \\(A\\). 6.5 Network Analysis of Risk Territories Risk is a classic board game of conflict and diplomacy played on a map of the world. Players try to capture territories by moving their armies through adjancent territories. Here is what the game map looks like, with the countries colored by continent. Risk Game Board (image: wikipedia) Here is a network representation of the gameboard, created from an adjacency matrix. library(igraph) risk &lt;- read.csv(&quot;https://raw.github.com/mathbeveridge/math236_f20/main/data/riskmatrix.csv&quot;) A = data.matrix(risk) countries = names(risk) g=graph_from_adjacency_matrix(A,mode=&#39;undirected&#39;) coords = layout_nicely(g) plot(g, layout=coords, vertex.size = 10, vertex.label.cex=0.75, vertex.color=&#39;khaki&#39;, vertex.frame.color=&quot;black&quot;) Calculate Gould’s Index for this network. Use this Gould’s Index ranking to identify the most central territory in each of the six continents in this worldwide network. Here is a list of territories by continent (Africa, Asia, Australia, Europe, North America, South America) to help you to classify the territories. Turn in a table with six rows. These six rows should be ordered by Gould’s index. Each row should contain: name of the continent name of the territory with the largest Gould Index, the degree of the territory, the Gould’s Index value for the territory. Important: You do not need to show your work for this problem! Just turn the table (handwritten is fine) of your results. "],["important-definitions.html", "Vector 7 Important Definitions", " Vector 7 Important Definitions span A set of vectors \\(\\mathsf{v}_1, \\mathsf{v}_2, \\ldots, \\mathsf{v}_n\\) span a vector space \\(V\\) if for every \\(\\mathsf{v} \\in V\\) there exist a set of scalars (weights) \\(c_1, c_2, \\ldots, c_n \\in \\mathbb{R}\\) such that \\[ \\mathsf{v} = c_1 \\mathsf{v}_1 + c_2 \\mathsf{v}_2 + \\cdots + c_n \\mathsf{v}_n. \\] Connection to Matrices: If \\(A = [\\mathsf{v}_1 \\mathsf{v}_2 \\cdots \\mathsf{v}_n]\\) is the matrix with these vectors in the columns, then this is the same as saying that \\(\\mathsf{x} = [c_1, \\ldots, c_n]^{\\top}\\) is a solution to \\(A x = \\mathsf{v}\\). linear independence A set of vectors \\(\\mathsf{v}_1, \\mathsf{v}_2,\\ldots, \\mathsf{v}_n\\) are linearly independent if the only way to write \\[ \\mathsf{0} = c_1 \\mathsf{v}_1 + c_2 \\mathsf{v}_2 + \\cdots + c_n \\mathsf{v}_n \\] is with \\(c_1 = c_2 = \\cdots = c_n = 0\\). Connection to Matrices: If \\(A = [\\mathsf{v}_1 \\mathsf{v}_2 \\cdots \\mathsf{v}_n]\\) is the matrix with these vectors in the columns, then this is the same as saying that \\(A x = \\mathsf{0}\\) has only the trivial solution. linear dependence Conversely, a set of vectors \\(\\mathsf{v}_1, \\mathsf{v}_2, \\ldots, \\mathsf{v}_n\\) are linearly dependent if there exist scalars \\(c_1, c_2,\\ldots, c_n \\in \\mathbb{R}\\) that are not all equal to 0 such that \\[ \\mathsf{0} = c_1 \\mathsf{v}_1 + c_2 \\mathsf{v}_2 + \\cdots + c_n \\mathsf{v}_n \\] This is called a dependence relation among the vectors. Connection to Matrices: If \\(A = [\\mathsf{v}_1 \\mathsf{v}_2 \\cdots \\mathsf{v}_n]\\) is the matrix with these vectors in the columns, then this is the same as saying that \\(\\mathsf{x} = [c_1, c_2, \\ldots, c_n]^{\\top}\\) is a nontrivial solution to \\(A \\mathsf{x} = \\mathsf{0}\\). linear transformation A function \\(T: \\mathbb{R}^n \\to \\mathbb{R}^m\\) is a linear transformation when: \\(T(\\mathsf{u} + \\mathsf{v}) = T(\\mathsf{u}) + T(\\mathsf{v})\\) for all \\(\\mathsf{u}, \\mathsf{v} \\in \\mathbb{R}^n\\) (preserves addition) \\(T(c \\mathsf{u} ) = c T(\\mathsf{u})\\) for all \\(\\mathsf{u} \\in \\mathbb{R}^n\\) and \\(c \\in \\mathbb{R}\\) (preserves scalar multiplication). It follows from these that also \\(T(\\mathsf{0}) = \\mathsf{0}\\). one-to-one A function \\(T: \\mathbb{R}^n \\to \\mathbb{R}^m\\) is a one-to-one when: for all \\(\\mathsf{y} \\in \\mathbb{R}^m\\) there is at most one \\(\\mathsf{x} \\in \\mathbb{R}^n\\) such that \\(T(\\mathsf{x}) = \\mathsf{y}\\). onto A function \\(T: \\mathbb{R}^n \\to \\mathbb{R}^m\\) is a onto when: for all \\(\\mathsf{y} \\in \\mathbb{R}^m\\) there is at least one \\(\\mathsf{x} \\in \\mathbb{R}^n\\) such that \\(T(\\mathsf{x}) = \\mathsf{y}\\). subspace A subset \\(S \\subseteq \\mathbb{R}^n\\) is a subspace when: \\(\\mathsf{u} + \\mathsf{v} \\in S\\) for all \\(\\mathsf{u}, \\mathsf{v} \\in S\\) (closed under addition) \\(c \\mathsf{u} \\in S\\) for all \\(\\mathsf{u}\\in S\\) and \\(c \\in \\mathbb{R}\\) (closed under scalar multiplication) It follows from these that also \\(\\mathsf{0} \\in S\\). basis A basis of a vector space (or subspace) \\(V\\) is a set of vectors \\(\\mathcal{B} = \\{\\mathsf{v}_1, \\mathsf{v}_2, \\ldots, \\mathsf{v}_n\\}\\) in \\(V\\) such that \\(\\mathsf{v}_1, \\mathsf{v}_2, \\ldots, \\mathsf{v}_n\\) span \\(V\\) \\(\\mathsf{v}_1, \\mathsf{v}_2, \\ldots, \\mathsf{v}_n\\) are linearly independent Equivalently, one can say that \\(\\mathcal{B} = \\{\\mathsf{v}_1, \\mathsf{v}_2, \\ldots, \\mathsf{v}_n\\}\\) is a basis of \\(V\\) if for every vector \\(\\mathsf{v} \\in V\\) there is a unique set of scalars \\(c_1, \\ldots, c_n\\) such that \\[ \\mathsf{v} = c_1 \\mathsf{v}_1 + c_2 \\mathsf{v}_2 + \\cdots + c_n \\mathsf{v}_n. \\] (the fact that there is a set of vectors comes from the span; the fact that they are unique comes from linear independence). "],["week-1-learning-goals.html", "Vector 8 Week 1 Learning Goals 8.1 Solving Linear Equations 8.2 Vocabulary 8.3 Conceptual Thinking 8.4 RStudio", " Vector 8 Week 1 Learning Goals Here are the knowledge and skills you should master by the end of this first, shorter week. 8.1 Solving Linear Equations I should be able to do the following tasks: Identify linear systems from nonlinear systems Create a linear system to solve a variety of applied scenarios Convert between a linear system and an augmented matrix Row reduce an augmented matrix into Row Echelon Form (REF) and Reduced Row Echelon Form (RREF) Use REF to determine whether a linear system is consistent or inconsistent Use REF to determine whether a consistent system has a unique solution or an infinite number of solutions Use RREF to find explicit equations for the solution set of a consistent system 8.2 Vocabulary I should know and be able to use and explain the following terms: elementary row operation (and be able to state them) augmented matrix REF and RREF pivot position basic variable (pivot variable) free variable consistent system and inconsistent system 8.3 Conceptual Thinking I should understand and be able to perform the following conceptual tasks: Model 2-dimensional linear systems as the intersections of lines Model 3-dimensional linear systems as the intersections of planes 8.4 RStudio Log in to Macalester’s RStudio server Upload R Markdown files to RStudio Knit R Markdown to produce HTML Use RStudio to create vectors and matrices Use the rref command from pracma to solve a linear system "],["week-2-learning-goals.html", "Vector 9 Week 2 Learning Goals 9.1 Solution Sets, Span and Linear Independence 9.2 Vocabulary 9.3 Conceptual Thinking", " Vector 9 Week 2 Learning Goals Here are the knowledge and skills you should master by the end the second week. 9.1 Solution Sets, Span and Linear Independence You should be able to do the following tasks: Go back and forth between (i) systems of equations, (ii) vector equations, and (iii) the matrix equation \\(Ax = b\\). Compute and understand the matrix-vector product \\(A x\\) both as a linear combination of the columns of A and as the dot product of \\(x\\) with the rows of \\(A\\). Write the solution set to \\(Ax=b\\) as a parametric vector equation. Determine whether a set of vectors is linearly dependent or independent Find a dependence relation among a set of vectors Decide if a set of vectors span \\(\\mathbb{R}^n\\) 9.2 Vocabulary You should know and be able to use and explain the following terms or properties. \\(A(x + y) = Ax + Ay\\) and \\(A(c x) = c A x\\) homogeneous and nonhomogeneous equations parametric vector equations linear independence and linear dependence 9.3 Conceptual Thinking I should understand and be able to explain the following concepts: Theorem 4 in Section 1.4 which says that the following are equivalent (they are all true or are all false) for an \\(m \\times n\\) matrix \\(A\\) For each \\(b \\in \\mathbb{R}^m\\), the system \\(A x = b\\) has at least one solution Each \\(b \\in \\mathbb{R}^m\\) is a linear combination of the columns of \\(A\\) The columns of \\(A\\) span \\(\\mathbb{R}^m\\) \\(A\\) has a pivot in every row. Understand the relation between homogeneous solutions and nonhomogeneous solutions. Linear independence Span More than \\(n\\) vectors in \\(\\mathbb{R}^n\\) must be linearly dependent. "],["week-3-learning-goals.html", "Vector 10 Week 3 Learning Goals 10.1 Linear Transformations and Matrix Inverses 10.2 Vocabulary 10.3 Conceptual Thinking", " Vector 10 Week 3 Learning Goals Here are the knowledge and skills you should master by the end the third week. 10.1 Linear Transformations and Matrix Inverses You should be able to do the following tasks: Determine whether a mapping from \\(\\mathbb{R}^n\\) to \\(\\mathbb{R}^n\\) is a linear transformation. Use the RREF of the corresponding matrix to determine whether \\(T(\\mathsf{x})\\) is one-to-one and/or onto. Describe 2D linear transformations as a mixture of geometric operations, including expansion, contraction, reflection, rotation, shearing and dimension reduction. Perform a 2D translation using 3D homogeneous coordinates. Multiply an \\(m \\times n\\) matrix with an \\(n \\times p\\) matrix to get an \\(m \\times p\\) matrix. Determine whether a \\(2 \\times 2\\) matrix is invertible. Find the inverse of a \\(2 \\times 2\\) matrix by hand. Use RStudio to check for invertiblity and to find the inverse of an \\(n \\times n\\) square matrix. Explain the connection between Gaussian Elimination, elementary matrices, and the matrix inverse. 10.2 Vocabulary You should know and be able to use and explain the following terms or properties. Linear Transformation: \\(T(a \\mathsf{u} + b \\mathsf{v}) = a T(\\mathsf{u}) + b T(\\mathsf{v})\\) domain, codomain (aka target) and range (aka image) \\(T\\) maps vector \\(\\mathsf{x}\\) to its image \\(T(\\mathsf{x})\\) one-to-one onto standard matrix for a linear transformation homogeneous coordinates transpose of a matix invertible matrix elementary matrices 10.3 Conceptual Thinking I should understand and be able to explain the following concepts: A linear transformation \\(T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\\) corresponds to multiplication by an \\(m \\times n\\) matrix \\(A\\). \\(T(\\mathsf{x})=\\mathsf{A} \\mathsf{x}\\) is a one-to-one linear transformations if and only \\(\\mathsf{A}\\) has linearly independent columns \\(T(\\mathsf{x})=\\mathsf{A} \\mathsf{x}\\) is an onto linear transformations if and only if the columns of \\(\\mathsf{A}\\) span \\(\\mathbb{R}^m\\). The Invertible Matrix Theorem (Section 2.3, Theorem 8, page 112) is one of the highlights of the course! It gives 12 different conditions that all equivalent! You should think deeply about why everything comes together like this for square matrices. "],["week-4-learning-goals.html", "Vector 11 Week 4 Learning Goals 11.1 Vector Spaces and the Determinant 11.2 Vocabulary 11.3 Conceptual Thinking", " Vector 11 Week 4 Learning Goals Here are the knowledge and skills you should master by the end of the fourth week. 11.1 Vector Spaces and the Determinant You should be able to do the following tasks: Prove/disprove that a subset of a vector space is a subspace. Prove/disprove that a set of vectors is linearly dependent. Prove/disprove that a set of vectors span a vector space (or a subspace). Find the kernel and image of \\(T(\\mathsf{x}) = Ax\\). Determine whether a set of vectors is a basis. Find a basis for \\(\\mathrm{Nul}(A)\\) and a basis for \\(\\mathrm{Col}(A)\\). Find the change-of-coordinate matrix \\(P_{\\mathcal{B}}\\) from basis \\({\\mathcal{B}}\\) to the standard basis \\(\\mathcal{S}\\). Use matrix inverses (and RStudio) to find the change-of-coordinate matrix \\(P_{\\mathcal{B}}^{-1}\\) from basis \\({\\mathcal{S}}\\) to the standard basis \\(\\mathcal{B}\\). Find the coordinate vector with respect to a given basis. Find the dimension of a vector space (or subspace) by finding or verifying a basis. Find the determinant of a \\(2 \\times 2\\) matrix by hand. Find the determinant of a \\(3 \\times 3\\) matrix by using row operations/cofactor expansion/permutation method. Use RStudio to calculate the determinant of a square matrix. Use \\(\\det(A)\\) to decide whether the square matrix \\(A\\) is invertible. 11.2 Vocabulary You should know and be able to use and explain the following terms or properties. Every one of these Important Definitions Subspace Null space and column space of a matrix Kernel and Image of a linear transformation Basis Coordinate vector with respect to a basis Change-of-coordinates matrix The coordinate vector with respect to a basis The dimension of a vector space (or a subspace) Determinant 11.3 Conceptual Thinking I should understand and be able to explain the following concepts: A vector space consists of a collection of vectors and all of their linear combinations. A subspace is a subset of a vector space that is also a vector space by itself (closed under linear combinations). The solutions to \\(A \\mathsf{x} = \\mathbb{0}\\) form a subspace. The span of the columns of \\(A\\) form a subspace. How the kernel and image of \\(T(\\mathsf{x}) = Ax\\) correspond to the nullspace and columnspace of \\(A\\). Every basis of a given vector space (or subspace) contains the same number of vectors. Why every vector in a vector space has a unique representation as a linear combination of a given basis \\({\\mathcal{B}}\\). How dimension relates to span and linear independence. Interpret \\(\\det(A)\\) as a measure the expansion/contraction of “volumes” in \\(\\mathbb{R}^n\\) under the linear transformation \\(T(\\mathsf{x})=A\\mathsf{x}\\). "],["linear-systems-in-r.html", "Vector 12 Linear Systems in R 12.1 Building Vectors and Matrices 12.2 Solving a Linear System 12.3 Solving another Linear System 12.4 Appendix: Dimensionless Vectors in R", " Vector 12 Linear Systems in R Let’s learn how to use R to solve systems of linear equations! Download this Rmd file. First, we will create vectors and matrices Then we will see how to create an augmented matrix and then apply Gaussian Elimination to obtain is reduced row echelon form. Gaussian elimination is performed by the rref() command. However, this command is not loaded into R by default. So we have have to tell RStudio to use the practical math package, which is known as pracma. So we need to run the following command once at the beginning of our session. 12.1 Building Vectors and Matrices A vector in R is a list of data. The simplest way to create a vector is to use the c() command. The letter ‘c’ is short for ‘combine these values into a vector.’ For example, we can make a vector v for the numbers 1,2,3 as follows: ## [1] 1 2 3 Note that we had to ask R to display the value of v. This is because the assignment of v doesn’t echo the value to the console. But can see the value of v in the Environment tab in the upper right panel of RStudio. For example, run this command and then check to see that the value of v gets updated in the environment. It is interesting to note that c() returns a dimensionless vector. So you can treat a vector c() as either a row or a column when you construct a matrix. For example, suppose that we want to make the matrix \\[ A = \\begin{bmatrix} 1 &amp; 1 &amp; 1 \\\\ 2 &amp; 4 &amp; 8 \\\\ 3 &amp; 9 &amp; 27 \\end{bmatrix}. \\] We could create this matrix by binding three row vectors: ## [,1] [,2] [,3] ## [1,] 1 1 1 ## [2,] 2 4 8 ## [3,] 3 9 27 or we could bind three column vectors: ## [,1] [,2] [,3] ## [1,] 1 1 1 ## [2,] 2 4 8 ## [3,] 3 9 27 12.2 Solving a Linear System Suppose that we want to solve the linear system \\[\\begin{aligned} x + y + z &amp;= 7 \\\\ 2x + 4y + 8z &amp;= 6 \\\\ 3x +9y+27z &amp;=12 \\end{aligned}\\] which has coefficient matrix \\[ A = \\begin{bmatrix} 1 &amp; 1 &amp; 1 \\\\ 2 &amp; 4 &amp; 8 \\\\ 3 &amp; 9 &amp; 27 \\end{bmatrix}. \\] and target (column) vector \\[ b = \\begin{bmatrix} 4 \\\\ 6 \\\\ 12 \\end{bmatrix}. \\] This is the same matrix A we defined above. Let’s define a vector b and use cbind() to create an augmented matrix which we will name Ab. (We could have just made the full augmented matrix from the start, but using cbind to add a column to a matrix is a skill we will use later in the course!) ## [,1] [,2] [,3] ## [1,] 1 1 1 ## [2,] 2 4 8 ## [3,] 3 9 27 ## b ## [1,] 1 1 1 4 ## [2,] 2 4 8 6 ## [3,] 3 9 27 12 Now we use the rref() command to apply Gaussian Elimination to produce the reduced row echelon form. (And remember: we had to load this function into R by using the require(pracma) command above.) ## b ## [1,] 1 0 0 7 ## [2,] 0 1 0 -4 ## [3,] 0 0 1 1 We conclude that this is a consistent system no free variables. The unique solution is \\[\\begin{align} x&amp;=7\\\\ y&amp;=-4\\\\ z&amp;=1 \\end{align}\\] We can verify that our answer works by multiplying \\(A\\) by one of the solutions above. Matrix multiplication uses the funny operation %*%. ## [,1] ## [1,] 4 ## [2,] 6 ## [3,] 12 Which matches our target \\[ b = \\begin{bmatrix} 4 \\\\ 6 \\\\ 12 \\end{bmatrix} \\] just as we had hoped. 12.3 Solving another Linear System Now let’s find the solution set for the linear system \\[ \\begin{array}{rrrrrcr} x_1 &amp; &amp; -x_3 &amp; -x_4 &amp; -x_5 &amp; = &amp; -2 \\\\ 2x_1 &amp; +x_2 &amp; +2x_3 &amp; -x_4 &amp; -x_5 &amp; = &amp; 4 \\\\ -x_1 &amp; +x_2 &amp; +x_3 &amp; &amp; &amp; = &amp; 10 \\\\ x_1 &amp; &amp; -x_3 &amp; -x_4 &amp; -x_5 &amp; = &amp; -2 \\\\ \\end{array} \\] which corresponds to augmented matrix \\[ \\left[ \\begin{array}{rrrrr|r} 1 &amp; &amp; -1 &amp; -1 &amp; -1 &amp; -2 \\\\ 2 &amp; +1 &amp; +2 &amp; -1 &amp; -1 &amp; 4 \\\\ -1 &amp; +1 &amp; +1 &amp; &amp; &amp; 10 \\\\ 1 &amp; &amp; -1 &amp; -1 &amp; -1 &amp; -2 \\\\ \\end{array} \\right] \\] This time, let’s just construct the augmented matrix direclty. Then we define the coefficient matrix \\(A\\). Here we use cbind to combine the vectors into the columns of a matrix named \\(A\\). You can use rbind if you want to combine the vectors into the rows of a matrix. ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 1 0 -1 -1 -1 -2 ## [2,] 2 1 2 1 5 10 ## [3,] -1 1 1 0 0 4 ## [4,] 1 0 -1 -1 -1 -2 And now let’s row reduce to get RREF. ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 1 0 0 0 1 1 ## [2,] 0 1 0 -1 -1 2 ## [3,] 0 0 1 1 2 3 ## [4,] 0 0 0 0 0 0 So the set of solutions in parametric form is \\[ \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 0 \\\\ 0 \\end{bmatrix} + s \\begin{bmatrix} 0 \\\\ 1 \\\\ -1 \\\\ 1 \\\\ 0 \\end{bmatrix} + t \\begin{bmatrix} -1 \\\\ 1 \\\\ -2 \\\\ 0 \\\\ 1 \\end{bmatrix} \\] and this is a “plane” in \\(\\mathbb{R}^5\\). It is in \\(\\mathbb{R}^5\\) because these vectors have 5 coordinates. It is a plane because it is spanned by two vectors that are not on the same line. 12.4 Appendix: Dimensionless Vectors in R Let’s revisit the vector constructed by cbind. Above we called this a “dimensionless” vector because it can be used as a column vector or a row vector. In general, R will do its best to make sense of a dimensionless vector. In other words, it will promote c() to make an expression valid. For example, let \\(A\\) be an \\(n \\times n\\) matrix, and let \\(b\\) be a vector. The expression \\(Av\\) is only defined when \\(v\\) is a \\(n \\times 1\\) column vector and that \\(wA\\) is only defined when \\(w\\) is a \\(1 \\times n\\) ** row vector**. But let’s look at what happens when we use a dimensionless vector instead. ## [,1] [,2] [,3] ## [1,] 1 -1 0 ## [2,] 1 0 1 ## [3,] 1 1 -1 ## [1] 2 5 11 ## [,1] ## [1,] -3 ## [2,] 13 ## [3,] -4 ## [,1] [,2] [,3] ## [1,] 18 9 -6 Both of these multiplications worked! So R treated b as a column vector for the multiplicationA %*% b. And then R treated b as a row vector for the multiplication b %b% A. So how do you make a true column vector or a true row vector? The answer is to use cbind and rbind! Here are some examples: ## [1] 1 2 3 4 ## b ## [1,] 1 ## [2,] 2 ## [3,] 3 ## [4,] 4 ## [,1] [,2] [,3] [,4] ## b 1 2 3 4 "],["d-linear-transformations.html", "Vector 13 2D Linear Transformations 13.1 Functions to plot our vectors 13.2 Your Turn 13.3 Exploration 13.4 Even More Exploration", " Vector 13 2D Linear Transformations Let’s explore linear transformations of the plane! Download this Rmd file. We know that a linear transformation \\(T\\) satisfies \\[ T(c \\mathsf{u} + d \\mathsf{v}) = c\\, T( \\mathsf{u}) +d \\, T( \\mathsf{v}). \\] But what do linear transformations look like? Let’s start to answer this question by considering linear transformations of the plane. We will look at mappings \\(T: \\mathbb{R}^2 \\rightarrow \\mathbb{R}^2\\) where \\(T(\\mathsf{x}) = \\mathsf{A} \\mathsf{x}\\) for a \\(2 \\times 2\\) matrix \\(\\mathsf{A}\\). \\[ T \\left( \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\right) = \\begin{bmatrix} a_{11} &amp; a_{12} \\\\ a_{21} &amp; a_{22} \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix}. \\] The linear transformation \\(T(\\mathsf{x})\\) maps the plane to itself. This nicely allows us to compare vectors before the mapping with their images after the mapping. We can then describe the effect of the mapping on the plane. 13.1 Functions to plot our vectors Here are a couple of helper functions to plot our “before” and “after” vectors as arrows in the plane. This function has four parameters. The parameters before1 and before2 are two vectors before the mapping, and after1 and after2 are their images after the mapping. The function creates a dashed plot of the parallelogram with corners (0,0), before1, before2 and before1+before2. It also creates a solid plot of the image of this parallelogram. These are plotted on the same plane so taht we can easily compare “before” and “after.” Here is an example. Let’s start with vectors \\(\\begin{bmatrix} 3 \\\\ 0 \\end{bmatrix}\\) and \\(\\begin{bmatrix} 0 \\\\ 2 \\end{bmatrix}\\). It’s nice to start with vectors of different lengths. Let’s consider the mapping correspoding to multiplication by the matrix \\[ A = \\begin{bmatrix} 2 &amp; 3 \\\\ 4 &amp; -1 \\end{bmatrix}. \\] Here is some example code showing how to make our plot. Note: A %*% x is the syntax for matrix multiplication in R. Figure 13.1: An example 2D linear transformation This visualization uses different colors for the vectors so that you can match up the original vector with its image. There is a lot going on in this mapping, so let’s start making some observations. The original rectangle mapped to a parallelogram. So the shape is ``squished’’ a bit. Both the black vector and the red vector have gotten larger. But we can see that the red vector has grown much more than the black one. So there is expansion, but it is not uniform. The black vector and the red vector have flipped! This means that there is some sort of reflection happening. There isn’t a simple description for what’s happening here. It’s a combination of effects, so that the image of the rectangle is a warped version of the original. 13.2 Your Turn Now it’s your turn. Investigate the effect of each of the following families of mappings. Using the previous code snippet as a guide, create a “before and after plot” for the black vector \\(\\begin{bmatrix} 3 \\\\ 0 \\end{bmatrix}\\) and the red vector \\(\\begin{bmatrix} 0 \\\\ 2 \\end{bmatrix}\\) Describe the effect of the mapping as best you can. Be sure to look at the different effect on the black vector and the red vector. Use words like, expansion, contraction, rotation, reflection and shear. Once you have looked at the effect of the family, look back at the form of the matrix \\(A\\). Can you explain why it leads to the outcome you see? 13.2.1 Family 1 Explore matrices of the form \\[A=\\displaystyle{ \\begin{bmatrix} a &amp; 0 \\\\ 0 &amp; b \\end{bmatrix}}.\\] Once again, try various combinations of positive, negative, small and large numbers. Here is some sample code that would create such a matrix for \\(a=1\\) and \\(b=1\\). 13.2.2 Family 2 Explore matrices of the form \\[A=\\displaystyle{ \\begin{bmatrix} 0 &amp; b \\\\ c &amp; 0 \\end{bmatrix}}.\\] Try various combinations of positive and negative numbers. Also try numbers of small magnitude (less than 1) and large magnitude. 13.2.3 Family 3 Explore matrices of the form \\[A=\\displaystyle{ \\begin{bmatrix} \\cos(t) &amp; -\\sin(t) \\\\ \\sin(t) &amp; \\cos(t) \\end{bmatrix}}\\] where \\(t\\) is in radians. Here is a function that will create such a matrix. ## [,1] [,2] ## [1,] 6.123234e-17 -1.000000e+00 ## [2,] 1.000000e+00 6.123234e-17 Note: R is numerical software. You’ll note that sin(pi/2) returns a value of 6.123234e-17 or something similar. This value is given in scientific notation, and is \\(\\approx 6.12 \\times 10^{-17}\\). You should treat this tiny number as equal to 0. Be sure to keep an eye out for return values like this that are ``numerically equivalent to 0.’’ 13.2.4 Family 4 Now explore matrices of the form \\[A=\\displaystyle{ \\begin{bmatrix} a &amp; -b \\\\ b &amp; a \\end{bmatrix}}\\] Once again, consider a wide variety of such matrices. 13.2.5 Some Other Matrices Now try these matrices. For each one, try to make other matrices that have a similar effect. (What is the relationship between the entries that leads to this particular kind of image?) \\[ A=\\displaystyle{ \\begin{bmatrix} 1 &amp; -3 \\\\ 2 &amp; -6 \\end{bmatrix}}, \\qquad B=\\displaystyle{ \\begin{bmatrix} 1 &amp; 1 \\\\ 0 &amp; 1 \\end{bmatrix}}, \\qquad C=\\displaystyle{ \\begin{bmatrix} 0 &amp; 1 \\\\ 0 &amp; 0 \\end{bmatrix}}, \\qquad D=\\displaystyle{ \\begin{bmatrix} 3 &amp; 0 \\\\ 3 &amp; 2 \\end{bmatrix}}, \\qquad \\] 13.3 Exploration Now it’s time to explore. Try one or more of the following: Can you find a mapping that will turn the rectangle with corners (0,0), (3,0), (3,2), (0,2) into a square? Look at some different starting vectors. Try some other matrices. What is the relationship between the rank of the matrix and the image of the transformation? 13.4 Even More Exploration For a more interactive experinece, head over to Section 2.6.2 of Understanding Linear Algbra. This short section on the geometry of \\(2 \\times 2\\) matrix transformations has an interactive activity where you can change the entries using slider controls. It is illuminating to see the progressive impact of your choices! "],["linear-transformations-of-a-house.html", "Vector 14 Linear Transformations of a House 14.1 Rotations 14.2 Expansion and contraction 14.3 Reflection over the line \\(y=x\\) 14.4 Shear Transformations 14.5 Dimension Reduction 14.6 A Complicated Transformation", " Vector 14 Linear Transformations of a House Download this Rmd file from GitHub Here is a plot of my house. You will need to run this chunk of code each time you re-start R to get the house back in memory. house = cbind(c(0,0), c(0,3/4), c(1/2,3/4), c(1/2,0), c(1,0), c(1,1), c(5/4,1), c(0,2), c(-5/4,1), c(-1,1), c(-1,0), c(0,0)); plot(house[1,],house[2,],type=&quot;n&quot;,xlim=c(-5,5),ylim=c(-5,5),xlab=&quot;x&quot;,ylab=&quot;y&quot;) abline(h=-6:6, v=-6:6, col=&quot;gray&quot;, lty=&quot;dotted&quot;) polygon(house[1,], house[2,], col = &quot;gray&quot;, border = &quot;blue&quot;) Today we will explore various families of linear transformations on the plane by looking at their effect on my house. We give a series of examples of 2D linear transformations. After each example, it’s your turn to play with variations from the same family of transformations. Using the previous code snippets as a guide, create a single plot with the “before and after” houses. Discuss the results with your group and share cool examples! Describe the effect of the mapping as best you can. Be sure to look at the different effect on the “ground” and the “walls” of the course. Use words like, expansion, contraction, rotation, reflection and shear. Once you have looked at the effect of the family, look back at the form of the matrix \\(A\\). Can you explain why it leads to the outcome you see? 14.1 Rotations First we will rotate my house by pi/3 radians. A 2D rotation matrix by \\(t\\) radians is given by \\[A=\\displaystyle{ \\begin{bmatrix} \\cos(t) &amp; -\\sin(t) \\\\ \\sin(t) &amp; \\cos(t) \\end{bmatrix}}.\\] Here is the code to display this transformation. Observe that I apply the matrix A to the house, call it house2 and plot both the original house and the new house in the same plot. # create a plot that we will add more layers to plot(house[1,],house[2,],type=&quot;n&quot;,xlim=c(-5,5),ylim=c(-5,5),xlab=&quot;x&quot;,ylab=&quot;y&quot;) # add the grid lines abline(h=-6:6, v=-6:6, col=&quot;gray&quot;, lty=&quot;dotted&quot;) # define the matrix A A = cbind(c(cos(pi/3),sin(pi/3)),c(-sin(pi/3),cos(pi/3))) # display A A ## [,1] [,2] ## [1,] 0.5000000 -0.8660254 ## [2,] 0.8660254 0.5000000 # transform the house using matrix multiplication house2 = A %*% house # plot the original house polygon(house[1,], house[2,], col = &quot;gray&quot;, border = &quot;blue&quot;) # plot the transformed house polygon(house2[1,], house2[2,], col = &quot;pink&quot;, border = &quot;black&quot;) And now I rotate it back to its original position. The inverse in this case is rotation by -pi/3.I apply this mapping to house2 to get house3 and then plot those houses together. plot(house[1,],house[2,],type=&quot;n&quot;,xlim=c(-5,5),ylim=c(-5,5),xlab=&quot;x&quot;,ylab=&quot;y&quot;) abline(h=-6:6, v=-6:6, col=&quot;gray&quot;, lty=&quot;dotted&quot;) Ainv = cbind(c(cos(-pi/3),sin(-pi/3)),c(-sin(-pi/3),cos(-pi/3))) # A inverse Ainv # display A inverse ## [,1] [,2] ## [1,] 0.5000000 0.8660254 ## [2,] -0.8660254 0.5000000 house3 = Ainv %*% house2 polygon(house2[1,], house2[2,], col = &quot;pink&quot;, border = &quot;black&quot;) polygon(house3[1,], house3[2,], col = &quot;green&quot;, border = &quot;black&quot;) 14.1.1 Your Turn Explore matrices of the form \\[A=\\displaystyle{ \\begin{bmatrix} \\cos(t) &amp; -\\sin(t) \\\\ \\sin(t) &amp; \\cos(t) \\end{bmatrix}}\\] where \\(t\\) is in radians. Here is a function that will create such a matrix (so that you only have to enter the angle once). create_angle_matrix &lt;- function(t) { A = cbind(c(cos(t), sin(t)), c(-sin(t), cos(t))) return(A) } A = create_angle_matrix(pi/2) A ## [,1] [,2] ## [1,] 6.123234e-17 -1.000000e+00 ## [2,] 1.000000e+00 6.123234e-17 Note #1: R is numerical software. The example code rotates the couse by \\(pi/2\\). You’ll note that sin(pi/2) returns a value of 6.123234e-17 or something similar. This value is given in scientific notation, and is \\(\\approx 6.12 \\times 10^{-17}\\). You should treat this tiny number as equal to 0. Be sure to keep an eye out for return values like this that are “numerically equivalent to 0.” Note #2: By default, an R plot stretches the horizontal scale compared to the vertical scale. In order to create a square plot, your R chunk should start with {r, fig.height=4,fig.width=4} rather than {r}. Here is an example of what that looks like: 14.2 Expansion and contraction Next, let’s perform the transformation that scales the house by 2 in the \\(x\\)-direction and by 3 in the \\(y\\)-direction. (A = cbind(c(2,0),c(0,3))) ## [,1] [,2] ## [1,] 2 0 ## [2,] 0 3 plot(house[1,],house[2,],type=&quot;n&quot;,xlim=c(-5,5),ylim=c(-5,5),xlab=&quot;x&quot;,ylab=&quot;y&quot;) abline(h=-6:6, v=-6:6, col=&quot;gray&quot;, lty=&quot;dotted&quot;) house2 = A %*% house polygon(house[1,], house[2,], col = &quot;gray&quot;, border = &quot;blue&quot;) polygon(house2[1,], house2[2,], col = &quot;pink&quot;, border = &quot;black&quot;) 14.2.1 Your Turn Explore matrices of the form \\[A=\\displaystyle{ \\begin{bmatrix} a &amp; 0 \\\\ 0 &amp; b \\end{bmatrix}}.\\] Here is some sample code that would create such a matrix for \\(a=1\\) and \\(b=1\\). a = 1 b = 1 A = cbind(c(a,0), c(0,b)) Try various combinations of \\(a\\) and \\(b\\). Here are some guiding questions: How would you expand along the \\(x\\)-axis while contracting along the \\(y\\)-axis? What happens when \\(a\\) is negative? when \\(b\\) is negative? when both are negative? 14.3 Reflection over the line \\(y=x\\) Now let’s try reflecting the house over the line \\(y = x\\). Note that by putting the assignment of A into parentheses it prints out the value of A while you are assigning it (A = cbind(c(0,1),c(1,0))) ## [,1] [,2] ## [1,] 0 1 ## [2,] 1 0 plot(house[1,],house[2,],type=&quot;n&quot;,xlim=c(-5,5),ylim=c(-5,5),xlab=&quot;x&quot;,ylab=&quot;y&quot;) abline(h=-6:6, v=-6:6, col=&quot;gray&quot;, lty=&quot;dotted&quot;) house2 = A %*% house polygon(house[1,], house[2,], col = &quot;gray&quot;, border = &quot;blue&quot;) polygon(house2[1,], house2[2,], col = &quot;pink&quot;, border = &quot;black&quot;) 14.3.1 Your Turn Explore matrices of the form \\[A=\\displaystyle{ \\begin{bmatrix} 0 &amp; a \\\\ b &amp; 0 \\end{bmatrix}}.\\] Try various combinations of \\(a\\) and \\(b\\), using both positive and negative values. 14.4 Shear Transformations A shear transformation leaves the direction of one axis fixed. Here is an example. (A = cbind(c(1,0),c(1,1))) ## [,1] [,2] ## [1,] 1 1 ## [2,] 0 1 plot(house[1,],house[2,],type=&quot;n&quot;,xlim=c(-5,5),ylim=c(-5,5),xlab=&quot;x&quot;,ylab=&quot;y&quot;) abline(h=-6:6, v=-6:6, col=&quot;gray&quot;, lty=&quot;dotted&quot;) house2 = A %*% house polygon(house[1,], house[2,], col = &quot;gray&quot;, border = &quot;blue&quot;) polygon(house2[1,], house2[2,], col = &quot;pink&quot;, border = &quot;black&quot;) 14.4.1 Your Turn Now explore matrices of the form \\[ A=\\displaystyle{ \\begin{bmatrix} a &amp; b \\\\ 0 &amp; c \\end{bmatrix}} \\quad \\mbox{and} \\quad A=\\displaystyle{ \\begin{bmatrix} a &amp; 0 \\\\ b &amp; c \\end{bmatrix}} \\] Start with \\(a=b=c=1\\). Then consider a wider variety of such matrices as with the families above. 14.5 Dimension Reduction Here we perform the transformation that sends \\(\\mathsf{e}_1\\) to \\((-1,1/2)\\) and \\(\\mathsf{e}_2\\) to \\((2,-1)\\). Notice that they are the same line and the transformation projects the house onto this line. (A = cbind(c(-1,1/2),c(2,-1))) ## [,1] [,2] ## [1,] -1.0 2 ## [2,] 0.5 -1 plot(house[1,],house[2,],type=&quot;n&quot;,xlim=c(-5,5),ylim=c(-5,5),xlab=&quot;x&quot;,ylab=&quot;y&quot;) abline(h=-6:6, v=-6:6, col=&quot;gray&quot;, lty=&quot;dotted&quot;) house2 = A %*% house polygon(house[1,], house[2,], col = &quot;gray&quot;, border = &quot;blue&quot;) polygon(house2[1,], house2[2,], col = &quot;pink&quot;, border = &quot;black&quot;) 14.5.1 Your Turn Explore matrices of the form \\[ A=\\displaystyle{ \\begin{bmatrix} a &amp; ca \\\\ b &amp; cb \\end{bmatrix}} \\quad \\mbox{and} \\quad A=\\displaystyle{ \\begin{bmatrix} a &amp; b \\\\ ca &amp; cb \\end{bmatrix}} \\] Once again, consider a wide variety of such matrices using various values for \\(a,b,c\\). 14.6 A Complicated Transformation Finally, suppose that we wish to perform the transformation that reflects over the \\(y\\)-axis, then rotates by pi/2, and finally scales the \\(x\\)-direction by 2 and the y-direction by 3 in that order. You can do this as three matrices that you multiply together. Note: The order of these matrices goes from right to left. The rightmost matrix is the one that is closest to the vector. So that transformation happens first! The matrix A: scale = cbind(c(2,0),c(0,3)) rot = cbind(c(cos(pi/2),sin(pi/2)),c(-sin(pi/2),cos(pi/2))) reflect = cbind(c(-1,0),c(0,1)) A = scale %*% rot %*% reflect plot(house[1,],house[2,],type=&quot;n&quot;,xlim=c(-5,5),ylim=c(-5,5),xlab=&quot;x&quot;,ylab=&quot;y&quot;) abline(h=-6:6, v=-6:6, col=&quot;gray&quot;, lty=&quot;dotted&quot;) house2 = A %*% house polygon(house[1,], house[2,], col = &quot;gray&quot;, border = &quot;blue&quot;) polygon(house2[1,], house2[2,], col = &quot;pink&quot;, border = &quot;black&quot;) 14.6.1 Your Turn Using the previous example as a guide, create a complicated mapping of your own that combines some of the linear transformations above. "],["d-translations-with-homogeneous-coordinates.html", "Vector 15 2D Translations with Homogeneous Coordinates 15.1 Translation 15.2 Translation and then Rotation 15.3 Rotation and then Translation 15.4 Your Turn", " Vector 15 2D Translations with Homogeneous Coordinates Download this Rmd file A translation of the plane shifts every vector by a constant vector. For example, the mapping \\[ S \\left( \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\right) = \\begin{bmatrix} x \\\\ y \\end{bmatrix} + \\begin{bmatrix} 3 \\\\ -4 \\end{bmatrix} = \\begin{bmatrix} x +3 \\\\ y - 4 \\end{bmatrix} \\] translates every vector in the plane by \\(\\begin{bmatrix} 3 \\\\ -4~ \\end{bmatrix}\\). The bad news: This is a simple and natural mapping, but it is not a linear transformation! We know that a linear transformation must map \\(\\mathbb{0}\\) to \\(\\mathbb{0}\\), and that is certainly not the case when we translate! This restriction is rather limiting for computer graphics: we can never move our image away from the origin. The good news: We can work around this problem by creating a 3D linear transformation \\(T: \\mathbb{R}^3 \\rightarrow \\mathbb{R}^3\\) and then retricting our attention to a plane in this larger space. As discussed in the Homogeneous Coordinates video, we do the following: Embed the \\(xy\\)-plane \\(\\mathbb{R}^2\\) into the plane \\(z = 1\\) in \\(\\mathbb{R}^3\\). Translate in \\(\\mathbb{R}^3\\) using a mapping \\(T\\) that maps this horizontal plane to itself. That is: \\[ T \\left( \\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix} \\right) = \\begin{bmatrix} u \\\\ v \\\\ 1 \\end{bmatrix}. \\] When we create our plot, we use only the first two coordinates and ignore the third coordinate (which is still 1). In summary, during our calculations, we replace the vector \\(\\begin{bmatrix} x \\\\ y \\end{bmatrix}\\) in \\(\\mathbb{R}^2\\) with the homogeneous coordinate vector \\(\\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}\\) in \\(\\mathbb{R}^3\\). 15.1 Translation Here is my house once again. Note that we have add \\(z=1\\) as the third coordinate to each point. However, when plotting, we only use the first two coordinates. # the third entry always = 1 house = cbind(c(0,0,1), c(0,3/4,1), c(1/2,3/4,1), c(1/2,0,1), c(1,0,1), c(1,1,1), c(5/4,1,1), c(0,2,1), c(-5/4,1,1), c(-1,1,1), c(-1,0,1), c(0,0,1)); # only plot the first two coordinates plot(house[1,],house[2,],type=&quot;n&quot;,xlim=c(-6,6),ylim=c(-6,6),xlab=&quot;x&quot;,ylab=&quot;y&quot;) abline(h=-6:6, v=-6:6, col=&quot;gray&quot;, lty=&quot;dotted&quot;) polygon(house[1,], house[2,], col = &quot;gray&quot;, border = &quot;blue&quot;) Next, we translate by \\(\\begin{bmatrix} 3 \\\\ - 4 \\end{bmatrix}\\) by using the linear transformation \\[ T \\left( \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} \\right) = \\begin{bmatrix} 1 &amp; 0 &amp; 3 \\\\ 0 &amp; 1 &amp; -4 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix}. \\] Let’s check that this has the desired effect on a homogeneous coordinate vector: \\[ T \\left( \\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix} \\right) = \\begin{bmatrix} 1 &amp; 0 &amp; 3 \\\\ 0 &amp; 1 &amp; -4 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} x+3 \\\\ y - 4 \\\\ 1 \\end{bmatrix}. \\] It worked! Note that this linear transformation maps every horizontal plane to itself. For the plane \\(z=1\\) (and only for this plane!) we get the exact translation that we desire. So it is crucial that \\(z=1\\). That’s the magic of homogeneous coordinates. Let’s do this calculation in R and plot the first two coordiantes: A = cbind(c(1,0,0),c(0,1,0),c(3,-4,1)) house2 = A %*% house # only plot the first two coordinates plot(house[1,],house[2,],type=&quot;n&quot;,xlim=c(-6,6),ylim=c(-6,6),xlab=&quot;x&quot;,ylab=&quot;y&quot;) abline(h=-6:6, v=-6:6, col=&quot;gray&quot;, lty=&quot;dotted&quot;) polygon(house[1,], house[2,], col = &quot;gray&quot;, border = &quot;blue&quot;) polygon(house2[1,], house2[2,], col = &quot;pink&quot;, border = &quot;black&quot;) 15.2 Translation and then Rotation We know plenty 2D linear transformation, including rotation, reflection and shear mappings. We can turn any of them into a 3D transformation by appending a row and a column with a 1 in the lower right corner and zero everywhere else. For example, the 2D rotation \\[ \\begin{bmatrix} \\cos \\theta &amp; -\\sin \\theta~ \\\\ \\sin \\theta &amp; \\cos \\theta \\end{bmatrix} \\] becomes the 3D transformation \\[ \\begin{bmatrix} \\cos\\theta &amp; -\\sin\\theta~ &amp; 0 \\\\ \\sin\\theta &amp; \\cos\\theta &amp;0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix}. \\] This mapping rotates 3D space around the \\(z\\)-axis. So let’s combine two operations: a translation and a rotation. First, let’s translate by \\(\\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix}\\) and then rotate counterclockwise by \\(2 \\pi/3\\). And remember: the matrix closest to the vector acts first. So if we want to translate first, the translation matrix needs to be to the right of the rotation matrix: \\[ T \\left( \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} \\right) = \\begin{bmatrix} \\cos \\frac{2\\pi}{3} &amp; -\\sin\\frac{2\\pi}{3}~ &amp; 0 \\\\ \\sin\\frac{2\\pi}{3} &amp; \\cos\\frac{2\\pi}{3} &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 0 &amp; -2 \\\\ 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix}. \\] ## [,1] [,2] [,3] ## [1,] 1 0 -2 ## [2,] 0 1 1 ## [3,] 0 0 1 ## [,1] [,2] [,3] ## [1,] -0.5000000 -0.8660254 0 ## [2,] 0.8660254 -0.5000000 0 ## [3,] 0.0000000 0.0000000 1 ## [,1] [,2] [,3] ## [1,] -0.5000000 -0.8660254 0.1339746 ## [2,] 0.8660254 -0.5000000 -2.2320508 ## [3,] 0.0000000 0.0000000 1.0000000 15.3 Rotation and then Translation Let’s reverse the order of these matrices and see that we get a different transformation. ## [,1] [,2] [,3] ## [1,] -0.5000000 -0.8660254 -2 ## [2,] 0.8660254 -0.5000000 1 ## [3,] 0.0000000 0.0000000 1 Indeed, these two transformations are different! So the order matters. 15.4 Your Turn Here are a couple of plots that you should try to reproduce using homogeneous coordinates. 15.4.1 House of Orange Here is a picture of a gray house and a larger, upside-down orange house. Work as a group to reproduce this image using homogeneous coordinates. You will have to use a combination of translation, rotation, and expansion. You will do this by multiplying three matrices. Think carefully and experiment. Remember that the order of your matrices matters, and the rightmost one happens first. ############################# # your code defining the 3x3 matrices A1 and A2 A1 = cbind(c(1,0,0), c(0,1,0), c(0,0,1)) A2 = cbind(c(1,0,0), c(0,1,0), c(0,0,1)) A3 = cbind(c(1,0,0), c(0,1,0), c(0,0,1)) A = A3 %*% A2 %*% A1 ############################# # you do not need to change this code plot(house[1,],house[2,],type=&quot;n&quot;,xlim=c(-6,6),ylim=c(-6,6),xlab=&quot;x&quot;,ylab=&quot;y&quot;) house2 = A %*% house abline(h=-6:6, v=-6:6, col=&quot;gray&quot;, lty=&quot;dotted&quot;) polygon(house2[1,], house2[2,], col = &quot;orange&quot;, border = &quot;green&quot;) polygon(house[1,], house[2,], col = &quot;gray&quot;, border = &quot;blue&quot;) 15.4.2 House Party Here is a plot of the grey house and four other houses, colored cyan, red, gold and green. Reproduce this image using homogeneous coordinates. Work as a group! You can collaborate, or divide and conquer. Be ready to help one another out! ############# # your code for 3x3 matrices that create the transformed houses goes here A.red = cbind(c(1,0,0), c(0,1,0), c(0,0,1)) A.purple = cbind(c(1,0,0), c(0,1,0), c(0,0,1)) A.gold = cbind(c(1,0,0), c(0,1,0), c(0,0,1)) A.cyan = cbind(c(1,0,0), c(0,1,0), c(0,0,1)) #################### # you do not need to change this code house = cbind(c(0,0,1), c(0,3/4,1), c(2/4,3/4,1), c(2/4,0,1), c(4/4,0,1), c(4/4,4/4,1), c(5/4,4/4,1), c(0,8/4,1), c(-5/4,4/4,1), c(-4/4,4/4,1), c(-4/4,0,1), c(0,0,1)); plot(house[1,], house[2,], type = &quot;n&quot;, xlim=c(-2.5,2.5),ylim=c(-2.0,3.0),,xlab=&quot;x&quot;,ylab=&quot;y&quot;) abline(h=-4:4, v=-4:4, col=&quot;gray&quot;, lty=&quot;dotted&quot;) house.gold = A.gold %*% house polygon(house.gold[1,], house.gold[2,], col = &quot;gold&quot;, border = &quot;blue&quot;) house.cyan = A.cyan %*% house polygon(house.cyan[1,], house.cyan[2,], col = &quot;cyan&quot;, border = &quot;blue&quot;) house.red = A.red %*% house polygon(house.red[1,], house.red[2,], col = &quot;red&quot;, border = &quot;blue&quot;) house.purple= A.purple %*% house polygon(house.purple[1,], house.purple[2,], col = &quot;purple&quot;, border = &quot;blue&quot;) polygon(house[1,], house[2,], col = &quot;gray&quot;, border = &quot;blue&quot;) "],["fractals.html", "Vector 16 Fractals 16.1 Transforming My House. 16.2 Watching a series of points. 16.3 Here are some from http://paulbourke.net/fractals/ifs/", " Vector 16 Fractals You’ve probably heard of fractals: mathematical sets with a self-similar structure. Each smaller part is a miniature copy of the whole structure. Today, we will see how to use linear transformations and homogeneous coordiantes to generate a fractal. We will generate a fractal by repeatedly applying the following 3D linear transformations. We pick one of these four transformations using some randomness. Most of the time we apply matrix A1. Occasionally, we apply matrix A2 or A3. And rarely we apply A4. So let’s generate a fractal! 16.1 Transforming My House. So what is happening? Let’s look at the effect of each of these linear transformations on my house ## [,1] [,2] [,3] ## [1,] 0.20 -0.25 0.0 ## [2,] 0.21 0.23 1.5 ## [3,] 0.00 0.00 1.0 ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] ## [1,] 0.00 0.046875 0.066875 0.02000 0.0400 0.1025 0.112500 0.1250 0.012500 0.0225 -0.0400 0.00 ## [2,] 2.25 2.289675 2.311725 2.27205 2.2941 2.3470 2.358025 2.3558 2.247775 2.2588 2.2059 2.25 ## [3,] 1.00 1.000000 1.000000 1.00000 1.0000 1.0000 1.000000 1.0000 1.000000 1.0000 1.0000 1.00 16.2 Watching a series of points. Let’s see what happens when we repeatedly apply the same mapping. ## Your Turn Make some small adjustments to one of these matrices. Explore the impact of the fractal. Can you make it spikier? Bushier? 16.3 Here are some from http://paulbourke.net/fractals/ifs/ a 0.2020 0.1380 b -0.8050 0.6650 c -0.6890 -0.5020 d -0.3420 -0.2220 e -0.3730 0.6600 f -0.6530 -0.2770 ## [,1] [,2] ## [1,] 0.824074 0.088272 ## [2,] 0.281428 0.520988 ## [3,] -0.212346 -0.463889 ## [4,] 0.864198 -0.377778 ## [5,] -1.882290 0.785360 ## [6,] -0.110607 8.095795 ## [[1]] ## [,1] [,2] [,3] ## [1,] 0.787879 -0.424242 1.758647 ## [2,] 0.242424 0.859848 1.408065 ## [3,] 0.000000 0.000000 1.000000 ## ## [[2]] ## [,1] [,2] [,3] ## [1,] -0.121212 0.257576 -6.721654 ## [2,] 0.151515 0.053030 1.377236 ## [3,] 0.000000 0.000000 1.000000 ## ## [[3]] ## [,1] [,2] [,3] ## [1,] 0.181818 -0.136364 6.086107 ## [2,] 0.090909 0.181818 1.568035 ## [3,] 0.000000 0.000000 1.000000 "],["dynamical-systems-in-2d.html", "Vector 17 Dynamical Systems in 2D 17.1 Helper Function to Plot Dynamical Systems 17.2 Our first example 17.3 Your Turn", " Vector 17 Dynamical Systems in 2D Download this Rmd file Let \\(A\\) be a square \\(n \\times n\\) matrix and let \\(\\mathsf{x}_0 \\in \\mathbb{R}^n\\). A dynamical system is a sequence of vectors \\(\\mathsf{x}_0,\\mathsf{x}_1,\\mathsf{x}_2, \\ldots, \\mathsf{x}_t, \\ldots\\) where \\[ \\mathsf{x}_{t} = A \\mathsf{x}_{t-1} = A^t \\mathsf{x}_0 \\quad \\mbox{for} \\quad t \\geq 1. \\] The sequence \\(\\mathsf{x}_0,\\mathsf{x}_1,\\mathsf{x}_2, \\ldots, \\mathsf{x}_t, \\ldots\\) is called the trajectory for initial vector \\(\\mathsf{x}_0\\). A dynamical system evolves over time. The long-term behavior is governed by the eigenvalues of matrix \\(A\\) We will look at some \\(2 \\times 2\\) dynamical systems to develop some intuition about eigensystems. 17.1 Helper Function to Plot Dynamical Systems I have written some code that makes some helpful plots. You should run this code chunk before the others. get_traj &lt;- function(mat, x0, num) { traj = cbind(x0) num for (i in 1:num) { traj = cbind(traj, mat %*% traj[,dim(traj)[2]]) traj } return(traj) } plot_traj &lt;- function(mat, x0, num) { traj = get_traj(mat,x0,num) points(traj[1,],traj[2,], pch=20, col=rainbow(length(traj))) } trajectory_plot &lt;- function(mat, t=20, datamax=5, plotmax=10, numpoints=10, showEigenspaces=TRUE) { # initialize plot par(pty = &quot;s&quot;) plot(c(0),c(0),type=&quot;n&quot;, xlim=c(-plotmax,plotmax),ylim=c(-plotmax,plotmax), xlab=&#39;x&#39;, ylab=&#39;y&#39;) abline(h=-plotmax:plotmax, v=-plotmax:plotmax, col=&quot;gray&quot;) mygrid &lt;- expand.grid(x=seq(from = -datamax, by = 2*datamax/numpoints, l = numpoints+1), y=seq(from = -datamax, by = 2*datamax/numpoints, l = numpoints+1)) for (t in 1:dim(mygrid)[1]) { plot_traj(A,c(mygrid[t,1],mygrid[t,2]),t) } if (showEigenspaces) { eigen = eigen(A) #mylabel = cat(&#39;lambda=&#39;, eigen$values[1], &#39;and lambda=&#39;, eigen$values[2]) #title(xlab=mylabel) v1 = zapsmall(eigen$vectors[,1]) v2 = zapsmall(eigen$vectors[,2]) if (! class(v1[1]) == &quot;complex&quot;) { if (v1[1] == 0) { abline(v=0) } else { abline(a=0,b=v1[2]/v1[1], col=&quot;blue&quot;) } if (v2[1] == 0) { abline(v=0) } else { abline(a=0,b=v2[2]/v2[1], col=&quot;blue&quot;) } } } } 17.2 Our first example Let’s start by looking at the example from the video \\[ A = \\frac{1}{30} \\begin{bmatrix} 31 &amp; 4 \\\\ 2 &amp; 29 \\end{bmatrix}. \\] Here is some code that creates a single trajectory for \\(0 \\leq t \\leq 30\\) starting at \\(\\mathsf{x}_0 = \\begin{bmatrix} -0.5 &amp; 1 \\end{bmatrix}.\\) The colors of the points follow the rainbow ordering at \\(t\\) increases. A = 1/30 * cbind(c(31,2),c(4,29)) x0 = c(-0.5,1) # initialize the plot plot(c(0),c(0),type=&quot;n&quot;,xlim=c(-5,5),ylim=c(-5,5),xlab=&quot;x&quot;,ylab=&quot;y&quot;) abline(h=-5:5, v=-5:5, col=&quot;gray&quot;) plot_traj(A,x0,30) We get a more complete picture when we plot multiple trajectories at once. So I have written a helper function to plot the trajectories of a grid of points. It also plots the eigenspaces for the matrix. You can specify the matrix A the number of iterations the size of the square where the initial points lie the size of the plot the number of points along the side of the grid A = 1/30 * cbind(c(31,2),c(4,29)) trajectory_plot(A, t=30, datamax=5, plotmax=15, numpoints=5) Perhaps this system is best understood by comparing what we see with the eigenvector and eigenvalues. eigen(A) ## eigen() decomposition ## $values ## [1] 1.1 0.9 ## ## $vectors ## [,1] [,2] ## [1,] 0.8944272 -0.7071068 ## [2,] 0.4472136 0.7071068 We can see that we have slight expansion along \\([ 2, 1]^{\\top}\\) and slight contraction along \\([-1,1]\\). The long term behavior is an expansion in the direction of \\([2, 1]^{\\top}\\). 17.3 Your Turn Now it’s your turn to explore some dynamical systems. Create trajectory plots for each of these dynamical systems. Characterize the long-term behavior. What direction to vectors converge to? Do magnitudes increase? decrease? stabilize? Calculate the eigenvectors and eigenvalues and compare them to your plot. The eigensystem should tell the same story as your plot. If your original plot is confusing, try changing the parameters (initial square size, plot size, number of grid points). Here is some code for you to adapt for the examples. &#39;```{r, echo=TRUE} A = cbind(c(1,0),c(0,1)) trajectory_plot(A, t=30, datamax=5, plotmax=10, numpoints=10) eigen(A) 17.3.1 Example 1 \\[ A = \\frac{1}{60} \\begin{bmatrix} 55&amp; -8 \\\\ -1 &amp; 53 \\end{bmatrix} \\] 17.3.2 Example 2 \\[ A = \\frac{1}{20} \\begin{bmatrix} 24&amp; -6 \\\\ 1 &amp; 19 \\end{bmatrix} \\] 17.3.3 Example 3 \\[ A = \\frac{1}{110} \\begin{bmatrix} 106&amp; 12 \\\\ 6 &amp; 92 \\end{bmatrix} \\] 17.3.4 Example 4 \\[ A = \\frac{1}{16} \\begin{bmatrix} 17&amp; -15 \\\\ 15 &amp; 17 \\end{bmatrix} \\] "],["network-centralities.html", "Vector 18 Network Centralities 18.1 Graphs and Networks 18.2 Degree Centrality 18.3 Gould’s Index 18.4 Your Turn: The Rise of Moscow", " Vector 18 Network Centralities Download this Rmd file In this example, we will use a package called igraph. To install it, you need to go to the packages window (bottom right), choose install, and search for and install igraph from the packages window. library(igraph) The igraph R package isn’t all that well documented. Here are some places to look for documentation if you want to learn about other features. Let me know if you find any other good references: http://kateto.net/netscix2016 http://igraph.org/r/doc/aaa-igraph- 18.1 Graphs and Networks Graphs consists of vertices and the edges between them. These edges are used to model connections in a wide array of applications, including but not limited to, physical, biological, social, and information networks. To emphasize the application to real-world systems, the term Network Science is sometimes used. So we will use the terms graph and network interchangeably. In this application question, we will see that linear algebra is an important tool in the study of graphs. 18.1.1 Adjacency Matrices Matrices are used to represent graphs and networks in a very direct way: we place a 1 in position \\((i,j)\\) of the adjacency matrix \\(A\\) of the graph \\(G\\), if there is an edge from vertex \\(i\\) to vertex \\(j\\) in \\(G\\). Here is the adjacency matrix we will use today. As you can see it is a \\(12 \\times 12\\) matrix. A = rbind( c(0,1,0,1,0,0,0,0,1,0,0,0), c(1,0,1,1,1,0,1,0,0,0,0,0), c(0,1,0,0,1,0,0,0,0,0,0,0), c(1,1,0,0,0,1,0,1,0,0,0,0), c(0,1,1,0,0,0,1,1,0,0,0,1), c(0,0,0,1,0,0,1,0,0,0,0,0), c(0,1,0,0,1,1,0,1,0,0,0,0), c(0,0,0,1,1,0,1,0,0,1,1,0), c(1,0,0,0,0,0,0,0,0,0,0,0), c(0,0,0,0,0,0,0,1,0,0,0,0), c(0,0,0,0,0,0,0,1,0,0,0,0), c(0,0,0,0,1,0,0,0,0,0,0,0)) A ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] ## [1,] 0 1 0 1 0 0 0 0 1 0 0 0 ## [2,] 1 0 1 1 1 0 1 0 0 0 0 0 ## [3,] 0 1 0 0 1 0 0 0 0 0 0 0 ## [4,] 1 1 0 0 0 1 0 1 0 0 0 0 ## [5,] 0 1 1 0 0 0 1 1 0 0 0 1 ## [6,] 0 0 0 1 0 0 1 0 0 0 0 0 ## [7,] 0 1 0 0 1 1 0 1 0 0 0 0 ## [8,] 0 0 0 1 1 0 1 0 0 1 1 0 ## [9,] 1 0 0 0 0 0 0 0 0 0 0 0 ## [10,] 0 0 0 0 0 0 0 1 0 0 0 0 ## [11,] 0 0 0 0 0 0 0 1 0 0 0 0 ## [12,] 0 0 0 0 1 0 0 0 0 0 0 0 dim(A) ## [1] 12 12 Here is how to make the graph from your adjacency matrix g=graph_from_adjacency_matrix(A,mode=&#39;undirected&#39;) plot(g, vertex.color=&#39;tan1&#39;, vertex.frame.color=&quot;dodgerblue&quot;) Observe that there is an edge from vertex \\(i\\) to vertex \\(j\\) if and only if there is a 1 in position \\((i,j)\\) in the matrix. Let’s assume that this network is the route map of a small airline. Let’s add vertex labels and change the vertex size: airports = c(&quot;ATL&quot;,&quot;LAX&quot;,&quot;ORD&quot;,&quot;MSP&quot;,&quot;DEN&quot;,&quot;JFK&quot;,&quot;SFO&quot;,&quot;SEA&quot;,&quot;PHL&quot;,&quot;PDX&quot;,&quot;MDW&quot;,&quot;LGA&quot;) V(g)$label = airports plot(g,vertex.size=30, vertex.color=&#39;tan1&#39;, vertex.frame.color=&quot;dodgerblue&quot;) 18.1.2 Graph Layouts There are a variety of graph layout algorithms which place the vertices in the plane. You can find many algorithms in the igraph documentation. For example, here is a layout on a circle coords = layout_in_circle(g) plot(g, layout=coords, vertex.size = 30,vertex.label.cex=0.65, vertex.color=&#39;tan1&#39;, vertex.frame.color=&quot;dodgerblue&quot;) The Fruchterman-Reingold algorithm is one of the most popular graph vertex layout algorithms. It is a force-directed layout that tries to get a nice-looking graph where edges are similar in length and cross each other as little as possible. The algorithm simulates the graph as a physical system. Vertices are electrically charged particles that repulse each other when they get too close. The edges act as springs that attract connected vertices closer together. As a result, vertices are evenly distributed through the chart area. The resulting layout is intuitive: vertices which share more connections are closer to each other. coords = layout_with_fr(g) plot(g, layout=coords, vertex.size = 30, vertex.label.cex=0.65, vertex.color=&#39;tan1&#39;, vertex.frame.color=&quot;dodgerblue&quot;) We can also choose to layout vertices by hand: locations = rbind( c(20,0),c(-10,0),c(11,7),c(10,15),c(3,12),c(25,10), c(-10,10),c(-12,15),c(20,6),c(-15,12),c(12,4),c(25,13) ) plot(g,vertex.size=20, layout=locations, vertex.label.cex=0.65, vertex.color=&#39;tan1&#39;, vertex.frame.color=&quot;dodgerblue&quot;) 18.2 Degree Centrality If we are considering placing an office in one of our airport locations, we may want to chose the most central hub for that office. It turns out that there are many interesting centrality measures for networks. We will talk about two of them today. The simplest measure centrality is the degree of the vertex, or the number of edges connected to that vertex. We calculate the degree centralities from the adjacency matrix as follows: First make a vector \\(\\mathsf{v}\\) of all 1’s; then multiply \\(\\mathsf{d} = A\\mathsf{v}\\) to get the degree proportions; and we also divide vector \\(\\mathsf{d}\\) by the sum of its entries. The result is a normalized vector \\(\\mathsf{u}\\) whose entries sum to 1. Each entry of vector \\(\\mathsf{u}\\) represents to proportion of edges incident with the corresponding vertex. v=rep(1,nrow(A)) # all 1s vector d = A %*% v # degrees u=d/sum(d) # proportion of degrees cbind(d,u) # show d and u together side-by-side in a matrix ## [,1] [,2] ## [1,] 3 0.08823529 ## [2,] 5 0.14705882 ## [3,] 2 0.05882353 ## [4,] 4 0.11764706 ## [5,] 5 0.14705882 ## [6,] 2 0.05882353 ## [7,] 4 0.11764706 ## [8,] 5 0.14705882 ## [9,] 1 0.02941176 ## [10,] 1 0.02941176 ## [11,] 1 0.02941176 ## [12,] 1 0.02941176 Now let’s create a data visualization. We plot the network and size each vertex according to the vector \\(u\\). The larger vertices have more edges connected to them. This conveys information to the viewer about the relative importance of the vertices. plot(g, layout=locations, vertex.size=250*u,vertex.label.cex=0.65, vertex.color=&#39;tan1&#39;, vertex.frame.color=&quot;dodgerblue&quot;) We can also sort the vertices by degree. To include the vertex names, we do it in a data frame. df = data.frame(d) # Convert vector to a data frame so that we can add row names rownames(df)=airports ii=order(d,decreasing=TRUE) df2 = data.frame(df[ii,]) rownames(df2) = airports[ii] df2 ## df.ii... ## LAX 5 ## DEN 5 ## SEA 5 ## MSP 4 ## SFO 4 ## ATL 3 ## ORD 2 ## JFK 2 ## PHL 1 ## PDX 1 ## MDW 1 ## LGA 1 18.3 Gould’s Index Gould’s Index is a measure of centrality that uses the dominant eigenvector of a matrix. It was introduced by geographer P. R. Gould in 1967 to analyze the geographical features on maps. We will build up Gould’s Index step-by-step so that we can understand what it measures. 18.3.1 Step 1 The first step is typically to add the identity matrix to the adjancency matrix \\(A\\) to get a new matrix \\[B = A + I.\\] The \\(n \\times n\\) identity matrix in R is obtained by using diag(n). Adding the identity gives a connection from a vertex to itself. This loop edge corresponds to staying at the current city during a layover. (B = A + diag(nrow(A))) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] ## [1,] 1 1 0 1 0 0 0 0 1 0 0 0 ## [2,] 1 1 1 1 1 0 1 0 0 0 0 0 ## [3,] 0 1 1 0 1 0 0 0 0 0 0 0 ## [4,] 1 1 0 1 0 1 0 1 0 0 0 0 ## [5,] 0 1 1 0 1 0 1 1 0 0 0 1 ## [6,] 0 0 0 1 0 1 1 0 0 0 0 0 ## [7,] 0 1 0 0 1 1 1 1 0 0 0 0 ## [8,] 0 0 0 1 1 0 1 1 0 1 1 0 ## [9,] 1 0 0 0 0 0 0 0 1 0 0 0 ## [10,] 0 0 0 0 0 0 0 1 0 1 0 0 ## [11,] 0 0 0 0 0 0 0 1 0 0 1 0 ## [12,] 0 0 0 0 1 0 0 0 0 0 0 1 Here is what the corresponding network (with layovers) looks like. You can see why we refer to these additional edges as “loops.” However, we usually do not draw the network with these added loops to keep the figure less cluttered. g2=graph_from_adjacency_matrix(B,mode=&#39;undirected&#39;) airports = c(&quot;ATL&quot;,&quot;LAX&quot;,&quot;ORD&quot;,&quot;MSP&quot;,&quot;DEN&quot;,&quot;JFK&quot;,&quot;SFO&quot;,&quot;SEA&quot;,&quot;PHL&quot;,&quot;PDX&quot;,&quot;MDW&quot;,&quot;LGA&quot;) V(g2)$label = airports coords = layout_with_fr(g2) plot(g2, layout=coords, vertex.color=&#39;tan1&#39;, vertex.frame.color=&quot;dodgerblue&quot;) 18.3.2 Step 2 Start with the all 1’s vector \\(\\mathsf{v}_0 = [1, 1, \\ldots ,1 ]^{\\top}\\). We iterate the mapping \\(T(\\mathsf{x}) = B\\mathsf{x}\\) for a few steps to get \\(\\mathsf{v}_1 = B \\mathsf{v}_0\\) and \\(\\mathsf{v}_2 = B \\mathsf{v}_1 = B^2 \\mathsf{v}_0\\) and \\(\\mathsf{v}_3 = B \\mathsf{v}_2 = B^3 \\mathsf{v}_0\\). v0 = rep(1,nrow(B)) v1 = B %*% v0 v2 = B %*% v1 v3 = B %*% v2 df = data.frame(cbind(v0,v1,v2,v3)) #Convert vector to a data frame in order to add row names rownames(df)=airports colnames(df)=c(0,1,2,3) df ## 0 1 2 3 ## ATL 1 4 17 76 ## LAX 1 6 29 139 ## ORD 1 3 15 72 ## MSP 1 5 24 109 ## DEN 1 6 28 132 ## JFK 1 3 13 63 ## SFO 1 5 26 122 ## SEA 1 6 26 120 ## PHL 1 2 6 23 ## PDX 1 2 8 34 ## MDW 1 2 8 34 ## LGA 1 2 8 36 18.3.2.1 Your Turn Discuss with your group: Each of the entries of vector \\(\\mathsf{v}_{t}\\) corresponds to “a trip of length \\(t\\).” What kinds of trips does the \\(i\\)th entry of \\(\\mathsf{v}_{t}\\) count? Here is how you can figure this out: Compare the table of vectors with the picture of the network with layovers. Start by looking at the \\(t=1\\) column. The \\(i\\)th entry has something to do with the \\(i\\)th city. Next, look at the \\(t=2\\) column. And so on. Once you have noticed the connection between the network and data, explain why the rule \\(\\mathsf{v}_t = A \\mathsf{v}_{t-1}\\) leads to this result. 18.3.3 Step 3 We can calculate \\(\\mathsf{v}_1, \\ldots, \\mathsf{v}_{10}\\) using a loop: N = 10 X = matrix(0,nrow=nrow(B),ncol=N+1) X[,1] = rep(1,nrow(B)) for (i in 2:(N+1)) { X[,i] = B %*% X[,i-1] } X ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] ## [1,] 1 4 17 76 347 1603 7442 34638 161411 752642 3510616 ## [2,] 1 6 29 139 650 3044 14211 66352 309652 1445058 6743119 ## [3,] 1 3 15 72 343 1614 7567 35389 165336 771972 3603377 ## [4,] 1 5 24 109 507 2349 10936 50930 237450 1107376 5165837 ## [5,] 1 6 28 132 621 2909 13611 63595 296984 1386347 6470458 ## [6,] 1 3 13 63 294 1377 6418 29939 139617 651292 3038392 ## [7,] 1 5 26 122 576 2692 12585 58748 274225 1279724 5971890 ## [8,] 1 6 26 120 551 2563 11923 55591 259246 1209469 5642972 ## [9,] 1 2 6 23 99 446 2049 9491 44129 205540 958182 ## [10,] 1 2 8 34 154 705 3268 15191 70782 330028 1539497 ## [11,] 1 2 8 34 154 705 3268 15191 70782 330028 1539497 ## [12,] 1 2 8 36 168 789 3698 17309 80904 377888 1764235 df = data.frame(X) rownames(df)=airports colnames(df)=c(0:10) df ## 0 1 2 3 4 5 6 7 8 9 10 ## ATL 1 4 17 76 347 1603 7442 34638 161411 752642 3510616 ## LAX 1 6 29 139 650 3044 14211 66352 309652 1445058 6743119 ## ORD 1 3 15 72 343 1614 7567 35389 165336 771972 3603377 ## MSP 1 5 24 109 507 2349 10936 50930 237450 1107376 5165837 ## DEN 1 6 28 132 621 2909 13611 63595 296984 1386347 6470458 ## JFK 1 3 13 63 294 1377 6418 29939 139617 651292 3038392 ## SFO 1 5 26 122 576 2692 12585 58748 274225 1279724 5971890 ## SEA 1 6 26 120 551 2563 11923 55591 259246 1209469 5642972 ## PHL 1 2 6 23 99 446 2049 9491 44129 205540 958182 ## PDX 1 2 8 34 154 705 3268 15191 70782 330028 1539497 ## MDW 1 2 8 34 154 705 3268 15191 70782 330028 1539497 ## LGA 1 2 8 36 168 789 3698 17309 80904 377888 1764235 Wow, these numbers get big fast! Let’s normalize by dividing by the sum each time. N = 10 X = matrix(0,nrow=nrow(B),ncol=N+1) X[,1] = rep(1,nrow(B)) for (i in 2:(N+1)) { X[,i] = B %*% X[,i-1] X[,i] = X[,i]/sum(X[,i]) } df = data.frame(X) rownames(df)=airports colnames(df)=c(0:10) df ## 0 1 2 3 4 5 6 7 8 9 ## ATL 1 0.08695652 0.08173077 0.07916667 0.07773297 0.07708213 0.07674064 0.07657108 0.07647933 0.07643081 ## LAX 1 0.13043478 0.13942308 0.14479167 0.14560932 0.14637430 0.14654141 0.14667834 0.14671848 0.14674567 ## ORD 1 0.06521739 0.07211538 0.07500000 0.07683692 0.07761108 0.07802962 0.07823125 0.07833906 0.07839377 ## MSP 1 0.10869565 0.11538462 0.11354167 0.11357527 0.11295441 0.11277017 0.11258632 0.11250792 0.11245405 ## DEN 1 0.13043478 0.13461538 0.13750000 0.13911290 0.13988267 0.14035431 0.14058369 0.14071617 0.14078356 ## JFK 1 0.06521739 0.06250000 0.06562500 0.06586022 0.06621466 0.06618132 0.06618343 0.06615295 0.06613871 ## SFO 1 0.10869565 0.12500000 0.12708333 0.12903226 0.12944797 0.12977438 0.12986887 0.12993256 0.12995600 ## SEA 1 0.13043478 0.12500000 0.12500000 0.12343190 0.12324485 0.12294795 0.12288997 0.12283525 0.12282160 ## PHL 1 0.04347826 0.02884615 0.02395833 0.02217742 0.02144643 0.02112894 0.02098089 0.02090908 0.02087259 ## PDX 1 0.04347826 0.03846154 0.03541667 0.03449821 0.03390075 0.03369906 0.03358136 0.03353774 0.03351435 ## MDW 1 0.04347826 0.03846154 0.03541667 0.03449821 0.03390075 0.03369906 0.03358136 0.03353774 0.03351435 ## LGA 1 0.04347826 0.03846154 0.03750000 0.03763441 0.03793999 0.03813315 0.03826343 0.03833372 0.03837453 ## 10 ## ATL 0.07640399 ## LAX 0.14675521 ## ORD 0.07842281 ## MSP 0.11242772 ## DEN 0.14082110 ## JFK 0.06612665 ## SFO 0.12997042 ## SEA 0.12281194 ## PHL 0.02085358 ## PDX 0.03350515 ## MDW 0.03350515 ## LGA 0.03839628 18.3.3.1 Your Turn Discuss with your group: What do we learn from this table of normalized vectors? Interpret the vector for \\(t=10\\). Since we have normalized our vector, each entry is a proportion, rather than a raw count. Look at the entries as \\(t\\) increases. What do you observe? Iterative multiplication \\(\\mathsf{v}_t = A \\mathsf{v}_{t-1}\\) is a dynamical system! We talked about dynamical systems last week. There is a relationship between the eigenvectors of \\(A\\) and the “long term behavior” of the dynamical system. Share what you remember about this topic with your group. 18.3.4 Step 4 You have observed that the vectors are converging to a common direction. We get this final direction without saving all of the values along the way. Here we iterate 1000 steps and save the final value. This limiting vector, whose entries are scaled to sum to one, is called Gould’s Index. N = 1000 w = rep(1,nrow(B)) for (i in 2:(N+1)) { w = B %*% w w = w/sum(w) } df = data.frame(w) rownames(df)=airports colnames(df)=c(&quot;Gould Index&quot;) df ## Gould Index ## ATL 0.07637062 ## LAX 0.14676474 ## ORD 0.07845446 ## MSP 0.11239329 ## DEN 0.14086410 ## JFK 0.06611172 ## SFO 0.12998472 ## SEA 0.12280792 ## PHL 0.02083107 ## PDX 0.03349744 ## MDW 0.03349744 ## LGA 0.03842249 We saw last week that this direction must be the dominant eigenvector of \\(B\\). This dominant eigenvector is the directon that corresponds to the eigenvalue of largest magnitude. We can confirm that this is the dominant eigenvector as follows. First compute the eigenvectors. eigen(B) ## eigen() decomposition ## $values ## [1] 4.66618847 2.64207538 2.41909839 1.80037113 1.27260439 1.00000000 1.00000000 0.49835918 0.02718633 ## [10] -0.67732874 -0.92557189 -1.72298263 ## ## $vectors ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -0.23401334 0.57249329 -0.03677166 0.289569576 -0.11347970 0.000000e+00 0.000000e+00 0.17344569 ## [2,] -0.44971357 0.23508235 0.28327135 -0.009053428 0.29280642 2.626816e-16 1.203957e-16 0.27532162 ## [3,] -0.24039858 -0.04730698 0.44304618 0.102332378 0.42192015 -1.576610e-16 -4.434216e-17 -0.59911594 ## [4,] -0.34439328 0.35635470 -0.30954196 -0.120977575 0.09253829 4.851644e-01 1.208947e-01 -0.01657232 ## [5,] -0.43163295 -0.31276398 0.34545477 0.090957309 -0.17778914 1.198948e-16 1.395385e-16 0.02521939 ## [6,] -0.20257820 0.10572025 -0.24645181 -0.612347635 -0.18646435 -5.005332e-18 -9.291441e-17 -0.52296040 ## [7,] -0.39829657 -0.18275409 -0.04019741 -0.369127791 -0.14336929 -4.851644e-01 -1.208947e-01 0.27891061 ## [8,] -0.37630557 -0.32813461 -0.43931838 0.235004528 0.03236396 -1.021498e-16 -3.393381e-17 0.08250644 ## [9,] -0.06383014 0.34864008 -0.02591199 0.361794131 -0.41627977 -4.851644e-01 -1.208947e-01 -0.34575674 ## [10,] -0.10264218 -0.19982920 -0.30957570 0.293619448 0.11872135 -1.709709e-01 6.861261e-01 -0.16447314 ## [11,] -0.10264218 -0.19982920 -0.30957570 0.293619448 0.11872135 1.709709e-01 -6.861261e-01 -0.16447314 ## [12,] -0.11773343 -0.19046871 0.24343257 0.113643916 -0.65218735 4.851644e-01 1.208947e-01 -0.05027381 ## [,9] [,10] [,11] [,12] ## [1,] 0.19570619 6.653425e-01 0.08742351 0.026476499 ## [2,] 0.33415547 -4.571765e-01 -0.14917762 0.397124122 ## [3,] -0.08232149 1.379670e-01 0.40635541 -0.072909426 ## [4,] -0.32336571 -2.621537e-01 0.02623868 -0.459495824 ## [5,] -0.25407199 2.257605e-01 -0.63328894 -0.198593023 ## [6,] 0.18953651 1.563407e-01 -0.22162883 0.307139725 ## [7,] 0.13898200 -8.104161e-05 0.40052356 -0.376840313 ## [8,] -0.40482358 7.521122e-02 0.23285847 0.520458800 ## [9,] -0.20117541 -3.966679e-01 -0.04540132 -0.009723345 ## [10,] 0.41613681 -4.483988e-02 -0.12092951 -0.191135557 ## [11,] 0.41613681 -4.483988e-02 -0.12092951 -0.191135557 ## [12,] 0.26117231 -1.345953e-01 0.32888356 0.072932167 Now, we will extract the dominant eigenvector \\(\\mathsf{v}_1\\) rescale this vector to sum to 1, and display it next to the vector \\(w\\) we got above by iteration. vecs = eigen(B)$vectors gould = vecs[,1] gould = gould/sum(gould) cbind(w,gould) ## gould ## [1,] 0.07637062 0.07637062 ## [2,] 0.14676474 0.14676474 ## [3,] 0.07845446 0.07845446 ## [4,] 0.11239329 0.11239329 ## [5,] 0.14086410 0.14086410 ## [6,] 0.06611172 0.06611172 ## [7,] 0.12998472 0.12998472 ## [8,] 0.12280792 0.12280792 ## [9,] 0.02083107 0.02083107 ## [10,] 0.03349744 0.03349744 ## [11,] 0.03349744 0.03349744 ## [12,] 0.03842249 0.03842249 18.3.5 Step 5 Now let’s plot the network with: the vertices sized by Gould’s Index the labels sized by degree centrality plot(g, layout=locations, vertex.size=250*gould,vertex.label.cex=7*u, vertex.color=&#39;tan1&#39;, vertex.frame.color=&quot;dodgerblue&quot; ) And we can create a data frame containing both the Gould’s Index and the Degree Centrality. We order the data using the Gould Index and then compare the two. df = data.frame(gould, u) #Convert vector to a data frame in order to add row names rownames(df)=airports colnames(df)=c(&#39;Gould&#39;, &#39;Degree&#39;) ii=order(gould,decreasing=TRUE) df2 = data.frame(df[ii,]) rownames(df2) = airports[ii] df2 ## Gould Degree ## LAX 0.14676474 0.14705882 ## DEN 0.14086410 0.14705882 ## SFO 0.12998472 0.11764706 ## SEA 0.12280792 0.14705882 ## MSP 0.11239329 0.11764706 ## ORD 0.07845446 0.05882353 ## ATL 0.07637062 0.08823529 ## JFK 0.06611172 0.05882353 ## LGA 0.03842249 0.02941176 ## PDX 0.03349744 0.02941176 ## MDW 0.03349744 0.02941176 ## PHL 0.02083107 0.02941176 18.3.5.1 Your Turn Discuss with your group: Degree centrality and Gould’s Index give different rankings. Look at the table and observe that: LAX, DEN and SEA have the same degree centrality. However LAX and DEN have higher Gould Index than SEA. SFO has lower degree centrality than SEA, but higher Gould centrality! So these two centralities give different rankings. Remind yourselves about the intuitive idea behind Gould’s Index. What does Gould Index measure? Why does the Gould Index value SFO more than SEA? Find another pair of cities where the rankings of degree centrality and Gould’s Index differ. Look at the plot of the network and explain why this is the case. 18.3.6 Gould Index Summary Now that we understand what Gould’s Index means, let’s summarize how to find the Gould Index values for an adjacency matrix \\(A\\). Create the matrix \\(B = A+I\\). Find the dominant eigenvector \\(\\mathbf{v}\\) of \\(B\\). Normalize the values of \\(\\mathbf{v}\\) so that the entries sum to 1. 18.4 Your Turn: The Rise of Moscow Russian historians often attribute the dominance and rise to power of Moscow to its strategic position on medieval trade routes (see Figure 1). Others argue that sociological and political factors aided Moscow’s rise to power, and thus Moscow did not rise to power strictly because of its strategic location on the trade routes. The figure below shows the major cities and trade routes of medieval Russia. Let’s use Gould’s Index to form a geographer’s opinion about this debate. Either: Moscow’s location was the primary reason for its rise to power, or Other forces must have come into play. Here is the adjacency matrix for this transportation network into an adjacency matrix and a plot of the network. RusCity = c(&quot;Novgorod&quot;, &quot;Vitebsk&quot;, &quot;Smolensk&quot;, &quot;Kiev&quot;, &quot;Chernikov&quot;, &quot;Novgorod Severskij&quot;, &quot;Kursk&quot;, &quot;Bryansk&quot;, &quot;Karachev&quot;, &quot;Kozelsk&quot;, &quot;Dorogobusch&quot;, &quot;Vyazma&quot;, &quot;A&quot;, &quot;Tver&quot;, &quot;Vishnij Totochek&quot;, &quot;Ksyatyn&quot;, &quot;Uglich&quot;, &quot;Yaroslavl&quot;, &quot;Rostov&quot;, &quot;B&quot;, &quot;C&quot;, &quot;Suzdal&quot;, &quot;Vladimir&quot;, &quot;Nizhnij Novgorod&quot;, &quot;Bolgar&quot;, &quot;Isad&#39;-Ryazan&quot;, &quot;Pronsk&quot;, &quot;Dubok&quot;, &quot;Elets&quot;, &quot;Mtsensk&quot;, &quot;Tula&quot;, &quot;Dedoslavl&quot;, &quot;Pereslavl&quot;, &quot;Kolomna&quot;, &quot;Moscow&quot;, &quot;Mozhaysk&quot;, &quot;Dmitrov&quot;, &quot;Volok Lamskij&quot;, &quot;Murom&quot;) A = rbind(c(0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0), c(0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0), c(1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)) g=graph_from_adjacency_matrix(A,mode=&#39;undirected&#39;) V(g)$label = RusCity # Plot network plot(g) 18.4.1 Find the Degree Centrality values. Create a vector containing the normalized Degree Centralities. See Section 18.2 for help. 18.4.2 Find the Gould Index values Create a vector containing the Gould Index values. See Section 18.3.6 for help. 18.4.3 Analyze the Data Plot the network where the size of the vertices is determined by Gould’s Index and the size of the label is determined by degree centrality. Create a data frame that contains Gould’s Index and Degree Centralities. The rows should be labeled with the city names and the columns should be named by the centrality measures. Sort according to Gould’s Index. Use Gould’s Index to decide whether Moscow’s dominance was solely due to its geographic location. Compare the Gould’s Index and Degree Centrality rankings and note any interesting findings. See Section 18.3.5 for help. "],["voting-patterns-in-the-us-senate.html", "Vector 19 Voting Patterns in the US Senate 19.1 The Data 19.2 The 88th Congressional Session (1964) 19.3 Using the Eigenbasis 19.4 Your Turn", " Vector 19 Voting Patterns in the US Senate Download this Rmd file In 2014, the Pew Research Center published a report about the increasing polarization of US politics. They wrote: Republicans and Democrats are more divided along ideological lines – and partisan antipathy is deeper and more extensive – than at any point in the last two decades. These trends manifest themselves in myriad ways, both in politics and in everyday life. Is this really true, or is this just hype? Let’s see what linear algebra can tell us about the evolution of voting patterns in the US Senate from 1964 to 2012. 19.1 The Data We will analyze datasets corresponding to US Senate votes during a 2-year Congressional Session. Our data sets are 12 years apart, and were chosen to coincide with US election years. Table 19.1: Congressional Sessions of the US Senate Session Years US Election # Floor Votes 84 1963-1965 Lyndon Johnson vs Richard Nixon 534 94 1975-1977 Jimmy Carter vs Gerald Ford 1311 100 1987-1989 George H. W. Bush vs Michael Dukakis 799 106 1999-2001 George W. Bush vs Al Gore 672 112 2011-2013 Barack Obama vs John McCain 486 Here is a list our our data files, which we will load from Github. The original data can be found at voteview.com. There are two files for each year. A csv file containing a matrix whose \\((i,j)\\) entry counts the number of times Senator \\(i\\) and Senator \\(j\\) cast the same vote on an issue. There are actually nine different possibilities, including Yea, Nay, Present, Abstention and “Not a member of the chamber when the vote was taken.” A csv file containing senator information: name, state and party affiliation. senate.1964.files = c(&#39;https://raw.github.com/mathbeveridge/math236_f20/main/data/Senate088matrix.csv&#39;, &#39;https://raw.github.com/mathbeveridge/math236_f20//main/data/Senate088senators.csv&#39;) senate.1976.files = c(&#39;https://raw.github.com/mathbeveridge/math236_f20/main/data/Senate094matrix.csv&#39;, &#39;https://raw.github.com/mathbeveridge/math236_f20//main/data/Senate094senators.csv&#39;) senate.1988.files = c(&#39;https://raw.github.com/mathbeveridge/math236_f20/main/data/Senate100matrix.csv&#39;, &#39;https://raw.github.com/mathbeveridge/math236_f20//main/data/Senate100senators.csv&#39;) senate.2000.files = c(&#39;https://raw.github.com/mathbeveridge/math236_f20/main/data/Senate106matrix.csv&#39;, &#39;https://raw.github.com/mathbeveridge/math236_f20//main/data/Senate106senators.csv&#39;) senate.2012.files = c(&#39;https://raw.github.com/mathbeveridge/math236_f20/main/data/Senate112matrix.csv&#39;, &#39;https://raw.github.com/mathbeveridge/math236_f20//main/data/Senate112senators.csv&#39;) 19.2 The 88th Congressional Session (1964) Let’s load in our data. # pick the data set that we want to look at senate.files = senate.1964.files # First we load in the information about the senators. # We will use these names as our labels. # We also set up the colors we will use for our data points. senators &lt;- read.csv(senate.files[2], header=FALSE) sen.name = senators[,2] sen.party = senators[,4] sen.color=rep(&quot;chartreuse&quot;, length(senators)) sen.color[sen.party==&#39;D&#39;]=&quot;cornflowerblue&quot; sen.color[sen.party==&#39;R&#39;]=&quot;firebrick&quot; # Next we load in the square matrix that measures how often senators voted together. # We add names for the columns and rows. votes &lt;- read.csv(senate.files[1], header=FALSE) names(votes) &lt;- sen.name row.names(votes) &lt;- sen.name knitr::kable( head(votes), booktabs = TRUE, caption = &#39;Congressional Sessions of the US Senate&#39; ) Table 19.2: Congressional Sessions of the US Senate AIKEN George David ALLOTT Gordon Llewellyn ANDERSON Clinton Presba BARTLETT Edward Lewis (Bob) BEALL James Glenn BENNETT Wallace Foster BIBLE Alan Harvey BOGGS James Caleb BREWSTER Daniel Baugh BURDICK Quentin Northrup BYRD Harry Flood BYRD Robert Carlyle CANNON Howard Walter CARLSON Frank CASE Clifford Philip CHURCH Frank Forrester CLARK Joseph Sill COOPER John Sherman COTTON Norris H. CURTIS Carl Thomas DIRKSEN Everett McKinley DODD Thomas Joseph DOUGLAS Paul Howard EASTLAND James Oliver ELLENDER Allen Joseph ENGLE Clair ERVIN Samuel James Jr. FONG Hiram Leong FULBRIGHT James William GOLDWATER Barry Morris GORE Albert Arnold GRUENING Ernest Henry HART Philip Aloysius HARTKE Rupert Vance HAYDEN Carl Trumbull HICKENLOOPER Bourke Blakemore HILL Joseph Lister HOLLAND Spessard Lindsey HRUSKA Roman Lee HUMPHREY Hubert Horatio Jr. INOUYE Daniel Ken JACKSON Henry Martin (Scoop) JAVITS Jacob Koppel JOHNSTON Olin DeWitt Talmadge JORDAN Benjamin Everett KEATING Kenneth Barnard KEFAUVER Carey Estes KUCHEL Thomas Henry LAUSCHE Frank John LONG Edward Vaughn LONG Russell Billiu MAGNUSON Warren Grant MANSFIELD Michael Joseph (Mike) McCARTHY Eugene Joseph McCLELLAN John Little McGEE Gale William McGOVERN George Stanley McNAMARA Patrick Vincent METCALF Lee Warren MONRONEY Almer Stillwell Mike MORSE Wayne Lyman MORTON Thruston Ballard MOSS Frank Edward (Ted) MUNDT Karl Earl MUSKIE Edmund Sixtus NEUBERGER Maurine Brown PASTORE John Orlando PROUTY Winston Lewis PROXMIRE William RANDOLPH Jennings RIBICOFF Abraham Alexander ROBERTSON Absalom Willis RUSSELL Richard Brevard Jr. SALTONSTALL Leverett SCOTT Hugh Doggett Jr. SMATHERS George Armistead SMITH Margaret Chase SPARKMAN John Jackson STENNIS John Cornelius SYMINGTON William Stuart (Stuart) TALMADGE Herman Eugene WILLIAMS Harrison Arlington Jr. WILLIAMS John James YARBOROUGH Ralph Webster YOUNG Milton Ruben YOUNG Stephen Marvin DOMINICK Peter Hoyt BAYH Birch Evans EDMONDSON James Howard JORDAN Leonard Beck (Len) KENNEDY Edward Moore (Ted) McINTYRE Thomas James MECHEM Edwin Leard MILLER Jack Richard NELSON Gaylord Anton PEARSON James Blackwood PELL Claiborne de Borda SIMPSON Milward Lee TOWER John Goodwin THURMOND James Strom WALTERS Herbert Sanford SALINGER Pierre Emil George AIKEN George David 0 321 252 302 336 287 282 384 286 297 155 246 245 318 366 294 254 316 259 248 302 301 322 172 175 58 201 377 183 128 215 248 292 259 185 308 198 218 243 310 326 302 339 183 199 379 33 394 287 275 155 262 258 278 201 288 298 285 289 301 265 266 280 306 316 256 320 425 334 292 318 173 181 326 321 160 416 217 187 292 190 305 296 219 290 296 286 287 227 323 221 331 215 328 316 297 306 248 187 182 124 26 ALLOTT Gordon Llewellyn 321 0 221 251 293 326 266 344 237 250 171 196 234 322 289 237 172 296 260 286 286 255 239 163 193 50 191 326 137 139 157 218 219 200 147 287 179 227 269 235 257 271 272 169 205 296 14 310 285 237 141 237 203 222 211 235 230 204 227 253 230 285 235 323 246 178 239 340 278 240 247 204 177 284 292 127 323 183 199 244 196 232 288 190 294 228 339 221 225 344 159 263 244 320 236 327 234 321 240 208 129 17 ANDERSON Clinton Presba 252 221 0 304 258 175 302 248 322 303 106 254 298 215 290 287 279 227 170 142 187 286 279 138 161 82 173 256 193 114 213 256 308 284 213 180 186 179 132 303 338 287 276 203 190 280 40 284 190 265 178 278 255 296 155 276 308 305 303 310 255 191 298 201 321 253 301 235 271 283 303 129 136 223 248 186 295 200 165 289 182 299 166 238 219 263 182 302 290 203 280 332 135 215 299 214 289 144 111 114 137 21 BARTLETT Edward Lewis (Bob) 302 251 304 0 288 201 363 291 349 386 133 318 323 258 335 359 335 264 182 162 213 351 355 150 187 83 196 313 237 75 264 340 370 328 252 216 245 221 154 395 419 349 332 263 230 332 48 317 205 328 209 335 325 361 196 362 377 375 374 389 328 208 334 230 401 327 377 284 336 349 379 162 175 249 286 215 334 250 185 333 206 378 193 285 256 326 200 348 291 220 292 400 141 233 379 215 377 159 110 144 150 37 BEALL James Glenn 336 293 258 288 0 274 290 357 279 290 170 227 249 307 330 250 243 278 268 249 254 315 306 152 156 57 191 355 168 149 194 256 286 270 174 271 183 194 255 280 310 292 327 201 207 367 24 352 248 264 158 256 223 260 188 262 276 266 258 275 275 255 247 295 284 241 292 349 326 286 310 175 182 287 347 145 368 179 170 307 198 295 278 216 267 293 292 266 236 318 219 315 238 304 295 306 289 249 225 189 124 32 BENNETT Wallace Foster 287 326 175 201 274 0 249 337 178 183 238 198 212 296 233 185 135 270 317 343 290 199 189 212 226 37 244 284 162 220 162 200 167 156 124 336 189 238 328 176 205 215 223 203 231 251 14 263 282 188 191 178 151 163 241 189 176 161 173 208 203 267 181 360 185 151 188 305 246 198 189 239 244 261 264 148 274 204 253 207 245 184 349 177 286 184 329 171 198 393 109 223 307 321 181 300 195 370 303 290 143 17 Looking at this table, we see that Aiken voted with Allott 321 times. Aiken voted with Anderson 252 times. Allot voted with Anderson 221 times. And so on. We also should note that ** each “coordinate” represents a senator. Coordinate 1 is “Aiken.” Coordinate 2 is “Allot,” etc. This interpretation will be important later! 19.3 Using the Eigenbasis As the table above notes, there are 102 Senators in our data set. So each Senator is represented by a vector in \\(\\mathbb{R}^{102}\\). This vector represents how similar the Senator is to each colleague. But just because our data lives in \\(\\mathbb{R}^{102}\\) doesn’t mean that it is inherently 102-dimensional! We can draw a line in \\(\\mathbb{R}^3\\). That line is 1-dimensional, even though it lives in a higher dimensional space. Maybe if we find a good basis for \\(\\mathbb{R}^{102}\\) then we can detect some interesting features of the data set. So what happens if we use an eigenbasis? We know that this basis is custom-made for our matrix. Here is what we will observe: The basis of eigenvector of our matrix will pick up some patterns in our data. The eigenvectors corresponding to the largest eigenvalues are the most important ones when modeling our column space. This is where the patterns are! The eigenvectors for the small eigenvalues don’t really matter. They just pick up “noise” in the data. In other words: Our data set will be “essentially low dimensional” (maybe only 3D or 4D) even though it lives in a high dimensional space. Moreover, the structure of the eigenvectors (for the large eigenvalues) will reflect the prevalent patterns in the data. 19.3.1 Using the Dominant Eigenvectors. First we will find the eigenvalues and eigenvectors. mat = data.matrix(votes) eigsys = eigen(mat) eigsys$values ## [1] 24198.14970 4385.33792 2523.42898 413.59778 274.12291 219.84394 93.86570 -19.59596 -39.68442 ## [10] -73.58725 -84.08451 -124.18257 -137.88542 -155.95645 -162.94701 -176.71449 -183.14311 -197.74427 ## [19] -203.16191 -219.90337 -222.98559 -225.77864 -236.01870 -240.90787 -249.06305 -257.49697 -263.81555 ## [28] -268.10860 -272.63265 -275.30214 -279.92416 -280.34948 -287.69592 -292.00408 -296.93484 -299.17667 ## [37] -303.67128 -309.89778 -314.33373 -318.90633 -320.25895 -321.98658 -326.58688 -327.83596 -332.06144 ## [46] -336.46538 -338.76991 -343.48455 -346.38591 -348.16746 -349.23190 -350.47588 -358.25692 -359.24338 ## [55] -360.90037 -363.21807 -365.17417 -370.46006 -371.56674 -374.12517 -379.23090 -380.38760 -382.65978 ## [64] -384.71680 -388.62093 -389.78271 -391.81075 -394.10770 -396.11524 -400.65534 -401.80357 -405.81092 ## [73] -407.44165 -410.46333 -411.66607 -412.99086 -416.39535 -418.09114 -418.76583 -422.02379 -424.59269 ## [82] -426.38701 -428.84359 -430.30353 -431.59921 -435.24536 -435.91447 -437.63064 -439.58808 -443.56104 ## [91] -445.20242 -447.99489 -451.15747 -453.68351 -454.57543 -458.33775 -461.38347 -463.97462 -467.11710 ## [100] -469.27240 -474.43223 -475.75931 What do we see? The largest eigenvalue \\(\\approx 24200\\) is huge compared to the others! There is a huge gap after that. So this eigenspace is the most important (by far)! The second and third eigenvectors are still pretty big \\(\\approx 4400\\) and \\(\\approx 2500\\). But then we have another big gap: the rest have magnitudes below 500. So it seems like this data set is “roughly” 3-dimensional. Of course, this isn’t technically correct because our matrix is invertible (all the eigenvalues are nonzero). But you can think of this data set as a “cloud of points” around a 3D subspace of \\(\\mathbb{R}^{102}\\). 19.3.2 Patterns in the First Two Eigenvectors Let’s create a plot of the first two eigenvectors. Each point represents a Senator. # let&#39;s give simple names to our top eigenvectors v1 = eigsys$vectors[,1] v2 = eigsys$vectors[,2] v3 = eigsys$vectors[,3] v4 = eigsys$vectors[,4] v5 = eigsys$vectors[,5] # Plot use v1 for the x-axis and v2 for the y-axis # We color the points by the party of the Senator xdir = v1 ydir = v2 plot(xdir, ydir, col=sen.color) During class, we will talk about how to think about this picture. We will also compare this plot to plots made using the other eigenvectors. 19.3.3 Creating a Table Sorted by an Eigenvector When we get to more contemporary data, it will be fun later on to look at the names of the Senators who get large (positive or negative) eigenvector scores. Here is some code to help with that. myorder= order(v1) eigendata = data.frame(cbind(v1,v2, sen.party)) rownames(eigendata)=sen.name myorder= order(v1) knitr::kable( head(eigendata[myorder,]), booktabs = TRUE, caption = &#39;One Extreme&#39; ) Table 19.3: One Extreme v1 v2 sen.party INOUYE Daniel Ken -0.124510990388193 0.0960716902237526 D McINTYRE Thomas James -0.123097587465213 0.0793272186071726 D SMITH Margaret Chase -0.120654354853401 0.0290668793843522 R MUSKIE Edmund Sixtus -0.118947766632202 0.0997692334878442 D MONRONEY Almer Stillwell Mike -0.118641982145802 0.0596868115454118 D HUMPHREY Hubert Horatio Jr. -0.118613491347109 0.112820684546629 D myrevorder = order(-v1) knitr::kable( head(eigendata[myrevorder,]), booktabs = TRUE, caption = &#39;The Other Extreme&#39; ) Table 19.3: The Other Extreme v1 v2 sen.party SALINGER Pierre Emil George -0.011895821132766 0.00841073422406016 D KEFAUVER Carey Estes -0.0154423731600536 0.0140931934686823 D ENGLE Clair -0.0307343177099913 0.0102249015658184 D GOLDWATER Barry Morris -0.0482357085359829 -0.118817158736983 R WALTERS Herbert Sanford -0.0605618365871763 -0.0767520789280585 D BYRD Harry Flood -0.0665699568843238 -0.172435813910847 D 19.4 Your Turn The data for the 88th Congressional Session (1964) does not seem very partisan. Democrats and Republicans are finding plenty of common ground. When we look at the “extremes” we find some recognizable names, including Hubert Humphrey (D) and Barry Goldwater (R). But there is no clear “left” or “right” pattern to the party affiliation. What about the remaining 5 data sets? It’s your turn to explore and discuss. The code above has been written for ease of reuse. Go back to the top and change the following line: # pick the data set that we want to look at senate.files = senate.1964.files to one of the other options: senate.1976.files, senate.1988.files, senate.2000.files, senate.2012.files Do a similar analysis as described above, as well as the things we tried in class together. Find the eigenvalues. Where are the gaps? What is the rough “dimension” of each data set? Plotting the two dominant eigenvectors. Do you see evidence of political divission? Then try plotting other pairs of eigenvectors. Which ones are just noise? Create tables of the two extreme for the dominant eigenvectors. Do you see any names that you recognize? Finally, you have some evidence to help you to answer the orignal question: “Is US Politics more polarized than ever before?” "],["modeling-of-ecological-systems.html", "Vector 20 Modeling of Ecological Systems 20.1 Northern Spotted Owl Population 20.2 More recent numbers for Northern Spotted Owls 20.3 Brook Trout in Hunt Creek, MI", " Vector 20 Modeling of Ecological Systems Download this Rmd file 20.1 Northern Spotted Owl Population We model the population dyamics of the Northern Spotted Owls using a Leslie Matrix. The age classes for the spotted owls are: juvenile (less than 1 year old) subadult (1 to 2 years old) adult (over 2 years old) and the Leslie Matrix is: \\[L=\\begin{bmatrix} 0&amp;0&amp;0.33 \\\\ 0.18 &amp; 0 &amp; 0 \\\\ 0 &amp; 0.71 &amp; 0.94 \\end{bmatrix}.\\] 20.1.1 Population forecast Suppose that we started out with 200 juveniles, 300 subadults and 500 adults. What happens to this population over time? ## [,1] [,2] [,3] ## [1,] 0.00 0.00 0.33 ## [2,] 0.18 0.00 0.00 ## [3,] 0.00 0.71 0.94 This code shows the population dynamics. You shouldn’t need to edit this. ### this code follows the populations for N steps m = dim(L)[1] # m is the number of rows of L X = matrix(0,nrow=m,ncol=N) # Store the results in a (m x N) matrix called X X[,1] = start # put start in the first column of X # loop N times and put your results in X for (i in 2:N) { X[,i] = L %*% X[,i-1] # here is the loop } #### this code plots the populations in the (m x N) matrix X t = seq(1,N) # time # Expand right side of clipping rect to make room for the legend par(xpd=T, mar=par()$mar+c(0,0,0,7)) # Plot graph plot(t,X[1,],type=&#39;l&#39;,col=1,ylim=c(0,1000),ylab=&quot;population&quot;,xlab=&quot;time (year)&quot;, main=&quot;Population in Age Group&quot;) for (i in 1:m) { lines(t,X[i,],col=i) points(t,X[i,],col=i,pch=20,cex=.8) } # Plot legend where you want legend(60,1000,c(&quot;(0-1)&quot;, &quot;(1-2)&quot;, &quot;(over 2)&quot;), col=1:m, lty = 1) # Restore default clipping rect par(mar=c(5, 4, 4, 2) + 0.1) 20.1.2 Your Turn Change the code above to run for \\(N=100\\) iteratons, and then \\(N=200\\). Can you now make a stronger statement about the long-term population? Use eigenvalues and eigenvectors to explain the asymptotic behavior of the system. You can use the function eigen(A) to compute the eigenvalues and eigenvectors of a matrix. 20.2 More recent numbers for Northern Spotted Owls More recent spotted owl data give the following entries for the Leslie Matrix of the spotted owl population: Juvenile Survival 0.33 Subadult Survival 0.85 Adult Survival 0.85 Subadult Fecundity 0.125 Adult Fecundity 0.26 20.2.1 Find the long-range populations Using this data, determine the long-range population of the Northern Spotted Owl. Are the prospects for the owl better or worse than the original data given above? This code shows the population dynamics. You shouldn’t need to edit this. 20.3 Brook Trout in Hunt Creek, MI Here is the Leslie Matrix of a population of brook trout in Hunt Creek in Michigan. The population is categorized into 5 age categories: fingerlings (0,1), yearlings (1-2), young adults (2-3), adults (3-4), and adults (4-5). Right now the population is seen to be dying off. 20.3.1 The Leslie Matrix Explain, in words, the meaning of each of the non-zero entries of the matrix \\(L\\). ## [,1] [,2] [,3] [,4] [,5] ## [1,] 0.00 0.00 37.00 64.00 82 ## [2,] 0.05 0.00 0.00 0.00 0 ## [3,] 0.00 0.28 0.00 0.00 0 ## [4,] 0.00 0.00 0.16 0.00 0 ## [5,] 0.00 0.00 0.00 0.08 0 20.3.2 Find the long-range populations Here are the population dynamics. Calculate the eigenvalues for \\(L\\) and match what you see to the plot of he populations. What do you conclude about the long-range population? start = c(100,100,100,100,100) # the starting distribution N = 30 # N is the number of iterations m = dim(L)[1] X = matrix(0,nrow=5,ncol=N) # Store the results in a 3 x N matrix called X X[,1] = start # put start in the first column of X # loop N times and put your results in X for (i in 2:N) { X[,i] = L %*% X[,i-1] # here is the loop } t = seq(1,N) # time # Expand right side of clipping rect to make room for the legend par(xpd=T, mar=par()$mar+c(0,0,0,7)) plot(t,X[1,],type=&#39;l&#39;,col=1,ylim=c(0,8000),ylab=&quot;population&quot;,xlab=&quot;time (year)&quot;, main=&quot;Population in Age Group&quot;) for (i in 1:m) { lines(t,X[i,],col=i) points(t,X[i,],col=i,pch=20,cex=.8) } legend(25, 5000, legend=c(&quot;Fingerlings (0-1)&quot;, &quot;Yearlings (1-2)&quot;, &quot;Young Adults (2-3)&quot;,&quot;Adults (3-4)&quot;,&quot;Adults (4-5)&quot;), col=1:m, lty=1) # Restore default clipping rect par(mar=c(5, 4, 4, 2) + 0.1) 20.3.3 River Clean Up A river clean up effort is being conducted with the hope of increasing the rate of survival from fingerlings to yearlings. - To what level does that survival rate need to be increased to in order for the population to reach a steady state? Find your answer (accurate up to 3 decimal places) by trial and error. (You only need to change a single entry of \\(L\\). Which one?) - What are the population percentages in the stable population? ## [,1] [,2] [,3] [,4] [,5] ## [1,] 0.00 0.00 37.00 64.00 82 ## [2,] 0.05 0.00 0.00 0.00 0 ## [3,] 0.00 0.28 0.00 0.00 0 ## [4,] 0.00 0.00 0.16 0.00 0 ## [5,] 0.00 0.00 0.00 0.08 0 This code shows the population dynamics. You shouldn’t need to edit this. "],["quiz-1-review.html", "Vector 21 Quiz 1 Review 21.1 Overview 21.2 Practice Problems 21.3 Solutions to Practice Problems", " Vector 21 Quiz 1 Review 21.1 Overview Our first quiz covers sections 1.1 - 1.9 in Lay’s book. This corresponds to Problem Sets 1,2,3. 21.1.1 Vocabulary and Concepts You should understand these concepts and be able to read and use these terms correctly: elementary row operations REF and RREF pivot position linear combination span linear independence homogeneous and nonhomogeneous equations Understand the geometric relationship between the solutions to \\(Ax = 0\\) and \\(Ax=b\\) Understand Theorem 4 in Section 1.4 which says that the following are equivalent (they are all true or are all false) for an \\(m \\times n\\) matrix \\(A\\) For each \\(b\\) in \\(\\mathbb{R}^m\\), \\(A x = b\\) has a solution Each \\(b\\) in \\(\\mathbb{R}^m\\) is a linear combination of the columns of \\(A\\) The columns of \\(A\\) span \\(\\mathbb{R}^m\\) \\(A\\) has a pivot in every row. The columns of \\(A\\) are linearly independent if and only if \\(Ax=0\\) only has the trivial solution Understand Theorem 8 in Section 1.7: if you have more than \\(n\\) vectors in \\(\\mathbb{R}^n\\) they must be linearly dependent. linear transformation one-to-one and onto Understand Theorem 12 in Section 1.9 which states that \\(T(x)=Ax\\) is onto if and only if the column of \\(A\\) span \\(\\mathbb{R}^m\\) \\(T(x)=Ax\\) is one-to-one if and only if the columns of \\(A\\) are linearly independent. 21.1.2 Skills You should be able to perform these linear algebra tasks. Identify linear systems from nonlinear systems Make the augmented matrix from a set of equations Row reduce a system of equations into Row Echelon Form (REF) and Reduced Row Echelon Form (RREF) Write the solution set to \\(Ax=b\\) as a parametric vector equation. Convert back and forth between systems of equations, vector equations, and matrix equations. Compute the matrix-vector product \\(Ax\\) Determine whether a set of vectors is linearly dependent or independent Find a dependence relation among a set of vectors Decide if a set of vectors span \\(\\mathbb{R}^n\\) Manipulate matrix vector products using: \\(A(x + y) = Ax + Ay\\) and \\(A(c x) = c A x\\) Determine whether a linear transformation is one-to-one and/or onto Find the standard matrix for a linear transformation Give geometric descriptions of linear transformations \\(T: \\mathbb{R}^2 \\rightarrow \\mathbb{R}^2\\) 21.2 Practice Problems I have performed some row operations below for you on a matrix \\(A\\). Write out the complete set of solutions to \\(A \\mathsf{x} = {\\bf 0}\\). \\[ A= \\begin{bmatrix} 1&amp; 2&amp; 0&amp; 2&amp; 0&amp; -1 \\\\ 1&amp; 2&amp; 1&amp; 1&amp; 0&amp; -2 \\\\ 2&amp; 4&amp; -2&amp; 6&amp; 1&amp; 2 \\\\ 1&amp; 2&amp; 0&amp; 2&amp; -1&amp; -3 \\\\ \\end{bmatrix} \\longrightarrow \\begin{bmatrix} 1&amp; 2&amp; 0&amp; 2&amp; 0&amp; -1\\\\ 0&amp; 0&amp; 1&amp; -1&amp; 0&amp; -1\\\\ 0&amp; 0&amp; 0&amp; 0&amp; 1&amp; 2\\\\ 0&amp; 0&amp; 0&amp; 0&amp; 0&amp; 0\\\\ \\end{bmatrix} \\] I have performed some row operations below for you on a matrix \\(B\\). \\[ B= \\begin{bmatrix} 1&amp; 1&amp; 0 \\\\ 0&amp; 1&amp; 1 \\\\ 2&amp; 1&amp; 2 \\\\ 1&amp; -1&amp; 1 \\\\ 2&amp; 3&amp; 1 \\\\ \\end{bmatrix} \\longrightarrow \\begin{bmatrix} 1&amp; 0&amp; 0 \\\\ 0&amp; 1&amp; 0 \\\\ 0&amp; 0&amp; 1 \\\\ 0&amp;0&amp;0 \\\\ 0&amp;0&amp;0 \\\\ \\end{bmatrix} \\] Describe the solutions to the equation \\(B \\mathsf{x} = {\\bf 0}\\). Fill in the boxes: the transformation \\(T(\\mathsf{x}) = B\\mathsf{x}\\) is a linear transformation from \\(\\mathbb{R}^{\\square}\\) to \\(\\mathbb{R}^{\\square}\\). I want to know if it is possible to write \\(\\mathsf{w}\\) as a linear combination of the vectors \\(\\mathsf{v}_1, \\mathsf{v}_2, \\mathsf{v}_3\\) below. Write down, but do not solve, a matrix equation that would solve this problem. Your answer should be of the form \\(A \\mathsf{x} = \\mathsf{b}\\), where I can clearly see what \\(A, \\mathsf{x}\\), and \\(\\mathsf{b}\\) are. I should also be able to tell how many unknowns there are. \\[ \\mathsf{v}_1 = \\left[ \\begin{matrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\\\ \\end{matrix}\\right] , \\quad \\mathsf{v}_2 = \\left[ \\begin{matrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\end{matrix}\\right] , \\quad \\mathsf{v}_3 = \\left[ \\begin{matrix} 1 \\\\ 1 \\\\ 0 \\\\ -2 \\\\ \\end{matrix}\\right] , \\quad \\mathsf{w} = \\left[ \\begin{matrix} 1 \\\\ -8 \\\\ -11 \\\\ -24 \\\\ \\end{matrix}\\right] . \\] Describe all vectors that are not in the span of the columns of the matrix \\(A\\) below: \\[ A= \\begin{bmatrix} 1&amp; 2&amp; 4 \\\\ -3&amp; -5&amp; -11\\\\ 1&amp; 1&amp; 3 \\\\ \\end{bmatrix} \\] The matrix below is \\(3 \\times 3\\) but the third column is missing. Add a nonzero third column so that the columns of \\(A\\) are linearly dependent and add a 3rd column so that the columns of \\(A\\) are linearly independent. Briefly describe your strategy. \\[ \\begin{bmatrix} 1&amp; 0 &amp; \\quad \\\\ 0&amp; 1&amp; \\quad \\\\ 2&amp; 2&amp; \\quad \\\\ \\end{bmatrix} \\qquad\\qquad \\begin{bmatrix} 1&amp; 0 &amp; \\quad \\\\ 0&amp; 1&amp; \\quad \\\\ 2&amp; 2&amp; \\quad \\\\ \\end{bmatrix} \\] In each case below, find the matrix of the linear transformation that is described, if you believe that the matrix exists. Otherwise, demonstrate that the transformation is not linear. The transformation \\(T\\) is given by: \\[T \\left( \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\end{bmatrix}\\right) = \\begin{bmatrix} x_1 + x_2 \\\\ 2 x_1 \\\\ -x_2 \\\\\\end{bmatrix}. \\] The transformation \\(T\\) is given by: \\[T \\left( \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} \\right)= \\begin{bmatrix} x_1 + x_2 + x_3 \\\\ x_1 x_2 \\\\ -x_2 + 2 x_3 \\end{bmatrix}. \\] The transformation \\(L: \\mathbb{R}^2 \\to \\mathbb{R}^2\\) sends the shaded region on the left to the the shaded region on the right such that \\(A\\) maps to \\(A\\), \\(B\\) maps to \\(B\\), \\(C\\) maps to \\(C\\), and \\(D\\) maps to \\(D\\). \\(\\qquad \\qquad\\) The transformation \\(R: \\mathbb{R}^2 \\to \\mathbb{R}^2\\) sends the shaded region on the left to the the shaded region on the right such that \\(A\\) maps to \\(A\\), \\(B\\) maps to \\(B\\), \\(C\\) maps to \\(C\\), and \\(D\\) maps to \\(D\\). \\(\\qquad \\qquad\\) Write the following systems of equations in vector and matrix form. \\[ \\begin{array} {ccccccccccc} 5 x_1 &amp;+&amp; 3 x_2 &amp;+&amp; x_3 &amp;+&amp; 11 x_4 &amp;-&amp; x_5 &amp;=&amp; 10 \\\\ 4 x_1 &amp;+&amp; x_2 &amp;+&amp; 3 x_3 &amp;+&amp; 2 x_4 &amp;+&amp; 6 x_5 &amp;=&amp; 11 \\\\ - x_1 &amp;+&amp; 3 x_2 &amp;-&amp; 2 x_3 &amp;+&amp; x_4 &amp;+&amp; 6 x_5 &amp;=&amp; 12 \\\\ \\end{array} \\] Let \\(\\mathsf{v}_1, \\mathsf{v}_2, \\mathsf{v}_3, \\mathsf{v}_4\\) be the vectors in the columns of the matrix \\(A\\) below. \\[ A = \\left[ \\begin{array}{cccc} 1 &amp; 1 &amp; 3 &amp; 1 \\\\ 2 &amp; 0 &amp; 2 &amp; 3 \\\\ 1 &amp; 1 &amp; 3 &amp; 1 \\\\ -1 &amp; 0 &amp; -1 &amp; 0 \\end{array} \\right] \\longrightarrow \\left[ \\begin{array}{cccc} 1 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 2 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{array} \\right] \\] Are the vectors \\(\\mathsf{v}_1, \\mathsf{v}_2, \\mathsf{v}_3, \\mathsf{v}_4\\) linear independent or dependent? If they are linearly dependent, please give a dependence relation among them. Describe the span of the vectors \\(\\mathsf{v}_1, \\mathsf{v}_2, \\mathsf{v}_3, \\mathsf{v}_4\\) inside of \\(\\mathbb{R}^4\\)? Find a solution to \\(A \\mathsf{x}=0\\) that no one else in the class has. \\[ A = \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 4 \\\\ 2 &amp; 0 &amp; 4 &amp; 1 &amp; 4 \\\\ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 4 \\\\ 1 &amp; 0 &amp; 2 &amp; 1 &amp; 3 \\end{bmatrix} \\longrightarrow \\begin{bmatrix} 1 &amp; 0 &amp; 2 &amp; 0 &amp; 1 \\\\ 0 &amp; 1 &amp; -1 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 2 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix} \\] Let \\(T: \\mathbb{R}^n \\to \\mathbb{R}^m\\) be a linear transformation. Let \\(\\mathsf{u}, \\mathsf{v}, \\mathsf{w}\\) be a linearly independent set in \\(\\mathbb{R}^n\\), and suppose that \\(T(\\mathsf{u}), T(\\mathsf{v}), T(\\mathsf{w})\\) is a linearly dependent set in \\(\\mathbb{R}^m\\). State precisely what it means for \\(T(\\mathsf{u}), T(\\mathsf{v}), T(\\mathsf{w})\\) to be linearly dependent. Use the properties of a linear transformation to demonstrate that \\(T(\\mathsf{x}) = \\mathbf{0}\\) has a nontrivial solution. 21.3 Solutions to Practice Problems The parametric vector form of the solution is \\[\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5 \\\\ x_6 \\\\ \\end{bmatrix} = s \\begin{bmatrix} -2 \\\\ 1 \\\\ 0 \\\\ 0 \\\\0 \\\\ 0 \\end{bmatrix} + t \\begin{bmatrix} -2 \\\\ 0 \\\\ 1 \\\\ 1 \\\\0 \\\\ 0 \\end{bmatrix} u \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\\\-2 \\\\ 1 \\end{bmatrix}\\] There is one solution: \\(\\mathsf{x} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\\). The transformation \\(T(\\mathsf{x}) = B\\mathsf{x}\\) is a linear transformation from \\(\\mathbb{R}^{3}\\) to \\(\\mathbb{R}^{5}\\). \\[ \\begin{bmatrix} 1 &amp; 1 &amp; 1 \\\\ 2 &amp; 0 &amp; 1 \\\\ 3 &amp; 1 &amp; 0 \\\\ 4 &amp; 0 &amp; -2 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ -8 \\\\ -11 \\\\ -24 \\end{bmatrix} \\] We want to find all target vectors \\(\\mathsf{b}\\) such that \\(A \\mathsf{x} = \\mathsf{b}\\) is inconsistent. So we want the augmented matrix \\(\\begin{bmatrix} A \\,| \\, b \\end{bmatrix}\\) to have a pivot in the last column. \\[ \\left[ \\begin{array}{ccc|c} 1&amp; 2&amp; 4 &amp; b_1 \\\\ -3&amp; -5&amp; -11 &amp; b_2\\\\ 1&amp; 1&amp; 3 &amp; b_3 \\\\ \\end{array} \\right] \\longrightarrow \\left[ \\begin{array}{ccc|c} 1&amp; 2&amp; 4 &amp; b_1 \\\\ 0&amp; 1&amp; 1 &amp; 3b_1 +b_2\\\\ 0&amp; -1&amp; -1 &amp; -b_1+b_3 \\\\ \\end{array} \\right] \\longrightarrow \\left[ \\begin{array}{ccc|c} 1&amp; 2&amp; 4 &amp; b_1 \\\\ 0&amp; 1&amp; 1 &amp; 3b_1 +b_2\\\\ 0&amp; 0&amp; 0 &amp; 2b_1+b_2+b_3 \\\\ \\end{array} \\right] \\] So the set of target vectors that are not in the span of the columns of \\(A\\) are the vectors \\[ \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix} \\qquad \\mbox{where} \\qquad 2b_1 + b_2 + b_3 \\neq 0. \\] There are lots of right answers to this one. In my first matrix, I will just add the first two columns to get the thrid column. Then I will add one to one to the bottom right entry of the matrix. \\[ \\begin{bmatrix} 1&amp; 0 &amp; 1 \\\\ 0&amp; 1&amp; 1 \\\\ 2&amp; 2&amp; 4 \\\\ \\end{bmatrix} \\qquad\\qquad \\begin{bmatrix} 1&amp; 0 &amp; 1 \\\\ 0&amp; 1&amp; 1 \\\\ 2&amp; 2&amp; 5 \\\\ \\end{bmatrix} \\] This is a linear transformation with \\[A = \\begin{bmatrix} 1 &amp; 1 \\\\ 2 &amp; 0 \\\\ 0 &amp; -1 \\end{bmatrix}.\\] This is not a linear transformation because \\[ 2 \\, T \\left( \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix} \\right)= 2 \\begin{bmatrix} 3 \\\\ 1 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 6 \\\\ 2 \\\\ 2 \\end{bmatrix} \\quad \\mbox{while} \\quad T \\left( \\begin{bmatrix} 2 \\\\ 2 \\\\ 2 \\end{bmatrix} \\right)= 2 \\begin{bmatrix} 6 \\\\ 4 \\\\ 2 \\end{bmatrix}. \\] \\(A= \\begin{bmatrix} 1/2 &amp; 1/2 \\\\ 1/2 &amp; 1/2 \\end{bmatrix}\\) \\(A= \\begin{bmatrix} 0 &amp; -1 \\\\ -1 &amp; 0 \\end{bmatrix}\\) Vector Form: \\[ x_1 \\begin{bmatrix} 5 \\\\ 4 \\\\ -1 \\end{bmatrix} + x_2 \\begin{bmatrix} 3 \\\\ 1 \\\\ 3 \\end{bmatrix} + x_3 \\begin{bmatrix} 1 \\\\ 3 \\\\ -2 \\end{bmatrix} + x_4 \\begin{bmatrix} 11 \\\\ 2 \\\\ 1 \\end{bmatrix} + x_5 \\begin{bmatrix} -1 \\\\ 6 \\\\ 6 \\end{bmatrix} = \\begin{bmatrix} 10 \\\\ 11 \\\\ 12 \\end{bmatrix} \\] Matrix Form: \\[ \\begin{bmatrix} 5 &amp; 3 &amp; 1 &amp; 11 &amp; -1 \\\\ 4 &amp; 1 &amp; 3 &amp; 2 &amp; 6 \\\\ -1 &amp; 3 &amp; -2&amp; 1 &amp; 6 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5 \\end{bmatrix} = \\begin{bmatrix} 10 \\\\ 11 \\\\ 12 \\end{bmatrix} \\] \\(-\\mathsf{v}_1 - 2\\mathsf{v}_2 + \\mathsf{v}_3 + 0 \\mathsf{v}_4 = 0\\). \\(\\mathrm{span}(\\mathsf{v}_1,\\mathsf{v}_2,\\mathsf{v}_3,\\mathsf{v}_4)\\) looks like a copy of \\(\\mathbb{R}^3\\) sitting inside \\(\\mathbb{R}^4\\). In other words, is 3-dimensional subset of \\(\\mathbb{R}^4\\). The general solution is \\[ \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5 \\end{bmatrix} = s \\begin{bmatrix} -2 \\\\ 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix} + t \\begin{bmatrix} -1 \\\\ -1 \\\\ 0 \\\\ -2 \\\\ 1 \\end{bmatrix}. \\] My solution is \\[77,083,679 \\begin{bmatrix} -2 \\\\ 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix} - 72,159,215 \\begin{bmatrix} -1 \\\\ -1 \\\\ 0 \\\\ -2 \\\\ 1 \\end{bmatrix}. \\] There are scalars \\(c_1, c_2, c_3\\) not all zero such that \\(c_1 T(\\mathsf{u}) + c_2 T(\\mathsf{v}) + c_3 T(\\mathsf{w}) = \\mathbf{0}\\). We have \\[ \\mathbf{0} = c_1 T(\\mathsf{u}) + c_2 T(\\mathsf{v}) + c_3 T(\\mathsf{w}) = T(c_1 \\mathsf{u} + c_2 \\mathsf{v}+ c_3 \\mathsf{w}) \\] However, we know that \\(\\mathsf{u}, \\mathsf{v},\\mathsf{w}\\) are linearly independent, so \\[ c_1 \\mathsf{u} + c_2 \\mathsf{v}+ c_3 \\mathsf{w} \\neq \\mathbf{0}. \\] This is a nonzero vector that maps to the zero vector. Therefore \\(T\\) is not one-to-one. "],["quiz-2-review.html", "Vector 22 Quiz 2 Review 22.1 Overview 22.2 Practice Problems 22.3 Solutions to Practice Problems", " Vector 22 Quiz 2 Review 22.1 Overview Our first quiz covers sections 2.1 - 2.3 and 4.1-4.6 in Lay’s book. This corresponds to Problem Sets 4 and 5. The best way to study is to do practice problems. The Quiz will have calculation problems (like Edfinity) and more conceptual problems (like the problem sets). Here are some ways to practice: Make sure that you have mastered the Vocabulary, Skills and Concepts listed below. Look over the Edfinity homework assingments Do practice problems from the Edfinity Practice assignments. These allow you to “Practice Similar” by generating new variations of the same problem. Try to resolve the Problem Sets and compare your answers to the solutions. Do the practice problems below. Compare your answers to the solutions. 22.1.1 Vocabulary and Concepts You should understand these concepts and be able to read and use these terms correctly: all of the Important Definitions found here. matrix inverses the Invertible Matrix Theorem homogeneous coordinates subspaces null space and column space of a matrix kernel and image of a linear transformation basis (span and linearly independent) coordinate vector with respect to a basis \\(\\mathcal{B}\\) change-of-coordinates matrix dimension 22.1.2 Skills You should be able to perform these linear algebra tasks. solve matrix algebra equations find a matrix inverse use homogeneous coordinates to transform and translate images in the plane. show that a subset is a subspace or demonstrate that it is not a subspace describe the null space and the column space determine if a vector is in a null space or column space find a basis of a subspace answer questions about the connections between all these ideas write short proofs of basic statements using the Important Definitions 22.2 Practice Problems Here is a picture of some boats. The blue, yellow and gray boats are linear transformations of the red boat (using homogeneous coordinates). Find the \\(3 \\times 3\\) matrix corresponding to the linear transformation that creates: The shadow gray boat The fast blue boat The funny yellow boat. For your convenience, here is the code to draw the red boat as well as some commented code that you can adapt to create the other boats. &#39;```{r,fig.height=4,fig.width=4} # the red boat boat =cbind(c(0,0), c(-6,0), c(-7,3), c(-1,3), c(-1,5), c(-6,5), c(-1,10), c(-1,11), c(-.5,11), c(-.5,3), c(2,3) ) boat = rbind(boat,rep(1,11)) ##### update these matrices graymap = cbind(c(1,0,0), c(0,1,0),c(0,0,1)) bluemap = cbind(c(1,0,0), c(0,1,0),c(0,0,1)) yellowmap = cbind(c(1,0,0), c(0,1,0),c(0,0,1)) # plot all of the boats grayboat = graymap %*% boat blueboat = bluemap %*% boat yellowboat = yellowmap %*% boat plot(boat[1,],boat[2,],type=&quot;n&quot;,xlim=c(-16,16),ylim=c(-16,16),xlab=&quot;x&quot;,ylab=&quot;y&quot;) abline(h=-16:16, v=-16:16, col=&quot;gray&quot;, lty=&quot;dotted&quot;) polygon(grayboat[1,], grayboat[2,], col = &quot;gray&quot;, border = &quot;gray&quot;) polygon(blueboat[1,], blueboat[2,], col = &quot;blue&quot;, border = &quot;gray&quot;) polygon(yellowboat[1,], yellowboat[2,], col = &quot;yellow&quot;, border = &quot;gray&quot;) polygon(boat[1,], boat[2,], col = &quot;red&quot;, border = &quot;blue&quot;) Find the inverse of the matrix \\[ \\left[ \\begin{array}{rrr} 1 &amp; -2 &amp; 2 \\\\ 1 &amp; 0 &amp; 0 \\\\ 2 &amp;-4 &amp; 5 \\end{array} \\right] \\] Suppose that a linear transformation \\(T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n\\) has the property that \\(T(\\mathsf{u}) = T(\\mathsf{v})\\) for some pair of distinct vectors \\(\\mathsf{u}, \\mathsf{v} \\in \\mathbb{R}^n\\). Can \\(T\\) map \\(\\mathbb{R}^n\\) onto \\(\\mathbb{R}^n\\)? Why or why not? Let \\(U\\) and \\(W\\) be subspaces of a vector space \\(\\mathbb{R}^n\\). Prove or disprove the following statements \\(U \\cap W = \\{ \\mathsf{v} \\in \\mathbb{R}^n \\mid \\mathsf{v} \\in U \\mbox{ and } \\mathsf{v} \\in W \\}\\) is a subspace \\(U \\cup W = \\{ \\mathsf{v} \\in \\mathbb{R}^n \\mid \\mathsf{v} \\in U \\mbox{ or } \\mathsf{v} \\in W \\}\\) is a subspace \\(U+W = \\{\\mathsf{u} + \\mathsf{w} \\mid \\mathsf{u} \\in U \\mbox{ and } \\mathsf{w} \\in W \\}\\) is a subspace Let \\(T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\\) be a linear transformation. Suppose that \\(T: \\mathbb{R}^n \\to \\mathbb{R}^m\\) is one-to-one. Prove that if \\(\\mathsf{v}_1, \\mathsf{v}_2, \\mathsf{v}_3\\) are linearly independent, then \\(T(\\mathsf{v}_1), T(\\mathsf{v}_2), T(\\mathsf{v}_3)\\) are linearly independent. Suppose that \\(T: \\mathbb{R}^n \\to \\mathbb{R}^m\\) is onto. Prove that if \\(\\mathsf{v}_1, \\mathsf{v}_2, \\mathsf{v}_3\\) span \\(\\mathbb{R}^n\\) then \\(T(\\mathsf{v}_1), T(\\mathsf{v}_2), T(\\mathsf{v}_3)\\) span \\(\\mathbb{R}^m\\). I have performed some row operations below for you on a matrix \\(A\\). Find a basis for the column space and the null space of \\(A\\). \\[ A= \\left[ \\begin{matrix} 1&amp; 2&amp; 0&amp; 2&amp; 0&amp; -1 \\\\ 1&amp; 2&amp; 1&amp; 1&amp; 0&amp; -2 \\\\ 2&amp; 4&amp; -2&amp; 6&amp; 1&amp; 2 \\\\ 1&amp; 2&amp; 0&amp; 2&amp; -1&amp; -3 \\\\ \\end{matrix}\\right] \\longrightarrow \\left[ \\begin{matrix} 1&amp; 2&amp; 0&amp; 2&amp; 0&amp; -1\\\\ 0&amp; 0&amp; 1&amp; -1&amp; 0&amp; -1\\\\ 0&amp; 0&amp; 0&amp; 0&amp; 1&amp; 2\\\\ 0&amp; 0&amp; 0&amp; 0&amp; 0&amp; 0\\\\ \\end{matrix}\\right] \\] Consider the matrix \\[ A = \\left[ \\begin{array}{cccc} 1 &amp; 5 &amp; 2 &amp; -4 \\\\ 3 &amp; 10 &amp; 2 &amp; 8 \\\\ 4 &amp; 15 &amp; 4 &amp; 4 \\end{array} \\right] \\] Find a basis for \\(\\mathrm{Col}(A)\\). Find a basis for \\(\\mathrm{Nul}(A)\\). Are the vectors in \\({\\mathcal B}\\) a basis of \\(\\mathbb{R}^3\\)? If not, find a basis of \\(\\mathbb{R}^3\\) that consists of as many of the vectors from \\({\\mathcal B}\\) as is possible. Explain your reasoning. \\[ \\mathcal{B}=\\left\\{ \\begin{bmatrix} 1 \\\\ -1 \\\\ -2 \\end{bmatrix},\\begin{bmatrix} 2 \\\\ -1 \\\\ 1 \\end{bmatrix},\\begin{bmatrix} -1 \\\\ -1 \\\\ -8 \\end{bmatrix} \\right\\} \\] I have the vectors below: \\[ \\begin{bmatrix} 5\\\\ 4\\\\ 3\\\\ 1\\\\ 2 \\end{bmatrix}, \\begin{bmatrix} 4\\\\ 4\\\\ 3\\\\ 1\\\\ 2 \\end{bmatrix}, \\begin{bmatrix} 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\end{bmatrix}. \\] I know that they do not span \\(\\mathbb{R}^5\\), but I want to extend them to a basis of \\(\\mathbb{R}^5\\) by adding some vectors to the set. I created the matrix below and row reduced. Give a basis for \\(\\mathbb{R}^5\\) that uses my three vectors and explain why this method works in general. \\[ \\left[ \\begin{array}{cccccccc} 5 &amp; 4 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 4 &amp; 4 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 3 &amp; 3 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 2 &amp; 2 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\\\ \\end{array} \\right] \\rightarrow \\left[ \\begin{array}{cccccccc} 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 2 &amp; -3 \\\\ 0 &amp; 1 &amp; 0 &amp; -1 &amp; 0 &amp; 0 &amp; -3 &amp; 4 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; -1 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 2 &amp; -3 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; -2 \\\\ \\end{array} \\right] \\] Find the coordinates of \\(\\mathsf{w}\\) in the standard basis and of \\(\\mathsf{v}\\) in the \\(\\mathcal{B}\\)-basis. \\[ \\mathcal{B} = \\left\\{ \\mathsf{v}_1=\\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\mathsf{v}_2=\\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\mathsf{v}_3=\\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\mathsf{v}_4=\\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix} \\right\\}, \\qquad \\mathsf{w} = \\begin{bmatrix} 3 \\\\ -2 \\\\ 0 \\\\ -1 \\end{bmatrix}_{\\mathcal{B}}, \\qquad \\mathsf{v} = \\begin{bmatrix} 10 \\\\ 9 \\\\ 7 \\\\ 4 \\end{bmatrix}_{\\mathcal{S}} \\] The subspace \\(S \\subset \\mathbb{R}^5\\) is given by \\[ \\mathsf{S} = \\mathsf{span} \\left( \\begin{bmatrix}1\\\\ 1\\\\ 0\\\\ -1\\\\ 2 \\end{bmatrix}, \\begin{bmatrix} 0\\\\ 1\\\\ 1\\\\ 1\\\\ 1 \\end{bmatrix}, \\begin{bmatrix} 3\\\\ 1\\\\ -2\\\\ -5\\\\ 4 \\end{bmatrix}, \\begin{bmatrix} 1\\\\ 0\\\\ 1\\\\ 0\\\\ 1 \\end{bmatrix}, \\begin{bmatrix} 2\\\\ -1\\\\ -1\\\\ -3\\\\ 1 \\end{bmatrix}, \\right)\\] Use the following matrix to find a basis for \\(S\\). What is the dimension of \\(S\\)? \\[ A=\\left[ \\begin{array}{ccccc} 1 &amp; 0 &amp; 3 &amp; 1 &amp; 2 \\\\ 1 &amp; 1 &amp; 1 &amp; 0 &amp; -1 \\\\ 0 &amp; 1 &amp; -2 &amp; 1 &amp; -1 \\\\ -1 &amp; 1 &amp; -5 &amp; 0 &amp; -3 \\\\ 2 &amp; 1 &amp; 4 &amp; 1 &amp; 1 \\\\ \\end{array} \\right] \\rightarrow \\left[ \\begin{array}{ccccc} 1 &amp; 0 &amp; 3 &amp; 0 &amp; 1 \\\\ 0 &amp; 1 &amp; -2 &amp; 0 &amp; -2 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\end{array} \\right] \\] Find a basis for \\(\\mathrm{Nul}(A)\\). What is the dimension of this nullspace? A \\(6 \\times 8\\) matrix \\(A\\) contains 5 pivots. For each of \\(\\mathrm{Col}(A)\\) and \\(\\mathrm{Nul}(A)\\), Determine the dimension of the subspace, Indicate whether it is subspace of \\(\\mathbb{R}^6\\) or \\(\\mathbb{R}^8\\), and Decide how you would find a basis of the subspace. 22.3 Solutions to Practice Problems Here are the matrices to make the boats. Shadow gray boat: \\[ \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; -1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] Fast blue boat: \\[ \\begin{bmatrix} 1 &amp; -0.25 &amp; 13 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] Funny yellow boat: \\[ \\begin{bmatrix} 0.35 &amp; -0.35 &amp; -3 \\\\ 0.35 &amp; 0.35 &amp; 8 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] And here is the updated code &#39;```{r,fig.height=4,fig.width=4,echo=TRUE} # the red boat boat =cbind(c(0,0), c(-6,0), c(-7,3), c(-1,3), c(-1,5), c(-6,5), c(-1,10), c(-1,11), c(-.5,11), c(-.5,3), c(2,3) ) boat = rbind(boat,rep(1,11)) # updated mappings graymap = cbind(c(1,0,0), c(0,-1,0),c(0,0,1)) bluemap = cbind(c(1,0,0), c(0,1,0),c(13,0,1)) %*% cbind(c(1,0,0), c(-.25,1,0),c(0,0,1)) t=pi/4 yellowmap = cbind(c(1,0,0), c(0,1,0),c(-3,8,1)) %*% cbind(c(cos(t),sin(t),0), c(-sin(t),cos(t),0),c(0,0,1)) %*% cbind(c(1/2,0,0),c(0,1/2,0),c(0,0,1)) # plot all of the boats grayboat = graymap %*% boat blueboat = bluemap %*% boat yellowboat = yellowmap %*% boat plot(boat[1,],boat[2,],type=&quot;n&quot;,xlim=c(-16,16),ylim=c(-16,16),xlab=&quot;x&quot;,ylab=&quot;y&quot;) abline(h=-16:16, v=-16:16, col=&quot;gray&quot;, lty=&quot;dotted&quot;) polygon(grayboat[1,], grayboat[2,], col = &quot;gray&quot;, border = &quot;gray&quot;) polygon(blueboat[1,], blueboat[2,], col = &quot;blue&quot;, border = &quot;gray&quot;) polygon(yellowboat[1,], yellowboat[2,], col = &quot;yellow&quot;, border = &quot;gray&quot;) polygon(boat[1,], boat[2,], col = &quot;red&quot;, border = &quot;blue&quot;) The inverse is \\[ \\begin{bmatrix} 0 &amp; 1 &amp; 0 \\\\ -5/2 &amp; 1/2 &amp;1 \\\\ -2 &amp; 0 &amp; 1 \\end{bmatrix} \\] require(pracma) A = cbind(c(1,1,2),c(-2,0,-4),c(2,0,5),c(1,0,0),c(0,1,0),c(0,0,1)) rref(A) ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 1 0 0 0.0 1.0 0 ## [2,] 0 1 0 -2.5 0.5 1 ## [3,] 0 0 1 -2.0 0.0 1 No \\(T\\) cannot be an onto mapping by the Invertible Matrix Theorem. Since \\(T\\) is not one-to-one, the mapping cannot be onto. True Since \\(U\\) and \\(W\\) are subspaces, we know that \\(\\mathbb{0} \\in U\\) and \\(\\mathbb{0} \\in W\\). Therefore \\(\\mathbb{0} \\in U \\cap W\\). Let \\(\\mathsf{v}_1 \\in U \\cap W\\) and \\(\\mathsf{v}_2 \\in U \\cap W\\). + We know that \\(\\mathsf{v}_1 \\in U\\) and \\(\\mathsf{v}_2 \\in U\\). Since \\(U\\) is a subspace, we have \\(\\mathsf{v}_1 + \\mathsf{v}_2 \\in U\\). + We know that \\(\\mathsf{v}_1 \\in W\\) and \\(\\mathsf{v}_2 \\in W\\). Since \\(W\\) is a subspace, we have \\(\\mathsf{v}_1 + \\mathsf{v}_2 \\in W\\). Therefore \\(\\mathsf{v}_1 + \\mathsf{v}_2 \\in U \\cap W\\). Let \\(\\mathsf{v} \\in U \\cap W\\) and \\(c \\in \\mathbb{R}\\). We know that \\(\\mathsf{v} \\in U\\) and \\(c \\in R\\). Since \\(U\\) is a subspace, we have \\(c \\mathsf{v} \\in U\\). We know that \\(\\mathsf{v} \\in W\\) and \\(c \\in R\\). Since \\(W\\) is a subspace, we have \\(c \\mathsf{v} \\in W\\). Therefore \\(c \\mathsf{v} \\in U \\cap W\\). False. Here is an example that shows this is not always true. Let \\(V= \\mathbb{R}^2\\), \\(U = \\{ { x \\choose 0} \\mid x \\in \\mathbb{R} \\}\\) and \\(W= \\{ { 0 \\choose y} \\mid y \\in \\mathbb{R} \\}\\). The set \\(U \\cup W\\) is not closed under addition. For example, \\({1 \\choose 0} + {0 \\choose 1} = { 1 \\choose 1} \\notin U \\cup W\\). True. Since \\(U\\) and \\(W\\) are subspaces, we know that \\(\\mathbb{0} \\in U\\) and \\(\\mathbb{0} \\in W\\). Therefore \\(\\mathbb{0} = \\mathbb{0} + \\mathbb{0} \\in U + W\\). Let \\(\\mathsf{u}_1 + \\mathsf{w}_1 \\in U + W\\) and \\(\\mathsf{u}_1 + \\mathsf{w}_2 \\in U + W\\), where \\(\\mathsf{u}_1, \\mathsf{u}_2 \\in U\\) and \\(\\mathsf{w}_1, \\mathsf{w}_2 \\in W\\). Then \\[ (\\mathsf{u}_1 + \\mathsf{w}_1) + (\\mathsf{u}_2 + \\mathsf{w}_2) = (\\mathsf{u}_1 + \\mathsf{u}_2) + (\\mathsf{w}_1 + \\mathsf{w}_2) \\] and \\(\\mathsf{u}_3 = (\\mathsf{u}_1 + \\mathsf{u}_2) \\in U\\) (because \\(U\\) is a subspace) and \\(\\mathsf{w}_3 = (\\mathsf{w}_1 + \\mathsf{w}_2) \\in W\\) (because \\(W\\) is a subspace). Therefore \\((\\mathsf{u}_1 + \\mathsf{v}_1) + (\\mathsf{u}_2 + \\mathsf{w}_2) = \\mathsf{u}_3 + \\mathsf{w}_3 \\in U + W\\). Let \\(\\mathsf{u} + \\mathsf{w} \\in U + W\\) and \\(c \\in \\mathbb{R}\\). Then \\(c(\\mathsf{u} + \\mathsf{w}) = c \\mathsf{u} + c \\mathsf{w}\\). We know that \\(c \\mathsf{u} \\in U\\) (since \\(U\\) is a subspace) and \\(c \\mathsf{w} \\in W\\) (since \\(W\\) is a subspace). Therefore \\(c(\\mathsf{u} + \\mathsf{w}) = c \\mathsf{u} + c \\mathsf{w} \\in U+W\\). Suppose that \\(c_1 T(\\mathsf{v}_1) + c_2 T(\\mathsf{v}_2) + c_3 T(\\mathsf{v}_3) = 0\\). We must show that \\(c_1 = c_2 = c_3 = 0\\). Since \\(T\\) is a linear transformation, this means that \\(T(c_1 \\mathsf{v}_1+ c_2 \\mathsf{v}_2 + c_3 \\mathsf{v}_3 )= 0\\). Since \\(T\\) is one-to-one and \\(T(\\mathbf{0}) = \\mathbf{0}\\), we must have \\(c_1 \\mathsf{v}_1+ c_2 \\mathsf{v}_2 + c_3 \\mathsf{v}_3 = \\mathbf{0}\\). Because \\(\\mathsf{v}_1, \\mathsf{v}_2, \\mathsf{v}_3\\) are linearly independent, this means that \\(c_1 = c_2 = c_3 = 0\\). This proves that \\(T(\\mathsf{v}_1), T(\\mathsf{v}_2), T(\\mathsf{v}_3)\\) are linearly independent. Given \\(\\mathsf{w} \\in W\\). We must show that there exist constants \\(c_1, c_2, c_3\\) such that \\(\\mathsf{w} = c_1 T(\\mathsf{v}_1) + c_2 T(\\mathsf{v}_2) + c_3 T(\\mathsf{v}_3)\\). Here we go! Since \\(T\\) is onto, we know that there exists \\(\\mathsf{v} \\in \\mathbb{R}^n\\) such that \\(T(\\mathsf{v}) = \\mathsf{w}\\). Since \\(\\mathsf{v}_1, \\mathsf{v}_2, \\mathsf{v}_3\\) span \\(\\mathbb{R}^n\\), we know that there exist constants \\(c_1, c_2, c_3\\) such that \\(\\mathsf{v}= c_1 \\mathsf{v}_1 + c_2 \\mathsf{v}_2 + c_3 \\mathsf{v}_k\\) Therefore \\[ \\mathsf{w} = T(\\mathsf{v})= T(c_1 \\mathsf{v}_1 + c_2 \\mathsf{v}_2 + c_3 \\mathsf{v}_k) = c_1 T(\\mathsf{v}_1) + c_2 T(\\mathsf{v}_2) + c_3 T(\\mathsf{v}_k) \\] because \\(T\\) is a linear transformation. This proves that \\(T(\\mathsf{v}_1), T(\\mathsf{v}_2), T(\\mathsf{v}_3)\\) span \\(W\\). A basis for \\(\\mathrm{Col}(A)\\) is \\[ \\begin{bmatrix} 1 \\\\1 \\\\ 2 \\\\ 1 \\end{bmatrix}, \\quad \\begin{bmatrix} 0 \\\\1 \\\\ -2 \\\\ 0 \\end{bmatrix}, \\quad \\begin{bmatrix} 0 \\\\0 \\\\ 1 \\\\ -1 \\end{bmatrix} \\] and a basis for \\(\\mathrm{Nul}(A)\\) is \\[ \\begin{bmatrix} -2 \\\\1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\quad \\begin{bmatrix} -2 \\\\0 \\\\ 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\quad \\begin{bmatrix} 1 \\\\0 \\\\ 1\\\\ 0 \\\\ -2 \\\\ 1 \\end{bmatrix}. \\] Using RStudio we find: ## [,1] [,2] [,3] [,4] ## [1,] 1 5 2 -4 ## [2,] 3 10 2 8 ## [3,] 4 15 4 4 ## [,1] [,2] [,3] [,4] ## [1,] 1 0 -2.0 16 ## [2,] 0 1 0.8 -4 ## [3,] 0 0 0.0 0 A basis for \\(\\mathrm{Col}(A)\\) is \\[ \\begin{bmatrix} 1 \\\\ 3 \\\\ 4 \\end{bmatrix}, \\quad \\begin{bmatrix} 5 \\\\ 10 \\\\ 15 \\end{bmatrix}. \\] A basis for \\(\\mathrm{Nul}(A)\\) is \\[ \\begin{bmatrix} 2 \\\\ -0.8 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\quad \\begin{bmatrix} -16 \\\\ 4 \\\\ 0 \\\\ 1 \\end{bmatrix}. \\] A = cbind(c(1,-1,-2),c(2,-1,1),c(-1,-1,-8)) A ## [,1] [,2] [,3] ## [1,] 1 2 -1 ## [2,] -1 -1 -1 ## [3,] -2 1 -8 rref(A) ## [,1] [,2] [,3] ## [1,] 1 0 3 ## [2,] 0 1 -2 ## [3,] 0 0 0 No they are not a basis. The corresponding matrix only has two pivots. Let’s add the three elementary vectors to create matrix \\(B\\) and then row reduce. B = cbind(A, c(1,0,0),c(0,1,0),c(0,0,1)) B ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 1 2 -1 1 0 0 ## [2,] -1 -1 -1 0 1 0 ## [3,] -2 1 -8 0 0 1 rref(B) ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 1 0 3 0 -0.3333333 -0.3333333 ## [2,] 0 1 -2 0 -0.6666667 0.3333333 ## [3,] 0 0 0 1 1.6666667 -0.3333333 From this matrix, we can see that the vectors \\[ \\begin{bmatrix} 1 \\\\ -1 \\\\ -2 \\end{bmatrix}, \\quad \\begin{bmatrix} 2 \\\\ -1 \\\\ 1 \\end{bmatrix}, \\quad \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}. \\] are linearly independent because they correspond to the basis columns of \\(B\\). A basis for \\(\\mathbb{R}^5\\) is \\[ \\begin{bmatrix} 5\\\\ 4\\\\ 3\\\\ 1\\\\ 2 \\end{bmatrix}, \\begin{bmatrix} 4\\\\ 4\\\\ 3\\\\ 1\\\\ 2 \\end{bmatrix}, \\begin{bmatrix} 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\end{bmatrix}, \\begin{bmatrix} 0\\\\ 1\\\\ 0\\\\ 0\\\\ 0\\end{bmatrix}, \\begin{bmatrix} 0\\\\ 0\\\\ 1\\\\ 0\\\\ 0 \\end{bmatrix} \\] because these are basic columns in the given matrix. This will always work: place your desired vectors in the first columns. Since they are linearly independent, they will be basic columns. The remaining \\(n\\) elementary basis vectors span $. So the columns of the matrix span \\(\\mathbb{R}^n\\) and Gaussian Elimination will identify \\(n\\) pivots. The corresponding columns are a basis. We need the matrices \\[ P_{\\cal B} = \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 0 &amp; 1 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} \\qquad \\mbox{and} \\qquad P_{\\cal B}^{-1} = \\begin{bmatrix} 1 &amp; -1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; -1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp;-1 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] The desired coordinate vectors are \\[ \\mathsf{w} = \\begin{bmatrix} 0 \\\\ -3 \\\\ -1 \\\\ -1 \\end{bmatrix}_{\\mathcal{S}}, \\qquad \\mathsf{v} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{bmatrix}_{\\mathcal{B}} \\] Here is the R code for this solution: A = cbind(c(1,0,0,0),c(1,1,0,0),c(1,1,1,0),c(1,1,1,1)) Ainv = solve(A) A %*% c(3,-2,0,-1) ## [,1] ## [1,] 0 ## [2,] -3 ## [3,] -1 ## [4,] -1 Ainv %*% c(10,9,7,4) ## [,1] ## [1,] 1 ## [2,] 2 ## [3,] 3 ## [4,] 4 \\(\\dim(S) = 3\\) and a basis for \\(S\\) is \\[ \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\\\ -1 \\\\2 \\end{bmatrix}, \\quad \\begin{bmatrix} 0 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}, \\quad \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\\\1 \\end{bmatrix}. \\] \\(\\dim(\\mathrm{Nul}(A))=2\\) and a basis is \\[ \\begin{bmatrix} -3 \\\\ 2 \\\\ 1 \\\\ 0 \\\\0 \\end{bmatrix}, \\quad \\begin{bmatrix} -1 \\\\ 2 \\\\ 0 \\\\ -1 \\\\1 \\end{bmatrix}. \\] \\(\\mathrm{Col}(A)\\) has dimension 5, and it is a subspace of \\(\\mathbb{R}^6\\). You would find a basis by taking the pivot columns of \\(A\\). \\(\\mathrm{Nul}(A)\\) has dimension 3, and it is a subspace of \\(\\mathbb{R}^8\\). You would find a basis by finding the parametric solution to \\(A \\mathsf{x}= \\mathbb{0}\\). "]]
