

# Quiz 4 Review


## Overview

Our fourth quiz covers sections 6.1-6.5, 7.1 and 7.4  in Lay's book. This corresponds to Problem Set 8.

The best way to study is to do practice problems. The Quiz will have calculation problems (like Edfinity) and more conceptual problems (like the problem sets). Here are some ways to practice:

* Make sure that you have mastered the Vocabulary, Skills and Concepts  listed below.
* Look over the Edfinity homework assingments
* Do practice problems from the Edfinity Practice assignments. These allow you to "Practice Similar" by generating new variations of the same problem.
* Redo the Jamboard problems
* Try to resolve the Problem Sets and compare your answers to the solutions.
* Do the practice problems below. Compare your answers to the solutions.

### Vocabulary, Concepts and Skills

See the [Week 7-8 Learning Goals](week-7-8-learning-goals) for the list of vocabulary, concepts and skills.



## Practice Problems


###

Let $\mathsf{v} =  \begin{bmatrix}1 \\ -1 \\ 1 \end{bmatrix}$ and $\mathsf{w}= \begin{bmatrix}5 \\ 2 \\ 3 \end{bmatrix}$.


a. Find $\| \mathsf{v} \|$ and $\| \mathsf{w} \|$.

a. Find the distance between $\mathsf{v}$ and $\mathsf{w}$.

a. Find the cosine of the angle between $\mathsf{v}$ and $\mathsf{v}$.

a. Find $\mbox{proj}_{\mathsf{v}} \mathsf{w}$. 


b. Let $W=\mbox{span} (\mathsf{v}, \mathsf{w})$. Create an orthonormal basis $\mathsf{u}_1, \mathsf{u}_2$ for $W$ such that $\mathsf{u}_1$ is a vector in the same direction as $\mathsf{v}$.


###

Let $\mathsf{u} \neq 0$ be a vector in $\mathbb{R}^n$. Define the function $T: \mathbb{R}^n \rightarrow \mathbb{R}^n$ by
$T(\mathsf{x}) = \mbox{proj}_{\mathsf{u}} \mathsf{x}$. 

a. Prove that $T: \mathbb{R}^n \rightarrow \mathbb{R}^n$ is a linear transformation.

b. Recall that the kernel of $T$ is the subspace $\mbox{ker}(T) = \{ \mathsf{x} \in \mathbb{R}^n \mid T(x) = \mathbf{0} \}$. Describe  $\mbox{ker}(T)$ as explicitly as you can.




### 

 The vectors $\mathsf{u}_1, \mathsf{u}_2$  form an orthonormal basis of a subspace $W$ of $\mathbb{R}^4$. Find the projection of $\mathsf{v}$ onto $W$ and determine how close $\mathsf{v}$ is to $W$.
$$
\mathsf{u}_1 = \frac{1}{2}\begin{bmatrix} 1\\ -1\\ -1\\ 1 \end{bmatrix}, \quad
\mathsf{u}_2 =  \frac{1}{2}\begin{bmatrix} 1\\ -1\\ 1\\ -1  \end{bmatrix}, \quad
\mathsf{v} =  \begin{bmatrix}   2\\ 2\\ 4\\ 2 \end{bmatrix} 
$$

###



Consider vectors 
$\mathsf{v}_1 = \begin{bmatrix} 1 \\ 1 \\-1 \end{bmatrix}$ and 
$\mathsf{v}_2= \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}$ in $\mathbb{R}^3$.
Let $W=\mbox{span}(\mathsf{v}_1, \mathsf{v}_2)$.

a.  Show that $\mathsf{v}_1$ and $\mathsf{v}_2$ are orthogonal.

b.  Find a basis for $W^{\perp}$.

c. Use orthogonal projections to find the representation of 
$\mathsf{y} = \begin{bmatrix} 8 \\ 0 \\ 2 \end{bmatrix}$ as
$\mathsf{y} = \hat{\mathsf{y}} + \mathsf{z}$ where
$\hat{\mathsf{y}} \in W$ and $\mathsf{z} \in W^{\perp}$.



###
Let $W$ be the span of the vectors
$$
\begin{bmatrix}
1 \\ -2 \\ 1 \\ 0 \\1 
\end{bmatrix}, \quad
\begin{bmatrix}
-1 \\ 3 \\ -1 \\ 1 \\ -1 
\end{bmatrix}, \quad
\begin{bmatrix}
0 \\ 0 \\ 1 \\ 3 \\1 
\end{bmatrix}, \quad
\begin{bmatrix}
0 \\ 2 \\ 0 \\ 0 \\4 
\end{bmatrix}
$$

a. Find a basis for $W$. What is the dimension of this subspace?
b. Use the Gram-Schmidt process on your answer to part (a) to find an orthonormal basis for $W$
c. Find a basis for $W^{\perp}$
d. Use the Gram-Schmidt process on your answer from part (c) to find an orthogonal basis for $W^{\perp}$.


### 

Let $\mathsf{u}_1, \mathsf{u}_1, \ldots, \mathsf{u}_n$ be an **orthonormal** basis for $\mathbb{R}^n$. Pick any $\mathsf{v} \in \mathbb{R}^n$. Show that
$$
\| \mathsf{v} \| = \sqrt{ ( \mathsf{v} \cdot \mathsf{u}_1)^2 + (\mathsf{v} \cdot \mathsf{u}_1)^2 + \cdots +(\mathsf{v} \cdot \mathsf{u}_1)^2}.
$$

<!--
* Use the Gram-Schmidt process to find an orthogonal basis for $W$.
* Find a basis for $W^{\perp}

```
A = cbind(c(3,0,0,4,0),c(1,1,0,-1,1),c(0,1,2,-1,2))
A = cbind(c(1,-2,1,0,1),c(-1,3,-1,1,-1),c(1,0,1,4,5),c(0,2,0,0,-4))

gramSchmidt(A)
```

-->


<!-- least squares -->

###

Consider the system $A \mathsf{x} = \mathsf{b}$ given by
$$
\begin{bmatrix}
1 & 1 & 1 \\
1 & 2 & -1 \\
1 & 1 & -1 \\
1 & 2 & 1
\end{bmatrix}
\begin{bmatrix}
x_1\\ x_2 \\ x_3
\end{bmatrix}
=
\begin{bmatrix}
4\\ 1 \\ -2 \\ -1
\end{bmatrix}.
$$

a. Show that this system is inconsistent.
b. Find the projected value $\hat{\mathsf{b}}$,  and the residual $\mathsf{z}$.
c. How close is your approximate solution to the desired target vector?

<!--
###

Here is an inconsistent system of equations:
$$
\begin{bmatrix} 1 & 2 \\ 1 & 2 \\ 1 & -1 \end{bmatrix}
 \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = 
  \begin{bmatrix} 6\\ 4 \\ -4 \end{bmatrix} 
$$

a. State the normal equations for this problem (be sure to do all of the necessary matrix multiplications).

b. Find the least squares solution to the problem.

c. How close is your approximate solution to the desired target vector?

### 
-->

###
According to the [COVID Tracking Project](https://covidtracking.com/), Minnestoa had $54,463$ positive COVID-19 cases between March 6 and 31 July, 2020. As of 16 December, 2020, that count has reached $386,412$. 

The vector `covid.mn` lists the total number of new COVID-19 cases in Minnesota between August 1, 2020 and December 16, 2020 (on top of the previously reported $54,463$).
 

```{r, echo=TRUE}


covid.mn = c(725, 1484, 2097, 2699, 3316, 4177, 4722, 5638, 6435, 7053, 7376, 7840, 8530, 9260, 9950, 10689, 11253, 11598, 12155, 12845, 13670, 14404, 15121, 15835, 16244, 16773, 17927, 18777, 19794, 20726, 21401, 21892, 22622, 23660, 24503, 25417, 26124, 26762, 27145, 27405, 27786, 28253, 29125, 29848, 30486, 30888, 31350, 32259, 33344, 34258, 35554, 36479, 36959, 37637, 38549, 39726, 41196, 42271, 43175, 43984, 44671, 45737, 46903, 48324, 49363, 50336, 51277, 52188, 53459, 54849, 56365, 57805, 58976, 60111, 61480, 62643, 64933, 66627, 68349, 69976, 71068, 72128, 73689, 75400, 77659, 79339, 80909, 83073, 84981, 87848, 91002, 94009, 96209, 99157, 102633, 106460, 110402, 115844, 120491, 126399, 130325, 135218, 140107, 147332, 152876, 161565, 169118, 176555, 182486, 187580, 195443, 202237, 208489, 215694, 222037, 228453, 234840, 234840, 240538, 249560, 258506, 264300, 267849, 273014, 279163, 284510, 290818, 296399, 301689, 304740, 309256, 312755, 316505, 320935, 324360, 327378, 329701, 331949)

```
a. Find the best fitting exponential function $f(t) = a e^{k t}$ for the number of  COVID-19 cases in Minnesota since 31 July, 2020.


b. Run the following code to plot your function. This code assumes that your least squares solution is given by `xhat`. Does it look like a good fit?

```
a = exp(xhat[1])
k = xhat[2]

f=function(y){a * exp(k*(y))}

plot(x,f(x)+ covid.start,type="l",lwd=3,ylab="new positive COVID-19 cases", xlab="days since July 31, 2020", main="best fit exponential function")
points(x,covid.mn + covid.start,pch=20,cex=.7,col="red")

```


###

Consider the symmetric matrix 
$$A = \begin{bmatrix}
   3  &  0 & 34  &  3 \\
   0  &  6 & -34  &  0 \\
  34 & -34 &  74  & 34 \\
   3  &  0  & 34  &  3
\end{bmatrix}
$$
a. Use RStudio to find the eigenvalues $\lambda_1 > \lambda_2 > \lambda_3 > \lambda_4$ and their corresponding eigenvectors $\mathsf{v}_1, \mathsf{v}_2, \mathsf{v}_3, \mathsf{v}_3$. Confirm that these eigenvectors form an orthonormal set.

b. Is the linear transformation $T(\mathsf{x}) = Ax$ invertible? How do you know?

c. Confirm that 
$$
A = \lambda_{1} \mathsf{v}_1 \mathsf{v}_1^{\top} + \lambda_{2} \mathsf{v}_2 \mathsf{v}_2^{\top} + \lambda_{3} \mathsf{v}_3 \mathsf{v}_3^{\top} + \lambda_{4} \mathsf{v}_4 \mathsf{v}_4^{\top}.
$$

d. Use your answer in part (d) to find the best rank 2 approximation for $A$. (Be careful!)

<!--
```{r}
#A = cbind(c(20,1,1), c(1,17,2), c(1,2,17))
#A
#eigen(A)
#%svd(A)


P = cbind(c(1,-1,-1,1),c(1,2,0,1), c(1,0,0,-1),c(1,-1,3,1))

D = diag(c(-7,1,0,9))


A = P %*% D %*% t(P)

A

syst = eigen(A)

v1 = syst$vectors[,1]
v2 = syst$vectors[,2]
v3 = syst$vectors[,3]
v4 = syst$vectors[,4]

syst$values[1] * v1 %*% t(v1) + syst$values[2] * v2 %*% t(v2) + syst$values[3] * v3 %*% t(v3) + syst$values[4] * v4 %*% t(v4)

syst$values[1] * v1 %*% t(v1)  + syst$values[4] * v4 %*% t(v4)

zapsmall(syst$values[2] * v2 %*% t(v2) + syst$values[3] * v3 %*% t(v3))

```
-->



### 
The matrix
$$
A = \left[
\begin{array}{cccc}
 1 & 2 &  5 \\
 2 & 3 &  6 \\
 -1 & 2 &  3 \\
 -3 & 0 &  1 \\
 1 & 4 &  5 \\
\end{array}
\right]
$$

has singular value decomposition

$$
\left[
\begin{array}{cccccc}
 0.48 & -0.02 & 0.55 & 0.63 & -0.27 \\
 0.61 & -0.24 & 0.32 & -0.63 & 0.27 \\
 0.30 & 0.43 & -0.24 & -0.32 & -0.75 \\
 0.032 & 0.87 & 0.22 & 0.00 & 0.44 \\
 0.56 & -0.01 & -0.70 & 0.32 & 0.31 \\
\end{array}
\right]
\left[
\begin{array}{cccc}
 11.4 & 0 & 0 \\
 0 & 3.60 & 0 \\
 0 & 0 & 1.39 \\
 0 & 0 & 0 \\
 0 & 0 & 0 \\
\end{array}
\right]
\left[
\begin{array}{cccc}
 0.16 & -0.98 & 0.062 \\
 0.49 & 0.026 & -0.87 \\
 0.86 & 0.17 & 0.49 \\
\end{array}
\right].
$$

a. Find an orthonormal basis for each of the four fundamental subspaces $\mbox{Nul}(A), \mbox{Col}(A), \mbox{Row}(A), \mbox{Nul}(A^{\top})$.  
b. Confirm that your basis for $\mbox{Nul}(A)$ is orthogonal to your basis for \mbox{Row}(A)
c. Explain how we know that the mapping $T(\mathsf{x}) = A\mathsf{x}$ is one-to-one.
d. Since the mapping $T: \mathbb{R}^3 \rightarrow \mathbb{R}^5$ is one-to-one. It maps a cube in $\mathbb{R}^3$  to a 3D "retangular cuboid" in $\mathbb{R}^5$. Does the 3D volume expand, contract, or stay constant after the mapping? How do you know?
e. What is the best rank 1 approximation of the matrix $A$?



###

Here is a matrix $A$ and its reduced row echelon form $B$
$$
A = \begin{bmatrix}
   1  &  3  & -3  &  1  &  0 \\
    2  &  1  &  0  &  6 &   5 \\
   3  &  3  & -3  &  6  &  3 \\
  -1  &  4  & -3  & -3  & -1
\end{bmatrix}
\qquad \longrightarrow \qquad
B = \begin{bmatrix}
    1 &   0  &  0 & 2.5 & 1.5 \\
    0  &  1  &  0 & 1.0 & 2.0 \\
  0  & 0  &  1 & 1.5 & 2.5 \\
   0  &  0  &  0 & 0.0 & 0.0
\end{bmatrix}.
$$

a. Find a basis for $\mbox{Nul}(A)$ and $\mbox{Col}(A)$.

b. Is the linear transformation $T(\mathsf{x}) = A \mathsf{x}$ one-to-one? Onto?

c. How is the SVD for $A$ related to the SVD for $B$? What properties will they share? What properties will be different? Make some conjectures.

d. Now find the SVD of both $A$ and $B$, and test your conjectures. Compare the singular values, the right singular vectors and the left singular vectors. Be sure to compare each of the four fundamental subspaces: $\mbox{Nul}(M), \mbox{Col}(M), \mbox{Row}(M), \mbox{Nul}(M^{\top})$. 

<!--
```
v1 = c(1,3,-3,0,0)
v2 = c(1,-2,4,2,-1)
v3 = c(0,1,0,3,2)
v4 = c(2,0,0,-1,3)

w1 = v1+v2
w2 = v4-v2+v3
w3 = v4+v1
w4 = v3 + v1-v4


v1 = c(1,3,-3,1,0)
#v2 = c(1,-2,4,0,-1)
v3 = c(0,1,0,1,2)
v4 = c(2,0,0,5,3)
v2 = c(0,0,0,0,0)

w1 = v1+v2
w2 = v4-v2+v3
w3 = v4+v1
w4 = v3 + v1-v4

B = rbind(w1,w2,w3,w4)
B
#U = rref(B)

U

svd(B)
svd(U)
```
-->




###

Singular value decomposition can be used for clustering of high dimensional data. Indeed, the singular vectors encode the patterns in a matrix. So let's try this out on the Senate votes from the 109th Congress (from Problem Set 8). Let's load in the data and assign a color to each senator according to their party.


```{r, echo=TRUE}
library(readr)

senate.vote.file = "https://raw.github.com/mathbeveridge/math236_f20//main/data/SenateVoting109.csv"

senators <- read_csv(senate.vote.file, col_names = TRUE)

A <- as.matrix(senators[4:49])

sen.color=rep("goldenrod", dim(senators)[1])
sen.color[senators$Party=='D']="cornflowerblue"
sen.color[senators$Party=='R']="firebrick"



```


a. Find the singular value decomposition. Define `singval` to be the singular values. Plot them  using the command `plot(singval,pch=19,cex=.5,col='blue')`. How many "important" singular values are there? 


b. Define `U` to be the matrix of right singular vectors. Plot the important singular vectors one by one. Here is a command to plot the first singular vector: ``plot(U[,1],pch=19,cex=.75,col=sen.color)`. Do any of the singular values distinguish Democrats from Republicans along the $y$-axis?


**Remark**: When we explored [Voting Patterns in the US Senate](voting-patterns-in-the-us-senate), we were actually using singular value decomposition to explore those other datasets. In this problem, you looked at a rectangular matrix  $A$ for senators (rows) and votes (columns). In the previous exploration, you were given a square matrix that was (essentially) $AA^{\top} = (A^{\top}A)^{\top}$. So the eigenvectors of that square matrix are the singular values of the rectangular matrix $A$.


